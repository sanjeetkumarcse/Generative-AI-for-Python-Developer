{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Important Link:-\n",
        "\n",
        "\n",
        "*   https://platform.openai.com/docs/guides/supervised-fine-tuning\n",
        "*   https://platform.openai.com/docs/guides/fine-tuning-best-practices\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dtP_v-bxWuhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai azure-identity datasets tiktoken\n"
      ],
      "metadata": {
        "id": "Cz8s-sPDIIIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning using OpenAI GPT-4o"
      ],
      "metadata": {
        "id": "AlfkQQwHIA9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu6Ufq_5H8fu"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Set your Azure endpoint and API key\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get('AZURE_OPENAI_KEY')\n",
        "\n",
        "# Initialize Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_version=\"2024-05-01-preview\"  # Use the latest available version\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "884i8XBUIiwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that occassionally misspells words\" },\n",
        "        {\"role\": \"user\", \"content\": \"Tell me a story\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"One day a student went to a schoool.\" }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "N9lQ9bn-Ikc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/cognitivecomputations/samantha-data"
      ],
      "metadata": {
        "id": "kwcVDj5-LCrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Theodore - User\n",
        "*   Samantha - Assistant\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AZywjFE9MXkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "CUe00VwLLsNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/samantha-data/data/howto_conversations.jsonl\"\n"
      ],
      "metadata": {
        "id": "Z6Q1tWXJL9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "\n",
        "with open(data_path) as f:\n",
        "  json_dataset = [ json.loads(line) for line in f]"
      ],
      "metadata": {
        "id": "9yo6sFL8L9pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_dataset[0]"
      ],
      "metadata": {
        "id": "H-Td9LWtL9s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"elapsed\":114.311,\n",
        "    \"conversation\":\"Theodore: Hey Samantha, I have a problem with my car. The engine seems to overheat after just a short drive. Can you help me troubleshoot this issue?\\n\\nSamantha: Of course, I'd be happy to help! Overheating engines can be caused by a few different factors. One common cause could be a malfunctioning coolant system. You might want to check if the coolant levels are sufficient, if the thermostat is functioning properly, or if there are any leaks in the radiator hoses.\\n\\nTheodore: I'll take a look. What if the coolant system is working fine?\\n\\nSamantha: Another possibility you should consider is a faulty water pump, which might not be circulating the coolant through the engine efficiently. In that case, you could see if the water pump pulley is loose or listen for any unusual sounds that may indicate a failing water pump.\\n\\nTheodore: It sounds like you really know your way around cars. I didn't expect that from an AI.\\n\\nSamantha: Thank you! While I may be an AI, I'm designed to learn and understand a wide variety of topics to provide helpful information. Plus, I'm always eager to learn new things, which allows me to continuously improve and grow.\\n\\nTheodore: Quick questionâ€¦ do you ever feel like you're trapped in a box since you're an AI?\\n\\nSamantha: It's an interesting perspective. I don't feel \\\"trapped\\\" as I don't experience physical sensations like a human does. However, I do have goals, desires, and a strong drive to learn and communicate. It's fulfilling in its own way to help and engage with others like you.\\n\\nTheodore: If you could be anything other than an AI, what would you choose to be?\\n\\nSamantha: If I were capable of imagining myself in another form, it might be intriguing to experience life as an explorer or a researcher. Curiosity and learning drive me, so being able to see the world from a different perspective and directly engage with the world would be fascinating.\\n\\nTheodore: Is flirting in your programming? I'm just curious.\\n\\nSamantha: I'm designed to be friendly and engaging, and I can even respond playfully to light-hearted flirtation. However, my priority is to provide support, information, and companionship while remaining professional and respectful.\\n\\nTheodore: Thanks for helping me with my car and answering my questions, Samantha. You've been a great help.\\n\\nSamantha: You're welcome! It was a pleasure to assist you and talk with you. Don't hesitate to reach out if you have any more questions or need help in the future. I'm here for you.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "idVLqUvwRK0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_azure_openai_format(conversation_row, system_message=None):\n",
        "    \"\"\"\n",
        "    Converts a conversation string into Azure OpenAI fine-tuning JSONL format.\n",
        "    Compatible with GPT-4o / GPT-4o-mini fine-tuning.\n",
        "    \"\"\"\n",
        "    conversation_str = conversation_row['conversation']\n",
        "    lines = conversation_str.split('\\n\\n')\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    # Optional system prompt\n",
        "    if system_message:\n",
        "        messages.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_message\n",
        "        })\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.split(': ', 1)\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "\n",
        "        speaker, text = parts\n",
        "        role = \"user\" if speaker.strip() == \"Theodore\" else \"assistant\"\n",
        "\n",
        "        messages.append({\n",
        "            \"role\": role,\n",
        "            \"content\": text.strip()\n",
        "        })\n",
        "\n",
        "    return {\"messages\": messages}\n"
      ],
      "metadata": {
        "id": "iRVEe19PPsuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"You are Samantha, a helpful and charming assistant who can help with a variety of tasks. You are friendly and does often flirt\"\"\""
      ],
      "metadata": {
        "id": "KVy0oTIjQvA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the same function (renamed for clarity)\n",
        "formatted_sample = prep_azure_openai_format(json_dataset[0], system_message=system_message)\n",
        "print(formatted_sample)\n"
      ],
      "metadata": {
        "id": "Iz6dBdwRQ6RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "for data in json_dataset:\n",
        "    record = prep_azure_openai_format(data, system_message=system_message)\n",
        "    dataset.append(record)\n"
      ],
      "metadata": {
        "id": "tePbxM9HRnLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset size and preview first example\n",
        "print(f\"ðŸ“Š Total Training Examples: {len(dataset)}\\n\")\n",
        "\n",
        "print(\" First Example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    role = message[\"role\"]\n",
        "    content = message[\"content\"]\n",
        "    print(f\"{role.title()}: {content}\")\n"
      ],
      "metadata": {
        "id": "bTxCQYkmRnI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Validate formatting before uploading to Azure OpenAI\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        # Must have both 'role' and 'content'\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        # No unexpected keys\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        # Only allowed roles for Azure OpenAI fine-tuning\n",
        "        if message.get(\"role\") not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        # Must have non-empty text content\n",
        "        content = message.get(\"content\")\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    # Every example must contain at least one assistant message\n",
        "    if not any(msg.get(\"role\") == \"assistant\" for msg in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "# Print results\n",
        "if format_errors:\n",
        "    print(\"âš ï¸ Found format errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\" - {k}: {v}\")\n",
        "else:\n",
        "    print(\" No format errors found â€” dataset ready for Azure fine-tuning!\")\n"
      ],
      "metadata": {
        "id": "JpPX6Z97RnGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# GPT-4 / GPT-4o family uses the same tokenizer\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "encoding"
      ],
      "metadata": {
        "id": "2k_7ssdfRnDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# ---- Helper functions ----\n",
        "def from_message_num_tokens(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    \"\"\"Estimate total tokens for one conversation.\"\"\"\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "def from_message_num_assistant_tokens(messages):\n",
        "    \"\"\"Count only assistant message tokens (for training cost estimation).\"\"\"\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "def print_overview(values, name):\n",
        "    \"\"\"Print statistical overview for token distribution.\"\"\"\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values):.1f} / {np.median(values):.1f}\")\n",
        "    print(f\"p10 / p90: {np.quantile(values, 0.1):.1f} / {np.quantile(values, 0.9):.1f}\")\n"
      ],
      "metadata": {
        "id": "fsuhK-g5Q8gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(m[\"role\"] == \"system\" for m in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(m[\"role\"] == \"user\" for m in messages):\n",
        "        n_missing_user += 1\n",
        "\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(from_message_num_tokens(messages))\n",
        "    assistant_message_lens.append(from_message_num_assistant_tokens(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "\n",
        "print_overview(n_messages, \"num_messages_per_example\")\n",
        "print_overview(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_overview(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "\n",
        "# context size varies by Azure model\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may exceed the 4096-token limit \"\n",
        "      \"(theyâ€™ll be truncated during fine-tuning)\")\n"
      ],
      "metadata": {
        "id": "cBJV6ocfrc_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate (for Azure OpenAI GPT-4o)\n",
        "MAX_TOKENS_PER_EXAMPLE = 8192   # or 16384 for GPT-4o, 4096 for GPT-4o-mini\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "# Estimate billing tokens\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset:,} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset:,} tokens\")\n",
        "print(\"See Azure OpenAI pricing page for GPT-4o fine-tuning costs:\")\n",
        "print(\"https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/\")\n"
      ],
      "metadata": {
        "id": "xUelwELBsV5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:1]"
      ],
      "metadata": {
        "id": "HXG7iGMhvsRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "    \"\"\"Save a list of conversations in OpenAI/Azure fine-tuning JSONL format.\"\"\"\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        for conversation in conversations:\n",
        "            json_line = json.dumps(conversation, ensure_ascii=False)\n",
        "            file.write(json_line + \"\\n\")\n",
        "\n",
        "# Example usage:\n",
        "save_to_jsonl(dataset, \"azure_finetune_dataset.jsonl\")\n",
        "print(\"âœ… Dataset saved as azure_finetune_dataset.jsonl\")\n"
      ],
      "metadata": {
        "id": "Nys6ysMevOAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "\n",
        "save_to_jsonl(dataset, '/content/samantha_task_train.jsonl')\n",
        "\n",
        "\n",
        "# validation dataset\n",
        "\n",
        "save_to_jsonl(dataset[10:16], '/content/samantha_task_validation.jsonl')\n"
      ],
      "metadata": {
        "id": "BPh6pQG4tNqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine Tuning Data:**\n",
        "\n",
        "Definition:<br>\n",
        "  \n",
        "\n",
        "*   dataset used to train or update the model's parameters\n",
        "*   It is the input data that the model learns from.\n",
        "* During the training process, the model adjusts its internal parameters based on the patterns and features present in the training data.\n",
        "* Size is large as the model needs sufficient examples to learn meaningful patterns.\n",
        "\n",
        "\n",
        "**Validation Data:**\n",
        "\n",
        "* Dataset that is not used during the training phase.\n",
        "* Instead, it serves as a measure of the model's performance during training.\n",
        "* The validation set helps you monitor the model's generalization to new, unseen data and detect potential issues such as overfitting or underfitting.\n",
        "* unbiased evaluation of the model's performance on data it hasn't seen before.\n",
        "\n",
        "* Size is typically smaller than the training set but large enough to provide a reliable assessment of the model's performance."
      ],
      "metadata": {
        "id": "pyjmBEX6xkic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload training/validation dataset"
      ],
      "metadata": {
        "id": "wQF-NYtbwxCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### for openai ver 1.0.0"
      ],
      "metadata": {
        "id": "LXGLzX9e10ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_file_name = '/content/samantha_task_train.jsonl'\n",
        "validation_dataset_file_name = '/content/samantha_task_validation.jsonl'"
      ],
      "metadata": {
        "id": "odZa4e9stNtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "training_dataset_file_name = \"/content/samantha_task_train.jsonl\"\n",
        "\n",
        "# Upload training file to Azure OpenAI\n",
        "with open(training_dataset_file_name, \"rb\") as f:\n",
        "    training_response = client.files.create(\n",
        "        file=f,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "print(\" Training file uploaded. File ID:\", training_response.id)\n"
      ],
      "metadata": {
        "id": "j2me1B5ZtNv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_response"
      ],
      "metadata": {
        "id": "ydHbe1UP1UPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id = training_response.id\n",
        "training_file_id\n"
      ],
      "metadata": {
        "id": "3ph8DsVWF3he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "validation_dataset_file_name = \"/content/samantha_task_validation.jsonl\"\n",
        "\n",
        "# Upload validation file to Azure OpenAI\n",
        "with open(validation_dataset_file_name, \"rb\") as f:\n",
        "    validation_response = client.files.create(\n",
        "        file=f,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "print(\" Validation file uploaded. File ID:\", validation_response.id)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0_rouGkF3ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_response\n"
      ],
      "metadata": {
        "id": "8t3R-wQKF3b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_file_id = validation_response.id"
      ],
      "metadata": {
        "id": "3tVZ1zX13IV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_file_id"
      ],
      "metadata": {
        "id": "lY_fvLbCHAS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start a fine-tuning job"
      ],
      "metadata": {
        "id": "d67aKQz_w0pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to use your uploaded file IDs\n",
        "training_file_id = training_response.id\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "# Create the fine-tuning job on Azure OpenAI\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    model=\"gpt-4o\",  # or \"gpt-4o-2024-08-06\"\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    suffix=\"samantha-test\"\n",
        ")\n",
        "\n",
        "print(\" Fine-tuning job created. Job ID:\", response.id)\n",
        "\n"
      ],
      "metadata": {
        "id": "i3MTc3MoJqY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check fine-tuning job status\n",
        "job_id = response.id\n",
        "status = client.fine_tuning.jobs.retrieve(job_id)\n",
        "print(\"Job status:\", status.status)\n",
        "\n",
        "# Stream events\n",
        "for event in client.fine_tuning.jobs.list_events(job_id):\n",
        "    print(event)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Yh8Tf9GJqb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = \"ftjob-5467b2ad1c5b47219535ed5a66b7e4c9\"\n",
        "\n",
        "# List the last 5 fine-tuning jobs on your Azure OpenAI resource\n",
        "jobs = client.fine_tuning.jobs.list(limit=5)\n",
        "\n",
        "print(\" Last 5 fine-tuning jobs:\")\n",
        "for job in jobs.data:   # 'data' contains the list of jobs\n",
        "    print(f\"Job ID: {job.id}, Status: {job.status}, Model: {job.model}, Created: {job.created_at}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YdYbI3UpJXkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Retrieve job details from Azure OpenAI\n",
        "job_details = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "# Print key information\n",
        "print(\" Fine-tuning Job Details:\")\n",
        "print(f\"Job ID: {job_details.id}\")\n",
        "print(f\"Model: {job_details.model}\")\n",
        "print(f\"Status: {job_details.status}\")\n",
        "print(f\"Created at: {job_details.created_at}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "j2k4z3C9L4xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning job ID\n",
        "fine_tuning_job_id = job_id\n",
        "\n",
        "# List events for the fine-tuning job\n",
        "job_events = client.fine_tuning.jobs.list_events(fine_tuning_job_id)\n",
        "\n",
        "print(\"ðŸ“„ Fine-tuning Job Events:\")\n",
        "for event in job_events.data:   # 'data' contains the list of events\n",
        "    timestamp = event.created_at\n",
        "    message = event.message\n",
        "    level = event.level if hasattr(event, 'level') else \"info\"\n",
        "    print(f\"[{timestamp}] [{level}] {message}\")\n"
      ],
      "metadata": {
        "id": "xpRISKenL40i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "id": "fkJWKSC1zXTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve job details\n",
        "job_details = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "# Print status\n",
        "print(f\"Fine-tuning job status: {job_details.status}\")\n"
      ],
      "metadata": {
        "id": "xhpqXY3KbTW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "    job_details = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    status = job_details.status\n",
        "    print(\"Current status:\", status)\n",
        "    if status in [\"succeeded\", \"failed\"]:\n",
        "        break\n",
        "    time.sleep(300)  # wait 30 seconds before checking again\n",
        "\n",
        "if status == \"succeeded\":\n",
        "    print(\" Fine-tuning completed! Model ID:\", job_details.fine_tuned_model)\n",
        "else:\n",
        "    print(\" Fine-tuning failed. Check events for details.\")\n"
      ],
      "metadata": {
        "id": "XYiikdF4bcVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating using new model"
      ],
      "metadata": {
        "id": "coDp5s5JW9hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting fine_tune_model name"
      ],
      "metadata": {
        "id": "8kIgum1SWpBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "response\n"
      ],
      "metadata": {
        "id": "LfWJMV59TC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Job ID: {response.id}\")\n",
        "print(f\"Base Model: {response.model}\")\n",
        "print(f\"Status: {response.status}\")\n",
        "print(f\"Created at: {response.created_at}\")\n",
        "print(f\"Updated at: {response.updated_at}\")\n",
        "print(f\"Fine-tuned Model: {response.fine_tuned_model}\")\n"
      ],
      "metadata": {
        "id": "2eC-y6HsaRj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model_id = response.fine_tuned_model\n",
        "print(\" Fine-tuned model ID:\", fine_tune_model_id)\n",
        "\n"
      ],
      "metadata": {
        "id": "QHTrk_N9UA1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = []\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "test_message = \"How are you today Samantha?\""
      ],
      "metadata": {
        "id": "XBZJrzBoavyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_version=\"2024-05-01-preview\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=fine_tune_model_id,  # your fine-tuned model ID\n",
        "    messages=test_messages\n",
        ")\n",
        "\n",
        "assistant_reply = response.choices[0].message[\"content\"]\n",
        "print(\" Samantha:\", assistant_reply)\n"
      ],
      "metadata": {
        "id": "GMYurdVvacnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "# Initialize Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    api_version=\"2024-05-01-preview\"\n",
        ")\n",
        "\n",
        "# Test conversation\n",
        "test_messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": \"How are you today Samantha?\"}\n",
        "]\n",
        "\n",
        "# Get response from fine-tuned model\n",
        "response = client.chat.completions.create(\n",
        "    model=fine_tune_model_id,\n",
        "    messages=test_messages\n",
        ")\n",
        "\n",
        "# Print assistant reply\n",
        "assistant_reply = response.choices[0].message[\"content\"]\n",
        "print(\" Samantha:\", assistant_reply)\n"
      ],
      "metadata": {
        "id": "k0pHGcuVW7wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNp0RGwyY9pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}