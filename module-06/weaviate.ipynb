{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCMkgM8suSgb",
        "outputId": "bec10d81-539f-4520-874a-1e5245605c37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting weaviate\n",
            "  Downloading weaviate-0.1.2-py3-none-any.whl.metadata (296 bytes)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Collecting validators<1.0.0,>=0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (1.6.5)\n",
            "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (1.76.0)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (5.29.5)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from weaviate-client)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation<3.0.0,>=2.1.0->weaviate-client) (25.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.23)\n",
            "Downloading weaviate-0.1.2-py3-none-any.whl (2.6 kB)\n",
            "Downloading weaviate_client-4.17.0-py3-none-any.whl (582 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m582.8/582.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: weaviate, validators, deprecation, weaviate-client\n",
            "Successfully installed deprecation-2.1.0 validators-0.35.0 weaviate-0.1.2 weaviate-client-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate openai weaviate-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CtYPmHHHVE-l"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "#import os\n",
        "#import requests\n",
        "#import json\n",
        "#import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lCOKSGnxECu",
        "outputId": "47941127-e9f6-44b1-8bdc-46f2a6acbd9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://frjipbt6qtgn1jge3dq7w.c0.asia-southeast1.gcp.weaviate.cloud\n",
            "ZmNLUXRFaU8zRFhUNm16Ql9lY2swSW1RbGVERks0N2dlbnZjblN5U0RTTHNpaUV4K29kWFhPcDJqemlRPV92MjAw\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "WEAVIATE_URL= userdata.get('WEAVIATE_URL')\n",
        "WEAVIATE_API_KEY = userdata.get('WEAVIATE_API_KEY')\n",
        "print(WEAVIATE_URL)\n",
        "print(WEAVIATE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly9DiVHez5im",
        "outputId": "93efba4a-ecc4-4235-ead9-a64be28e04d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: weaviate-client\n",
            "Version: 4.17.0\n",
            "Summary: A python native Weaviate client\n",
            "Home-page: https://github.com/weaviate/weaviate-python-client\n",
            "Author: Weaviate\n",
            "Author-email: hello@weaviate.io,\n",
            "License: BSD 3-clause\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: authlib, deprecation, grpcio, httpx, protobuf, pydantic, validators\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show weaviate-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeveJkI0vXtc",
        "outputId": "53f68e8f-e56c-4769-800e-7aa354e0e1ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "from weaviate.auth import Auth # Corrected import path\n",
        "# Connect to Weaviate Cloud\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_URL,\n",
        "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
        ")\n",
        "\n",
        "print(client.is_ready())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoMUGF-qgxSq",
        "outputId": "c8f4095f-67ea-413c-aeb4-615663f3bba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Movie': _CollectionConfig(name='Movie', description='Collection of movies with Azure OpenAI embeddings', generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={}), _Property(name='description', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={}), _Property(name='director', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'default': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.NONE: 'none'>, model={}, source_properties=None), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))}), 'MyCollection': _CollectionConfig(name='MyCollection', description='MyCollection', generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='mycolection_id', description=None, data_type=<DataType.INT: 'int'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-weaviate': _PropertyVectorizerConfig(skip=False, vectorize_property_name=True)}), _Property(name='hgkjh', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer=None, vectorizer_configs={'text2vec-weaviate': _PropertyVectorizerConfig(skip=False, vectorize_property_name=True)})], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=None, vector_index_type=None, vectorizer_config=None, vectorizer=None, vector_config={'default': _NamedVectorConfig(vectorizer=_NamedVectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseURL': 'https://api.embedding.weaviate.io', 'dimensions': 1024, 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right', 'vectorizeClassName': False}, source_properties=None), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000))})}\n"
          ]
        }
      ],
      "source": [
        "response = client.collections.list_all(simple=False)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xlNrBbiGg8rj"
      },
      "outputs": [],
      "source": [
        "client.collections.delete_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2kEGrLphBUi",
        "outputId": "e445de37-fb34-4bab-b8d8-97d8f516b86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{}\n"
          ]
        }
      ],
      "source": [
        "response = client.collections.list_all(simple=False)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgpK6J4rVw7W",
        "outputId": "aa18082c-8bf6-4d68-95be-081bb6fa234c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection 'Article' created successfully!\n"
          ]
        }
      ],
      "source": [
        "from weaviate.classes.config import Property, DataType, Configure\n",
        "\n",
        "client.collections.create(\n",
        "    name=\"Article\",\n",
        "    description=\"A collection of news articles for semantic search\",\n",
        "    vectorizer_config=Configure.Vectorizer.text2vec_openai(),  # Uses OpenAI embeddings\n",
        "    properties=[\n",
        "        Property(name=\"title\", data_type=DataType.TEXT),\n",
        "        Property(name=\"content\", data_type=DataType.TEXT),\n",
        "        Property(name=\"url\", data_type=DataType.TEXT),\n",
        "    ]\n",
        ")\n",
        "print(\"Collection 'Article' created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHg18FTtN_Ia",
        "outputId": "4d93f545-99aa-460c-fba0-26302ba965ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Article': _CollectionConfig(name='Article', description='A collection of news articles for semantic search', generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='content', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='url', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'isAzure': False, 'model': 'text-embedding-3-small'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None)}\n"
          ]
        }
      ],
      "source": [
        "response = client.collections.list_all(simple=False)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QcOB3t_FM4vn"
      },
      "outputs": [],
      "source": [
        "# collection_name can be a string (\"Article\") or a list of strings ([\"Article\", \"Category\"])\n",
        "collection_name = \"Article\"\n",
        "\n",
        "# THIS WILL DELETE THE SPECIFIED COLLECTION(S) AND THEIR OBJECTS\n",
        "client.collections.delete(\n",
        "    collection_name\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rscUS38hYff_",
        "outputId": "dccc7115-2fde-4146-fcd0-d8f028ff5c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Collection 'Movie' created successfully using text2vec-weaviate + Snowflake model!\n",
            "‚úÖ Data inserted successfully using Weaviate‚Äôs internal Snowflake embedding model!\n"
          ]
        }
      ],
      "source": [
        "from weaviate import WeaviateClient\n",
        "from weaviate.classes.config import Property, DataType, Configure\n",
        "\n",
        "\n",
        "# --- Create collection using text2vec-weaviate and Snowflake model ---\n",
        "client.collections.create(\n",
        "    name=\"Movie\",\n",
        "    description=\"This collection contains all my data.\",\n",
        "    multi_tenancy_config=Configure.multi_tenancy(enabled=False),\n",
        "\n",
        "    vectorizer_config=Configure.Vectorizer.text2vec_weaviate(\n",
        "        model=\"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
        "        vectorize_collection_name=True  # includes collection name in embeddings\n",
        "    ),\n",
        "\n",
        "\n",
        "\n",
        "    properties=[\n",
        "        Property(name=\"name\", data_type=DataType.TEXT),\n",
        "        Property(name=\"movie\", data_type=DataType.TEXT),\n",
        "        Property(name=\"description\", data_type=DataType.TEXT),\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"Collection 'Movie' created successfully using text2vec-weaviate + Snowflake model!\")\n",
        "\n",
        "# --- Access the collection ---\n",
        "collection = client.collections.get(\"Movie\")\n",
        "\n",
        "# --- Example insert data ---\n",
        "movies = [\n",
        "    {\n",
        "        \"name\": \"Christopher Nolan\",\n",
        "        \"movie\": \"Inception\",\n",
        "        \"description\": \"A skilled thief enters dreams to steal secrets and plant ideas.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Denis Villeneuve\",\n",
        "        \"movie\": \"Dune\",\n",
        "        \"description\": \"A young nobleman becomes the leader of a desert planet‚Äôs people.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for item in movies:\n",
        "    collection.data.insert(properties=item)\n",
        "\n",
        "print(\"Data inserted successfully using Weaviate‚Äôs internal Snowflake embedding model!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq3oIB9ZYuDn",
        "outputId": "5039a6ff-f6b4-4b3a-fea0-81be28484447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé¨ Movie: Inception\n",
            "üß† Description: A skilled thief enters dreams to steal secrets and plant ideas.\n",
            "üîπ Distance: (not returned by server)\n",
            "-----\n",
            "üé¨ Movie: Dune\n",
            "üß† Description: A young nobleman becomes the leader of a desert planet‚Äôs people.\n",
            "üîπ Distance: (not returned by server)\n",
            "-----\n"
          ]
        }
      ],
      "source": [
        "# Example: Semantic search\n",
        "query_text = \"movies involving dreams and subconscious worlds\"\n",
        "\n",
        "response = collection.query.near_text(\n",
        "    query=query_text,\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "for obj in response.objects:\n",
        "    movie = obj.properties.get(\"movie\")\n",
        "    desc = obj.properties.get(\"description\")\n",
        "    distance = getattr(obj.metadata, \"distance\", None)\n",
        "\n",
        "    print(f\"Movie: {movie}\")\n",
        "    print(f\"Description: {desc}\")\n",
        "\n",
        "    if distance is not None:\n",
        "        print(f\"üîπ Distance: {distance:.4f}\")\n",
        "    else:\n",
        "        print(\"üîπ Distance: (not returned by server)\")\n",
        "\n",
        "    print(\"-----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DhK8_PUWSZ-"
      },
      "outputs": [],
      "source": [
        "client.collections.delete_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN6p6Fpz0Agl"
      },
      "source": [
        "Schema Example\n",
        " {\n",
        "  \"classes\": [\n",
        "    {\n",
        "      \"class\": \"Article\",\n",
        "      \"description\": \"A collection of news articles\",\n",
        "      \"vectorizer\": \"text2vec-openai\",\n",
        "      \"properties\": [\n",
        "        { \"name\": \"title\", \"dataType\": [\"text\"] },\n",
        "        { \"name\": \"content\", \"dataType\": [\"text\"] },\n",
        "        { \"name\": \"url\", \"dataType\": [\"string\"] }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1jqhD6oXzDwZ"
      },
      "outputs": [],
      "source": [
        "articles = [\n",
        "    {\"title\": \"AI in Healthcare\", \"content\": \"AI assists doctors in diagnosis.\", \"url\": \"https://example.com/ai-healthcare\"},\n",
        "    {\"title\": \"Edge Computing Trends\", \"content\": \"Edge computing improves latency and privacy.\", \"url\": \"https://example.com/edge\"},\n",
        "    {\"title\": \"Fog vs Cloud\", \"content\": \"Fog computing bridges cloud and edge devices.\", \"url\": \"https://example.com/fog\"},\n",
        "    {\"title\": \"Machine Learning Basics\", \"content\": \"ML enables systems to learn from data.\", \"url\": \"https://example.com/ml\"},\n",
        "    {\"title\": \"Natural Language Processing\", \"content\": \"NLP powers chatbots and language models.\", \"url\": \"https://example.com/nlp\"},\n",
        "    {\"title\": \"Computer Vision\", \"content\": \"AI helps detect objects in real-time.\", \"url\": \"https://example.com/cv\"},\n",
        "    {\"title\": \"AI Ethics\", \"content\": \"Ethical AI ensures fairness and transparency.\", \"url\": \"https://example.com/ethics\"},\n",
        "    {\"title\": \"Generative AI\", \"content\": \"GenAI creates new text, images, and music.\", \"url\": \"https://example.com/genai\"},\n",
        "    {\"title\": \"IoT and AI\", \"content\": \"AI enhances IoT data analysis and automation.\", \"url\": \"https://example.com/iot-ai\"},\n",
        "    {\"title\": \"Autonomous Drones\", \"content\": \"AI enables drones to navigate and map terrain.\", \"url\": \"https://example.com/drones\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xlRH0vobPSWW"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
        "DEPLOYMENT_NAME = userdata.get('DEPLOYMENT_NAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg1urVQmPfRw",
        "outputId": "06ff7e20-c5bf-4efd-f2ce-35c28e65855d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x7b2c58a56ea0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.collections.create(\n",
        "    name=\"Article\",\n",
        "    vectorizer_config=weaviate.classes.config.Configure.Vectorizer.text2vec_openai(\n",
        "\n",
        "        model=\"text-embedding-3-small\"\n",
        "    ),\n",
        "    properties=[\n",
        "        Property(name=\"title\", data_type=DataType.TEXT),\n",
        "        Property(name=\"content\", data_type=DataType.TEXT),\n",
        "        Property(name=\"author\", data_type=DataType.TEXT),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkBfQS6oPp7c",
        "outputId": "85466e75-24a0-4496-82b8-d17823eb6c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Article': _CollectionConfigSimple(name='Article', description=None, generative_config=None, properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='content', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='author', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None)], references=[], reranker_config=None, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'isAzure': False, 'model': 'text-embedding-3-small'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None), 'Movie': _CollectionConfigSimple(name='Movie', description='This collection contains all my data.', generative_config=None, properties=[_Property(name='name', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None), _Property(name='movie', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None), _Property(name='description', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None)], references=[], reranker_config=None, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseURL': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, vector_config=None)}\n"
          ]
        }
      ],
      "source": [
        "collections = client.collections.list_all()\n",
        "print(collections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ffH7PS1SP6hG"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "embedding_client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=\"2024-02-01\"  # Confirm your API version in Azure portal\n",
        ")\n",
        "\n",
        "EMBED_MODEL = \"text-embedding-3-small\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LJ3HKqJHzIx4"
      },
      "outputs": [],
      "source": [
        "collection = client.collections.get(\"Article\")\n",
        "\n",
        "# Generate and insert\n",
        "for article in articles:\n",
        "    vector = embedding_client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=article[\"content\"]\n",
        "    ).data[0].embedding\n",
        "\n",
        "    collection.data.insert(properties=article, vector=vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbzZzizVQou8",
        "outputId": "dcdcde1a-9260-4010-b962-aa4d27f538a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîé Top matches:\n",
            "- AI Ethics: Ethical AI ensures fairness and transparency....\n",
            "- AI in Healthcare: AI assists doctors in diagnosis....\n",
            "- Computer Vision: AI helps detect objects in real-time....\n"
          ]
        }
      ],
      "source": [
        "query = \"fight with courage and persistence\"\n",
        "query_vector = embedding_client.embeddings.create(\n",
        "    model=EMBED_MODEL,\n",
        "    input=query\n",
        ").data[0].embedding\n",
        "\n",
        "results = collection.query.near_vector(query_vector, limit=3)\n",
        "\n",
        "print(\"\\n Top matches:\")\n",
        "for obj in results.objects:\n",
        "    print(f\"- {obj.properties['title']}: {obj.properties['content'][:60]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Iq_33RwRRPy2"
      },
      "outputs": [],
      "source": [
        "from weaviate.classes.config import Property, DataType\n",
        "\n",
        "articles = client.collections.use(\"Article\")\n",
        "\n",
        "articles.config.add_property(Property(name=\"onHomepage\", data_type=DataType.BOOL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANcNmU4PRS_H",
        "outputId": "24ee9074-6c36-4f97-88c5-a814178bd82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_CollectionConfig(name='Article', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='content', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='author', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='url', description=\"This property was generated by Weaviate's auto-schema feature on Thu Oct 30 05:16:33 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='onHomepage', description=None, data_type=<DataType.BOOL: 'boolean'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'isAzure': False, 'model': 'text-embedding-3-small'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None)\n"
          ]
        }
      ],
      "source": [
        "articles = client.collections.use(\"Article\")\n",
        "articles_config = articles.config.get()\n",
        "\n",
        "print(articles_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBKPRzlFRj8a",
        "outputId": "4002d095-fc0a-4696-8ccc-91679243dca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Article': _CollectionConfig(name='Article', description=None, generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='content', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='author', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='url', description=\"This property was generated by Weaviate's auto-schema feature on Thu Oct 30 05:16:33 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-openai', vectorizer_configs=None), _Property(name='onHomepage', description=None, data_type=<DataType.BOOL: 'boolean'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=None, tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-openai', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, model={'baseURL': 'https://api.openai.com', 'isAzure': False, 'model': 'text-embedding-3-small'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_OPENAI: 'text2vec-openai'>, vector_config=None), 'Movie': _CollectionConfig(name='Movie', description='This collection contains all my data.', generative_config=None, inverted_index_config=_InvertedIndexConfig(bm25=_BM25Config(b=0.75, k1=1.2), cleanup_interval_seconds=60, index_null_state=False, index_property_length=False, index_timestamps=False, stopwords=_StopwordsConfig(preset=<StopwordsPreset.EN: 'en'>, additions=None, removals=None)), multi_tenancy_config=_MultiTenancyConfig(enabled=False, auto_tenant_creation=False, auto_tenant_activation=False), properties=[_Property(name='name', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None), _Property(name='movie', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None), _Property(name='description', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=True), vectorizer='text2vec-weaviate', vectorizer_configs=None)], references=[], replication_config=_ReplicationConfig(factor=1, async_enabled=False, deletion_strategy=<ReplicationDeletionStrategy.NO_AUTOMATED_RESOLUTION: 'NoAutomatedResolution'>), reranker_config=None, sharding_config=_ShardingConfig(virtual_per_physical=128, desired_count=1, actual_count=1, desired_virtual_count=128, actual_virtual_count=128, key='_id', strategy='hash', function='murmur3'), vector_index_config=_VectorIndexConfigHNSW(multi_vector=None, quantizer=_RQConfig(bits=8, rescore_limit=20), cleanup_interval_seconds=300, distance_metric=<VectorDistances.COSINE: 'cosine'>, dynamic_ef_min=100, dynamic_ef_max=500, dynamic_ef_factor=8, ef=-1, ef_construction=128, filter_strategy=<VectorFilterStrategy.SWEEPING: 'sweeping'>, flat_search_cutoff=40000, max_connections=32, skip=False, vector_cache_max_objects=1000000000000), vector_index_type=<VectorIndexType.HNSW: 'hnsw'>, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseURL': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, vector_config=None)}\n"
          ]
        }
      ],
      "source": [
        "response = client.collections.list_all(simple=False)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygHcpul9SEty",
        "outputId": "049c3060-44f9-4e59-f1ba-dc3cc11a7460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò Collection Name: Article\n",
            "Properties:\n",
            " - title (text)\n",
            " - content (text)\n",
            " - author (text)\n",
            " - url (text)\n",
            " - onHomepage (boolean)\n",
            "üìò Collection Name: Movie\n",
            "Properties:\n",
            " - name (text)\n",
            " - movie (text)\n",
            " - description (text)\n"
          ]
        }
      ],
      "source": [
        "for col_name, col_config in response.items():\n",
        "    print(f\" Collection Name: {col_config.name}\")\n",
        "    print(\"Properties:\")\n",
        "    for prop in col_config.properties:\n",
        "        print(f\" - {prop.name} ({prop.data_type.value})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tucW8iToSV4K",
        "outputId": "f93544a5-d502-4397-c8dc-8c017aabf385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tTWg4di3otPr': 'READY'}\n"
          ]
        }
      ],
      "source": [
        "from weaviate.classes.config import (\n",
        "    Reconfigure,\n",
        "    VectorFilterStrategy,\n",
        "    ReplicationDeletionStrategy,\n",
        ")\n",
        "\n",
        "# Access the \"Article\" collection\n",
        "articles = client.collections.use(\"Article\")\n",
        "\n",
        "# Optional: update collection metadata\n",
        "articles.config.update(\n",
        "    description=\"An updated collection description.\",\n",
        "    property_descriptions={\n",
        "        \"title\": \"The updated title description for article\",\n",
        "        \"content\": \"The main content of the article\",\n",
        "        \"author\": \"Author of the article\",\n",
        "        \"url\": \"URL of the article\",\n",
        "        \"onHomepage\": \"Whether this article appears on homepage\"\n",
        "    }\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "article_shards = articles.config.update_shards(\n",
        "    status=\"READY\"\n",
        ")\n",
        "\n",
        "\n",
        "print(article_shards)\n",
        "\n",
        "# ============================================\n",
        "# Display collection name and properties\n",
        "# ============================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c16skhGrb_EX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1nOq4Lttbdq3"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "from weaviate.classes.config import Property, DataType, Configure\n",
        "\n",
        "# --- Connect to your hosted Weaviate instance ---\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_URL,   # e.g., https://my-instance.weaviate.network\n",
        "    auth_credentials=weaviate.auth.AuthApiKey(api_key=WEAVIATE_API_KEY)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjkwoCCWcDm2",
        "outputId": "a159943c-5bb6-4f32-cc4a-b8dcd5ccc2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 'Movie' collection created successfully!\n"
          ]
        }
      ],
      "source": [
        "client.collections.create(\n",
        "    name=\"Movie1\",\n",
        "    description=\"A collection of movies for semantic and filtered search.\",\n",
        "\n",
        "    vectorizer_config=Configure.Vectorizer.text2vec_weaviate(\n",
        "        model=\"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
        "        vectorize_collection_name=True\n",
        "    ),\n",
        "\n",
        "\n",
        "    properties=[\n",
        "        Property(name=\"title\", data_type=DataType.TEXT),\n",
        "        Property(name=\"director\", data_type=DataType.TEXT),\n",
        "        Property(name=\"year\", data_type=DataType.INT),\n",
        "        Property(name=\"genre\", data_type=DataType.TEXT),\n",
        "        Property(name=\"description\", data_type=DataType.TEXT),\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"'Movie' collection created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO8ndTDicGYf",
        "outputId": "64e09c70-d733-44db-c459-4d79b9b466e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Sample movie data inserted!\n"
          ]
        }
      ],
      "source": [
        "collection = client.collections.get(\"Movie1\")\n",
        "\n",
        "movies = [\n",
        "    {\n",
        "        \"title\": \"Inception\",\n",
        "        \"director\": \"Christopher Nolan\",\n",
        "        \"year\": 2010,\n",
        "        \"genre\": \"Sci-Fi\",\n",
        "        \"description\": \"A thief who steals secrets through dream-sharing technology.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Interstellar\",\n",
        "        \"director\": \"Christopher Nolan\",\n",
        "        \"year\": 2014,\n",
        "        \"genre\": \"Sci-Fi\",\n",
        "        \"description\": \"A team travels through a wormhole to save humanity.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Dark Knight\",\n",
        "        \"director\": \"Christopher Nolan\",\n",
        "        \"year\": 2008,\n",
        "        \"genre\": \"Action\",\n",
        "        \"description\": \"Batman faces the Joker, a criminal mastermind.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Dune\",\n",
        "        \"director\": \"Denis Villeneuve\",\n",
        "        \"year\": 2021,\n",
        "        \"genre\": \"Adventure\",\n",
        "        \"description\": \"A young nobleman becomes the leader of a desert planet‚Äôs people.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for movie in movies:\n",
        "    collection.data.insert(properties=movie)\n",
        "\n",
        "print(\" Sample movie data inserted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FDreEoIcJUP",
        "outputId": "bf46b16e-c569-4a51-c615-56b660261731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'title': 'Interstellar', 'year': 2014, 'description': 'A team travels through a wormhole to save humanity.', 'director': 'Christopher Nolan', 'genre': 'Sci-Fi'}\n",
            "{'title': 'The Dark Knight', 'year': 2008, 'description': 'Batman faces the Joker, a criminal mastermind.', 'director': 'Christopher Nolan', 'genre': 'Action'}\n",
            "{'title': 'Dune', 'year': 2021, 'description': 'A young nobleman becomes the leader of a desert planet‚Äôs people.', 'director': 'Denis Villeneuve', 'genre': 'Adventure'}\n",
            "{'title': 'Inception', 'year': 2010, 'description': 'A thief who steals secrets through dream-sharing technology.', 'director': 'Christopher Nolan', 'genre': 'Sci-Fi'}\n"
          ]
        }
      ],
      "source": [
        "response = collection.query.fetch_objects(limit=10)\n",
        "for obj in response.objects:\n",
        "    print(obj.properties)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxl3myzTcKz3",
        "outputId": "46dd1361-896d-45b8-83d3-e8cc0d10fe71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé¨ Inception (2010) ‚Äî Christopher Nolan\n",
            "üé¨ Interstellar (2014) ‚Äî Christopher Nolan\n"
          ]
        }
      ],
      "source": [
        "from weaviate.classes.query import Filter\n",
        "\n",
        "# Find movies directed by Christopher Nolan after 2009\n",
        "filter_condition = (\n",
        "    Filter.by_property(\"director\").equal(\"Christopher Nolan\") &\n",
        "    Filter.by_property(\"year\").greater_than(2009)\n",
        ")\n",
        "\n",
        "response = collection.query.fetch_objects(\n",
        "    filters=filter_condition,\n",
        "    limit=5\n",
        ")\n",
        "\n",
        "for obj in response.objects:\n",
        "    print(f\" {obj.properties['title']} ({obj.properties['year']}) ‚Äî {obj.properties['director']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fap7DKAcO3n",
        "outputId": "e3cd577e-6f20-4e92-98cf-76de3bcb84db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Updated movie ID: 141089f2-2da7-4fcd-8c2a-777106ca0296\n"
          ]
        }
      ],
      "source": [
        "# Get one object to update\n",
        "response = collection.query.fetch_objects(limit=1)\n",
        "movie_id = response.objects[0].uuid\n",
        "\n",
        "# Update description\n",
        "collection.data.update(\n",
        "    uuid=movie_id,\n",
        "    properties={\"description\": \"Updated: A thief enters dreams to alter reality itself.\"}\n",
        ")\n",
        "\n",
        "print(f\" Updated movie ID: {movie_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5_2il5ocQjv",
        "outputId": "5a6bfd83-e71e-4beb-e4cf-2c560919fbb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è Deleted object 141089f2-2da7-4fcd-8c2a-777106ca0296\n"
          ]
        }
      ],
      "source": [
        "# Delete a single object by UUID\n",
        "\n",
        "collection.data.delete_by_id(uuid=movie_id)\n",
        "print(f\" Deleted object {movie_id}\")\n",
        "\n",
        "# Delete entire collection (careful!)\n",
        "# client.collections.delete(\"Movie\")\n",
        "# print(\" Collection 'Movie' deleted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP7sFxxUcaDn",
        "outputId": "e0ac50e4-9e8a-453c-f3df-b7b3a7461cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Semantic Search Results:\n",
            "- Inception: A thief who steals secrets through dream-sharing technology.\n",
            "-----\n",
            "- Dune: A young nobleman becomes the leader of a desert planet‚Äôs people.\n",
            "-----\n",
            "- The Dark Knight: Batman faces the Joker, a criminal mastermind.\n",
            "-----\n"
          ]
        }
      ],
      "source": [
        "query_text = \"movies about dreams and alternate realities\"\n",
        "\n",
        "response = collection.query.near_text(\n",
        "    query=query_text,\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(\" Semantic Search Results:\")\n",
        "for obj in response.objects:\n",
        "    movie = obj.properties.get(\"title\")\n",
        "    desc = obj.properties.get(\"description\")\n",
        "    distance = getattr(obj.metadata, \"distance\", None)\n",
        "    print(f\"- {movie}: {desc}\")\n",
        "    if distance is not None:\n",
        "        print(f\"  üîπ Similarity distance: {distance:.4f}\")\n",
        "    print(\"-----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bE0hHclcbjf",
        "outputId": "fabc7ae1-c6a7-4313-e1f8-2941c82253a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî§ Keyword Search Results:\n",
            "- Inception: A thief who steals secrets through dream-sharing technology.\n"
          ]
        }
      ],
      "source": [
        "response = collection.query.bm25(\n",
        "    query=\"dream technology\",\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(\" Keyword Search Results:\")\n",
        "for obj in response.objects:\n",
        "    print(f\"- {obj.properties['title']}: {obj.properties['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeBapp0Bcd6Y",
        "outputId": "e850eb02-2471-4a24-b0e2-460e553550ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåó Hybrid Search Results:\n",
            "- Inception: A thief who steals secrets through dream-sharing technology.\n",
            "- Dune: A young nobleman becomes the leader of a desert planet‚Äôs people.\n",
            "- The Dark Knight: Batman faces the Joker, a criminal mastermind.\n"
          ]
        }
      ],
      "source": [
        "response = collection.query.hybrid(\n",
        "    query=\"dream world and time travel\",\n",
        "    alpha=0.5,  # 0 = pure keyword, 1 = pure semantic\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(\" Hybrid Search Results:\")\n",
        "for obj in response.objects:\n",
        "    print(f\"- {obj.properties['title']}: {obj.properties['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDUhTQNUezVh",
        "outputId": "1fb082f8-9934-4c9f-eb32-e27d8a868d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.14.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-llms-azure-openai\n",
            "  Downloading llama_index_llms_azure_openai-0.4.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-embeddings-azure-openai\n",
            "  Downloading llama_index_embeddings_azure_openai-0.4.1-py3-none-any.whl.metadata (503 bytes)\n",
            "Collecting llama-index-vector-stores-weaviate\n",
            "  Downloading llama_index_vector_stores_weaviate-1.4.1-py3-none-any.whl.metadata (427 bytes)\n",
            "Requirement already satisfied: weaviate-client in /usr/local/lib/python3.12/dist-packages (4.17.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.6 (from llama-index)\n",
            "  Downloading llama_index_core-0.14.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.6.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Collecting azure-identity<2,>=1.15.0 (from llama-index-llms-azure-openai)\n",
            "  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-azure-openai) (0.28.1)\n",
            "Requirement already satisfied: validators<1.0.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (0.35.0)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (1.6.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (2.11.10)\n",
            "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (1.76.0)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (5.29.5)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (2.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Collecting azure-core>=1.31.0 (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai)\n",
            "  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal>=1.30.0 (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai)\n",
            "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity<2,>=1.15.0->llama-index-llms-azure-openai)\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation<3.0.0,>=2.1.0->weaviate-client) (25.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-llms-azure-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-llms-azure-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (3.13.1)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading deprecated-1.3.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (2025.3.0)\n",
            "Collecting llama-index-workflows<3,>=2 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading llama_index_workflows-2.9.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (2.32.4)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.6->llama-index) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (0.12.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.6->llama-index) (2.0.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.6->llama-index) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.6->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.0.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<3,>=2->llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2,>=1.15.0->llama-index-llms-azure-openai) (2.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.6->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.6->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.6->llama-index) (3.2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.23)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.6->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.6->llama-index) (3.0.3)\n",
            "Downloading llama_index-0.14.6-py3-none-any.whl (7.4 kB)\n",
            "Downloading llama_index_llms_azure_openai-0.4.2-py3-none-any.whl (7.3 kB)\n",
            "Downloading llama_index_embeddings_azure_openai-0.4.1-py3-none-any.whl (4.4 kB)\n",
            "Downloading llama_index_vector_stores_weaviate-1.4.1-py3-none-any.whl (9.3 kB)\n",
            "Downloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m191.3/191.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.6-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.6-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading azure_core-1.36.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.9.1-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, wrapt, setuptools, pypdf, mypy-extensions, marshmallow, colorama, aiosqlite, typing-inspect, griffe, deprecated, azure-core, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, msal, llama-index-workflows, msal-extensions, llama-index-core, llama-index-vector-stores-weaviate, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, azure-identity, llama-parse, llama-index-llms-azure-openai, llama-index-cli, llama-index-readers-llama-parse, llama-index-embeddings-azure-openai, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 azure-core-1.36.0 azure-identity-1.25.1 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.14.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.6 llama-index-cli-0.5.3 llama-index-core-0.14.6 llama-index-embeddings-azure-openai-0.4.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-azure-openai-0.4.2 llama-index-llms-openai-0.6.6 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-vector-stores-weaviate-1.4.1 llama-index-workflows-2.9.1 llama-parse-0.6.54 marshmallow-3.26.1 msal-1.34.0 msal-extensions-1.3.1 mypy-extensions-1.1.0 pypdf-6.1.3 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0 wrapt-1.17.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e4fd0c73a5dd4480a5927d7c57124b51",
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install llama-index llama-index-llms-azure-openai llama-index-embeddings-azure-openai llama-index-vector-stores-weaviate weaviate-client openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SMkkYxEvgwDJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
        "DEPLOYMENT_NAME = userdata.get('DEPLOYMENT_NAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZGJaBWn7g6zT"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core import Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kC41Kdmug8nc"
      },
      "outputs": [],
      "source": [
        "llm = AzureOpenAI(\n",
        "    model=DEPLOYMENT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=\"2023-05-15\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X6g7A-rvhEE9"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "\n",
        "# ====== Step 1: Initialize Azure OpenAI embedding model ======\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-3-small\",  # model type\n",
        "    deployment_name=\"text-embedding-3-small\",\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=\"2023-05-15\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Vb1kZIDThH_H"
      },
      "outputs": [],
      "source": [
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Q8Kbt4h1S3",
        "outputId": "800a23de-4e27-4ecd-fb30-86fd56e9eedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://frjipbt6qtgn1jge3dq7w.c0.asia-southeast1.gcp.weaviate.cloud\n",
            "ZmNLUXRFaU8zRFhUNm16Ql9lY2swSW1RbGVERks0N2dlbnZjblN5U0RTTHNpaUV4K29kWFhPcDJqemlRPV92MjAw\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "WEAVIATE_URL= userdata.get('WEAVIATE_URL')\n",
        "WEAVIATE_API_KEY = userdata.get('WEAVIATE_API_KEY')\n",
        "print(WEAVIATE_URL)\n",
        "print(WEAVIATE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TO3H69Cisvw",
        "outputId": "63c9f4e6-6b10-4e0a-99ed-fec5a382013b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Connected to Weaviate\n",
            "‚úÖ Collection 'Movie' created successfully!\n",
            "‚úÖ Sample movie data inserted successfully!\n",
            "\n",
            "üé¨ Top Similar Movies:\n",
            "- Inception: A thief enters people's dreams to steal secrets and plant ideas.\n",
            "- The Matrix: A hacker discovers reality is a simulation controlled by machines.\n",
            "- Interstellar: Astronauts travel through a wormhole to find a new home for humanity.\n",
            "\n",
            "‚úÖ Done.\n"
          ]
        }
      ],
      "source": [
        "# create_weaviate_collection_azure_embeddings.py\n",
        "import os\n",
        "import weaviate\n",
        "from weaviate import auth\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# -----------------------------\n",
        "#  Azure OpenAI Config\n",
        "# -----------------------------\n",
        "\n",
        "AZURE_OPENAI_EMBED_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBED_DEPLOYMENT\", \"text-embedding-3-small\")\n",
        "AZURE_OPENAI_API_VERSION = \"2024-08-01-preview\"\n",
        "\n",
        "embedding_client = AzureOpenAI(\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    api_version=AZURE_OPENAI_API_VERSION,\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "#  Weaviate Config\n",
        "# -----------------------------\n",
        "\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_URL,\n",
        "    auth_credentials=auth.AuthApiKey(api_key=WEAVIATE_API_KEY),\n",
        ")\n",
        "\n",
        "assert client.is_ready(), \"‚ùå Weaviate not connected!\"\n",
        "print(\" Connected to Weaviate\")\n",
        "\n",
        "# -----------------------------\n",
        "#  Create a New Collection\n",
        "# -----------------------------\n",
        "COLLECTION_NAME = \"Movie\"\n",
        "\n",
        "\n",
        "\n",
        "# Create schema manually (since embeddings come from Azure, not Weaviate)\n",
        "client.collections.create(\n",
        "    name=COLLECTION_NAME,\n",
        "    description=\"Collection of movies with Azure OpenAI embeddings\",\n",
        "    vectorizer_config=None,  # we supply embeddings manually\n",
        "    properties=[\n",
        "        weaviate.classes.config.Property(name=\"title\", data_type=weaviate.classes.config.DataType.TEXT),\n",
        "        weaviate.classes.config.Property(name=\"description\", data_type=weaviate.classes.config.DataType.TEXT),\n",
        "        weaviate.classes.config.Property(name=\"director\", data_type=weaviate.classes.config.DataType.TEXT),\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(f\" Collection '{COLLECTION_NAME}' created successfully!\")\n",
        "\n",
        "collection = client.collections.get(COLLECTION_NAME)\n",
        "\n",
        "# -----------------------------\n",
        "#  Insert Data with Azure Embeddings\n",
        "# -----------------------------\n",
        "movies = [\n",
        "    {\n",
        "        \"title\": \"Inception\",\n",
        "        \"description\": \"A thief enters people's dreams to steal secrets and plant ideas.\",\n",
        "        \"director\": \"Christopher Nolan\",\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Matrix\",\n",
        "        \"description\": \"A hacker discovers reality is a simulation controlled by machines.\",\n",
        "        \"director\": \"Lana Wachowski\",\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Interstellar\",\n",
        "        \"description\": \"Astronauts travel through a wormhole to find a new home for humanity.\",\n",
        "        \"director\": \"Christopher Nolan\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for movie in movies:\n",
        "    text_for_embedding = f\"{movie['title']} - {movie['description']}\"\n",
        "    embedding = (\n",
        "        embedding_client.embeddings.create(\n",
        "            model=AZURE_OPENAI_EMBED_DEPLOYMENT,\n",
        "            input=text_for_embedding\n",
        "        )\n",
        "        .data[0]\n",
        "        .embedding\n",
        "    )\n",
        "    collection.data.insert(properties=movie, vector=embedding)\n",
        "\n",
        "print(\" Sample movie data inserted successfully!\")\n",
        "\n",
        "# -----------------------------\n",
        "#  Query by Similarity\n",
        "# -----------------------------\n",
        "query_text = \"movie about exploring dreams and reality\"\n",
        "query_embedding = (\n",
        "    embedding_client.embeddings.create(\n",
        "        model=AZURE_OPENAI_EMBED_DEPLOYMENT,\n",
        "        input=query_text\n",
        "    )\n",
        "    .data[0]\n",
        "    .embedding\n",
        ")\n",
        "\n",
        "results = collection.query.near_vector(\n",
        "    near_vector=query_embedding,\n",
        "    limit=3,\n",
        ")\n",
        "\n",
        "print(\"\\n Top Similar Movies:\")\n",
        "for obj in results.objects:\n",
        "    title = obj.properties.get(\"title\")\n",
        "    desc = obj.properties.get(\"description\")\n",
        "    print(f\"- {title}: {desc}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNY-A0t0hgXr",
        "outputId": "a3d29f92-c544-441b-82d1-c4daeb52c1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LlamaIndex connected to Weaviate collection successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
        "\n",
        "\n",
        "#  Wrap the Weaviate collection as a VectorStore\n",
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client=client,\n",
        "    index_name=COLLECTION_NAME,\n",
        ")\n",
        "\n",
        "#  Create StorageContext (still valid)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# -----------------------------\n",
        "#  Build LlamaIndex from the existing Weaviate collection\n",
        "# -----------------------------\n",
        "# Note: No 'service_context' parameter ‚Äî use global Settings instead\n",
        "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
        "\n",
        "print(\" LlamaIndex connected to Weaviate collection successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE8dgs3rjps9",
        "outputId": "1c06520e-cb35-4dbd-a408-ed9349372a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üé¨ **RAG Response:**\n",
            "The movie about artificial intelligence is \"The Matrix,\" directed by Lana Wachowski.\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "#  Create RAG Query Engine\n",
        "# -----------------------------\n",
        "query_engine = index.as_query_engine(similarity_top_k=5)\n",
        "\n",
        "# -----------------------------\n",
        "#  Ask a Question (RAG)\n",
        "# -----------------------------\n",
        "question = \"List the movies about artificial intelligence and their directors.\"\n",
        "response = query_engine.query(question)\n",
        "\n",
        "print(\"\\n **RAG Response:**\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A_Z2PCykHVe"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "#  Apply Metadata Filter (WHERE)\n",
        "# -----------------------------\n",
        "where_filter = {\n",
        "    \"path\": [\"director\"],\n",
        "    \"operator\": \"Equal\",\n",
        "    \"valueString\": \"Christopher Nolan\",\n",
        "}\n",
        "\n",
        "# Create a retriever with filter\n",
        "retriever = index.as_retriever(\n",
        "    search_kwargs={\n",
        "        \"where\": where_filter,\n",
        "        \"limit\": 3\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "IlJvJtixktXs",
        "outputId": "dec03114-0667-4e22-9e99-16f1e4929349"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "RetrieverQueryEngine.from_args() got multiple values for argument 'retriever'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2469204689.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Wrap retriever into a query engine correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiltered_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_query_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiltered_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Summarize Nolan‚Äôs movies dealing with dreams or altered realities.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiltered_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36mas_query_engine\u001b[0;34m(self, llm, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         )\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         return RetrieverQueryEngine.from_args(\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mretriever\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: RetrieverQueryEngine.from_args() got multiple values for argument 'retriever'"
          ]
        }
      ],
      "source": [
        "# Wrap retriever into a query engine correctly\n",
        "filtered_engine = index.as_query_engine(retriever=retriever)\n",
        "\n",
        "filtered_question = \"Summarize Nolan‚Äôs movies dealing with dreams or altered realities.\"\n",
        "filtered_response = filtered_engine.query(filtered_question)\n",
        "\n",
        "print(\"\\nüé• **Filtered RAG Response:**\")\n",
        "print(filtered_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKqZcPLWktRC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
