{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"opentelemetry-sdk==1.37.0\" \"opentelemetry-exporter-otlp-proto-http==1.37.0\""
      ],
      "metadata": {
        "id": "6XeKyp93hFVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGe4p9zQmarf",
        "outputId": "20fd6822-e7e8-4d8d-9267-9d308bdc8337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install chromadb openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup a client\n",
        "\n",
        "import chromadb\n",
        "client = chromadb.Client()"
      ],
      "metadata": {
        "id": "BH-DvgbPmeT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.heartbeat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tanx7wcKYx85",
        "outputId": "6bd0b31d-bd84-47c3-86b6-1109f34e582c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1761714868580231765"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neo_collection = client.create_collection(name=\"neo\")"
      ],
      "metadata": {
        "id": "O9cyC1x2mm1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspecting a collection\n",
        "print(neo_collection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eyflj87mo7T",
        "outputId": "a92ab030-4f14-41d4-94bd-b62532357039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection(name=neo)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the collection name and inspecting it again\n",
        "neo_collection.modify(name=\"neo_new\")\n",
        "print(neo_collection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--sCj03AmrY0",
        "outputId": "c6651d49-f6b0-469b-ae4c-46ef75f53f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection(name=neo_new)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting items\n",
        "item_count = neo_collection.count()\n",
        "print(f\"# of items in collection: {item_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KyFwFPImt3r",
        "outputId": "459b6947-8c4c-40fd-b86f-96d90e40c75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of items in collection: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance"
      ],
      "metadata": {
        "id": "u9Qr3obJmwdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get or Create a new collection, and change the distance function\n",
        "trinity_collection = client.get_or_create_collection(\n",
        "    name=\"trinity\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "print(trinity_collection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGAUBSUnmwwz",
        "outputId": "58e46bc9-9ad0-4e1b-f701-51cec45b58a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection(name=trinity)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting a collection\n",
        "try:\n",
        "    client.delete_collection(name=\"neo_new\")\n",
        "    print(\"neo_new collection deleted.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8sOjE52m1AL",
        "outputId": "c7bbf84e-93f8-4446-d953-a80d100dab3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neo_new collection deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neo_collection = client.create_collection(name=\"neo\")"
      ],
      "metadata": {
        "id": "CNNjuqSwm3V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding data\n",
        "# Adding raw documents\n",
        "neo_collection.add(\n",
        "    documents=[\n",
        "        \"There is no spoon.\",\n",
        "        \"I know kung fu.\"\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyJeCvLUm5cD",
        "outputId": "eadb143c-860c-4882-d1ac-d8cb3114440c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 76.8MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_count = neo_collection.count()\n",
        "print(f\"Count of items in collection: {item_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mXmy1v8m7fL",
        "outputId": "f8cc16d4-2dea-47e3-81a2-8dbe61c7423e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of items in collection: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neo_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8LlZWyQm9UD",
        "outputId": "e7853069-5734-499c-faa8-def495f4fd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['There is no spoon.', 'I know kung fu.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neo_collection.peek(limit=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dDWWlmQm_6L",
        "outputId": "8bacd072-3a94-4f2a-c325-a75feb3802dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2'],\n",
              " 'embeddings': array([[ 4.50641289e-03, -7.76351690e-02, -3.88775878e-02,\n",
              "         -1.23527283e-02, -8.39507505e-02,  4.84782569e-02,\n",
              "          2.70228963e-02, -8.26054215e-02,  7.58571178e-02,\n",
              "          1.64956041e-02,  3.45768631e-02, -6.97631761e-02,\n",
              "         -1.25152385e-02, -5.83279543e-02, -7.36757442e-02,\n",
              "         -1.22720554e-01, -3.31801139e-02, -1.08264811e-01,\n",
              "         -1.07758781e-02,  2.41387216e-03,  3.13210338e-02,\n",
              "          3.63168801e-04,  5.74709103e-02, -1.93405673e-02,\n",
              "          6.21309243e-02,  5.51330745e-02,  1.94749702e-02,\n",
              "         -6.18175380e-02, -2.54653525e-02,  6.34439811e-02,\n",
              "         -1.93185359e-02, -5.40940138e-03, -8.22466239e-02,\n",
              "         -4.52789366e-02,  3.76525968e-02,  7.05910474e-03,\n",
              "          5.04518896e-02,  4.01081741e-02,  5.01829386e-02,\n",
              "          1.59695391e-02, -6.82597756e-02, -7.21675307e-02,\n",
              "         -5.08137047e-02,  9.78314783e-03,  4.41795252e-02,\n",
              "          3.99049446e-02, -1.12011312e-02, -6.45495206e-02,\n",
              "          4.28408664e-03, -2.81753484e-02, -7.20274821e-02,\n",
              "         -8.58398993e-03, -1.82311349e-02, -1.08255139e-02,\n",
              "          6.20921655e-03, -5.04289987e-03,  9.80745256e-02,\n",
              "          3.54796387e-02, -3.44682746e-02,  8.11851472e-02,\n",
              "         -1.43287620e-02, -1.98971722e-02,  3.30433138e-02,\n",
              "          4.08851802e-02,  2.54308823e-02, -1.15774274e-02,\n",
              "         -6.44761138e-04, -3.17214988e-02, -1.27509432e-02,\n",
              "         -1.97746921e-02, -3.90412770e-02,  4.55965772e-02,\n",
              "          1.02846343e-02,  6.92792088e-02, -7.90532585e-03,\n",
              "         -3.87858339e-02,  1.33977598e-02, -2.40280200e-02,\n",
              "          2.14361995e-02,  1.35503456e-01, -1.16170503e-01,\n",
              "          2.89345719e-02,  9.86916199e-02,  9.32323262e-02,\n",
              "         -9.28720981e-02,  1.71981677e-02, -3.92350834e-03,\n",
              "         -1.24645354e-02, -8.06135610e-02, -4.07521129e-02,\n",
              "         -6.96076974e-02,  5.07096201e-02, -4.66580912e-02,\n",
              "          2.33443957e-02,  4.06968035e-02,  4.04339172e-02,\n",
              "         -1.54821100e-02,  3.92758101e-02, -9.70002189e-02,\n",
              "          9.69608054e-02, -6.12805635e-02,  3.88443209e-02,\n",
              "         -7.27581903e-02,  1.91439353e-02,  5.83796240e-02,\n",
              "          8.92097875e-02, -8.78032297e-03, -7.33417869e-02,\n",
              "         -3.71304005e-02,  1.52872866e-02,  3.57814110e-03,\n",
              "          9.92917269e-03, -1.52493105e-03, -1.29141547e-02,\n",
              "         -1.36762232e-01, -6.54069260e-02, -1.73722692e-02,\n",
              "         -4.91460748e-02, -8.45526233e-02,  1.66720767e-02,\n",
              "         -4.32353280e-03, -8.42415635e-03, -2.24659611e-02,\n",
              "          2.34989934e-02, -5.19415922e-02, -1.17938016e-02,\n",
              "          4.19032052e-02, -6.40367739e-33, -2.75211222e-02,\n",
              "         -7.13742003e-02,  1.18146405e-01, -6.28033355e-02,\n",
              "          2.93425779e-04,  4.57412861e-02,  5.26987687e-02,\n",
              "          3.96176614e-02,  6.97581843e-02,  9.28886002e-04,\n",
              "         -3.78552638e-02, -3.69420312e-02, -3.56224701e-02,\n",
              "         -5.57588860e-02,  4.70947735e-02, -1.44167589e-02,\n",
              "          1.69923641e-02,  4.90727052e-02,  4.31047566e-02,\n",
              "         -2.84967292e-02,  1.32349692e-02,  7.55377263e-02,\n",
              "         -2.46603321e-02, -1.71952285e-02, -9.89691168e-02,\n",
              "          3.21603343e-02, -6.60886569e-03, -3.88880484e-02,\n",
              "         -3.12353075e-02,  1.25006167e-02, -8.22699666e-02,\n",
              "          3.91686475e-03,  4.62271795e-02, -4.75320294e-02,\n",
              "         -5.35316467e-02, -9.94338989e-02, -3.55288349e-02,\n",
              "         -4.09708656e-02, -6.39893264e-02, -3.75071391e-02,\n",
              "         -6.70302510e-02,  2.65220683e-02,  4.12894739e-03,\n",
              "         -1.98621619e-02, -6.79602772e-02,  2.84720100e-02,\n",
              "          3.62334214e-02,  2.14710012e-02, -6.61756322e-02,\n",
              "         -1.89941227e-02,  8.50886852e-02,  3.80186550e-02,\n",
              "          2.17422284e-02,  5.22706546e-02,  4.86778514e-03,\n",
              "         -9.04923677e-03, -1.52323423e-02,  4.65236194e-02,\n",
              "         -5.72703145e-02,  1.53689198e-02, -1.04922997e-02,\n",
              "         -3.60210501e-02, -3.64854261e-02,  3.02918144e-02,\n",
              "         -3.06213312e-02,  5.15261330e-02, -1.27114747e-02,\n",
              "         -1.11507215e-02,  1.12015285e-01, -1.62432455e-02,\n",
              "          5.82630467e-03,  2.34359410e-02,  2.12374795e-02,\n",
              "          6.55781478e-02,  1.74042881e-02, -4.74723428e-02,\n",
              "          1.20975310e-03, -4.01850604e-02,  2.96541117e-02,\n",
              "          7.20214052e-03,  1.54085755e-01, -1.39159849e-02,\n",
              "         -7.49158906e-03, -3.36265303e-02, -1.18341064e-02,\n",
              "          3.79637368e-02, -6.81895018e-02,  2.25975527e-03,\n",
              "          4.57730889e-02,  6.28124969e-03, -9.41527337e-02,\n",
              "         -5.72134256e-02, -1.79078095e-02, -7.12230876e-02,\n",
              "         -8.58869851e-02,  3.65168165e-33,  2.38244794e-02,\n",
              "          3.90236750e-02, -1.08775415e-01,  7.12517723e-02,\n",
              "         -1.80439446e-02,  3.68159823e-02,  4.97386679e-02,\n",
              "         -2.74375838e-04,  4.53381799e-02,  6.16731821e-03,\n",
              "          4.04148810e-02, -1.69600528e-02,  4.18480225e-02,\n",
              "          1.13365548e-02,  2.49284171e-02,  1.20253801e-01,\n",
              "         -1.35170938e-02,  5.86224832e-02, -5.09326207e-03,\n",
              "          5.20934984e-02,  1.26994429e-02,  2.48967819e-02,\n",
              "         -1.43489642e-02, -6.79421201e-02, -6.11050315e-02,\n",
              "          7.95746502e-03, -1.20571200e-02,  1.68859232e-02,\n",
              "         -1.28905296e-01,  3.50276753e-02,  7.12062120e-02,\n",
              "         -8.96097869e-02, -7.64236436e-04, -8.14871639e-02,\n",
              "         -5.12094051e-02,  7.83510227e-03, -2.30561402e-02,\n",
              "         -9.07489881e-02, -6.25344813e-02,  5.54437889e-03,\n",
              "          3.72880213e-02, -2.01561605e-03,  7.21639693e-02,\n",
              "          6.84366450e-02, -2.97898613e-02,  1.94843404e-03,\n",
              "         -5.20437211e-02,  3.54228020e-02,  3.60426158e-02,\n",
              "          6.79057697e-03, -2.25315616e-02, -3.25548882e-03,\n",
              "          8.83965492e-02, -4.68131043e-02,  1.14233531e-02,\n",
              "          1.91256236e-02, -1.96983069e-02, -1.06728531e-01,\n",
              "          1.89795308e-02,  2.00970732e-02,  6.35900646e-02,\n",
              "          7.59528801e-02,  2.11234158e-03,  1.19918570e-01,\n",
              "          8.02087858e-02,  6.53196722e-02, -2.73100697e-02,\n",
              "          1.15475431e-01,  7.32056471e-03, -7.43608922e-02,\n",
              "          5.37995100e-02, -1.35002667e-02,  8.03709850e-02,\n",
              "         -7.60772824e-02,  6.41295314e-02,  1.36736542e-01,\n",
              "         -4.23931889e-02,  5.53591875e-04, -1.58555470e-02,\n",
              "         -6.22484982e-02, -5.38692868e-04, -2.42434163e-03,\n",
              "         -6.52763108e-03, -1.37007760e-03,  1.18711060e-02,\n",
              "         -4.40483242e-02,  3.70415114e-02, -3.05125732e-02,\n",
              "         -2.87464261e-02,  5.57304397e-02, -3.84331420e-02,\n",
              "         -7.30641112e-02,  4.22547124e-02,  6.55288622e-02,\n",
              "          9.32956338e-02, -1.52559139e-08,  1.40885860e-01,\n",
              "          4.47543785e-02,  6.60981834e-02,  1.32561196e-02,\n",
              "         -6.56729192e-03,  3.65132168e-02, -1.99893699e-03,\n",
              "         -3.72042917e-02,  9.91420075e-03,  7.87353143e-02,\n",
              "         -2.40568761e-02,  4.01584022e-02, -8.73477608e-02,\n",
              "          5.17630726e-02, -1.36134587e-02,  2.06630379e-02,\n",
              "          4.12907898e-02, -1.88106131e-02, -4.82174829e-02,\n",
              "         -6.40873704e-03, -4.10524532e-02,  3.37047204e-02,\n",
              "         -1.86663065e-02, -4.14470173e-02,  4.72560041e-02,\n",
              "          4.74703908e-02, -2.85628103e-02,  5.99237233e-02,\n",
              "          1.96958464e-02,  3.16965729e-02,  6.38273060e-02,\n",
              "         -2.06762441e-02,  2.41010683e-03,  8.35490995e-04,\n",
              "         -5.34415171e-02,  1.37853185e-02, -6.52726963e-02,\n",
              "          1.18075661e-01, -2.73203272e-02, -5.62392734e-02,\n",
              "         -7.92121962e-02,  1.31478691e-02,  5.29977493e-03,\n",
              "          1.28489034e-03, -4.42259125e-02,  9.76304337e-02,\n",
              "         -5.61009236e-02,  2.50407625e-02, -8.59240666e-02,\n",
              "          2.58037690e-02,  4.64848615e-02,  1.51296528e-02,\n",
              "          4.98083420e-02,  3.83938253e-02,  1.60111450e-02,\n",
              "          2.04601418e-02,  3.03753037e-02,  6.98856339e-02,\n",
              "         -4.36974363e-03,  5.56881726e-02, -1.02680251e-02,\n",
              "         -6.25720108e-03,  2.56414339e-02,  5.34475455e-03],\n",
              "        [ 4.38504405e-02, -3.08452621e-02, -3.99303921e-02,\n",
              "          6.50981739e-02, -4.27465066e-02,  1.82265826e-02,\n",
              "          8.11956897e-02, -8.98389444e-02,  9.66256484e-03,\n",
              "          6.07054234e-02,  7.88213462e-02, -2.01975182e-02,\n",
              "         -1.40898302e-02,  4.30233479e-02, -2.16736477e-02,\n",
              "         -1.65827386e-02,  9.39194020e-03,  5.16558513e-02,\n",
              "         -3.24004851e-02,  1.37096876e-02, -6.74205571e-02,\n",
              "          8.96612853e-02,  6.69486821e-03,  1.25199752e-02,\n",
              "         -4.50254269e-02, -1.03308829e-02, -7.03784032e-03,\n",
              "         -1.00037083e-02, -5.25311790e-02, -6.17985837e-02,\n",
              "         -1.06247403e-02,  7.33338594e-02, -3.26824151e-02,\n",
              "          3.09545528e-02, -4.12112884e-02, -2.08120309e-02,\n",
              "          3.16710807e-02,  4.19819169e-02, -4.40713614e-02,\n",
              "          1.00080959e-01, -2.41161902e-02,  8.77821520e-02,\n",
              "          7.43516609e-02, -6.60656765e-02,  7.58076310e-02,\n",
              "          3.81304882e-02, -9.24753491e-03, -3.18592489e-02,\n",
              "          6.95269257e-02, -2.38141324e-02, -1.63296552e-03,\n",
              "         -1.72345713e-02, -3.29762101e-02,  6.95230663e-02,\n",
              "          7.06233159e-02, -4.25076634e-02,  7.32465610e-02,\n",
              "          9.89609631e-04, -2.08625458e-02,  6.90217018e-02,\n",
              "         -4.80239391e-02,  6.71091629e-03, -3.33805382e-02,\n",
              "          2.97152158e-03,  3.21824327e-02, -4.98961890e-03,\n",
              "         -1.10582057e-02,  7.16631860e-02, -3.69664952e-02,\n",
              "         -1.58854537e-02,  2.76980922e-03, -1.39933117e-02,\n",
              "         -2.14274088e-03,  6.60245270e-02,  3.10815684e-02,\n",
              "          2.87353639e-02,  9.15875379e-03,  2.27431916e-02,\n",
              "          2.51890421e-02, -7.81441107e-02,  5.88578023e-02,\n",
              "         -1.03179170e-02, -5.44952899e-02,  4.79037501e-03,\n",
              "          9.15058255e-02,  5.77786937e-02, -6.81541339e-02,\n",
              "          3.49680730e-03,  2.48339791e-02,  2.64048605e-04,\n",
              "         -3.90068069e-02,  4.40816693e-02, -5.80802187e-02,\n",
              "          1.71008054e-02, -3.50231826e-02, -1.42683648e-02,\n",
              "         -1.77195240e-02,  4.69785072e-02, -1.05024494e-01,\n",
              "          5.52700981e-02, -6.61943853e-02,  6.66258205e-03,\n",
              "          2.45082695e-02,  1.10908644e-02,  7.51915723e-02,\n",
              "         -1.36070326e-02,  4.35100570e-02,  1.02504110e-02,\n",
              "          5.34369089e-02, -6.05124533e-02, -4.32865880e-02,\n",
              "          1.08872745e-02, -3.86317596e-02,  5.38053457e-03,\n",
              "          9.09563676e-02,  7.18365088e-02,  9.19439197e-02,\n",
              "         -1.30426129e-02, -7.88936242e-02, -5.60626527e-03,\n",
              "          4.61664312e-02,  9.43336636e-04, -1.75023396e-02,\n",
              "         -9.88565013e-03, -3.99162658e-02, -1.04333088e-01,\n",
              "          2.27436405e-02, -6.79999531e-33,  6.68231100e-02,\n",
              "         -6.08197413e-02,  8.90622437e-02,  2.10728142e-02,\n",
              "         -4.59431810e-03, -1.03818387e-01,  3.29665728e-02,\n",
              "         -9.00871828e-02, -1.68306921e-02,  9.41516981e-02,\n",
              "          6.18627891e-02, -9.14686639e-03, -8.36421624e-02,\n",
              "          2.65930668e-02,  7.09618852e-02,  5.94379231e-02,\n",
              "         -5.23815416e-02,  1.67915144e-03, -1.81813864e-03,\n",
              "         -2.03298554e-02,  1.52636534e-02,  7.80943334e-02,\n",
              "         -8.08336064e-02, -2.89297774e-02, -3.39740776e-02,\n",
              "          1.98094212e-02,  6.36078939e-02, -4.15413640e-03,\n",
              "          8.10211897e-02,  3.32129486e-02,  5.41571761e-04,\n",
              "          7.85888061e-02, -7.11644739e-02, -3.59624252e-02,\n",
              "          3.44265588e-02, -8.29381794e-02, -1.97764616e-02,\n",
              "         -7.18649998e-02,  2.62306035e-02,  6.95761666e-02,\n",
              "          1.31351547e-02,  3.53561901e-02, -5.22452556e-02,\n",
              "         -1.02870753e-02,  2.53438810e-03, -4.16224450e-03,\n",
              "          3.78354751e-02, -4.62743975e-02, -5.63607700e-02,\n",
              "          2.39985879e-03, -2.71017402e-02,  1.26514817e-02,\n",
              "          8.28794986e-02,  2.04551388e-02,  1.19661936e-03,\n",
              "         -4.35623787e-02,  4.51573990e-02, -1.02382933e-03,\n",
              "         -5.53270578e-02,  3.40741463e-02, -5.48020899e-02,\n",
              "          5.14451563e-02, -5.88647313e-02,  1.30884096e-01,\n",
              "         -3.39942202e-02, -5.29263988e-02, -1.21829528e-02,\n",
              "          5.27420864e-02,  1.04586191e-01, -6.63908571e-02,\n",
              "         -6.39322400e-02,  1.29926193e-03, -4.00480442e-02,\n",
              "         -1.37191057e-01, -4.16930057e-02, -6.87899143e-02,\n",
              "         -5.52438386e-02, -6.50060028e-02, -4.61842939e-02,\n",
              "          3.46115488e-03, -2.74834149e-02,  4.61787432e-02,\n",
              "         -3.45418565e-02,  6.03499785e-02,  6.78491816e-02,\n",
              "          7.92948355e-04,  2.54239440e-02, -9.49963368e-03,\n",
              "          1.95387900e-02, -4.29868549e-02, -1.26860544e-01,\n",
              "         -4.45655771e-02,  9.11241323e-02,  1.14190495e-02,\n",
              "         -3.14548574e-02,  5.38792795e-33, -2.24688053e-02,\n",
              "          1.45676862e-02,  1.72713287e-02,  8.20155814e-02,\n",
              "          7.40906224e-02, -1.83228161e-02, -2.77402010e-02,\n",
              "          7.99034089e-02, -5.31454533e-02, -8.38308595e-03,\n",
              "          6.23930537e-04, -7.00509995e-02,  3.38443071e-02,\n",
              "          1.48578566e-02,  1.23605661e-01,  1.24017149e-02,\n",
              "         -2.88118534e-02,  7.37875625e-02, -8.33186059e-05,\n",
              "          2.70420704e-02,  1.63833946e-02, -5.34336120e-02,\n",
              "          4.69464958e-02, -1.68333929e-02, -1.40507380e-02,\n",
              "          5.09421378e-02, -3.45099829e-02,  2.81196181e-02,\n",
              "         -4.49310318e-02,  6.89661950e-02,  5.42262979e-02,\n",
              "         -3.40550840e-02,  3.43166701e-02,  4.49392339e-03,\n",
              "         -3.41226123e-02, -2.30817366e-02, -2.58695725e-02,\n",
              "         -3.58439088e-02,  5.42767998e-03, -8.87858570e-02,\n",
              "         -4.33999952e-03, -1.73888914e-02,  1.61905661e-02,\n",
              "          3.37113887e-02, -1.64510366e-02, -7.21928179e-02,\n",
              "          5.32616675e-03,  7.63528273e-02, -3.71714472e-03,\n",
              "         -1.49760051e-02, -4.39815000e-02, -2.43372526e-02,\n",
              "         -3.07218172e-02, -1.01283692e-01,  3.18871662e-02,\n",
              "         -2.07671244e-02,  1.74578745e-02, -2.89633647e-02,\n",
              "         -8.14729929e-02,  1.07900705e-02, -2.56989840e-02,\n",
              "         -1.52197229e-02,  5.81131224e-03,  3.73117104e-02,\n",
              "         -1.33057628e-02,  6.16909228e-02,  1.22146066e-02,\n",
              "          7.43198842e-02, -4.10865322e-02, -4.85322513e-02,\n",
              "          6.76470771e-02,  4.35605496e-02,  5.94257340e-02,\n",
              "         -8.99500214e-03, -8.99406448e-02, -6.48479834e-02,\n",
              "         -2.89333612e-02,  5.07136993e-02, -1.76139437e-02,\n",
              "          4.38264683e-02, -5.08276606e-03, -1.17750049e-01,\n",
              "         -3.31922546e-02,  5.31798378e-02, -2.51283273e-02,\n",
              "          1.67066485e-01, -3.87735888e-02,  2.08828188e-02,\n",
              "          2.98263002e-02, -2.94498242e-02,  1.37251671e-02,\n",
              "         -1.90390460e-02,  6.52075633e-02, -5.90277724e-02,\n",
              "         -7.49122277e-02, -1.45822030e-08, -9.92472544e-02,\n",
              "          1.77605320e-02,  5.45674488e-02, -4.07942608e-02,\n",
              "         -7.51653314e-02,  4.76343557e-02, -4.95372079e-02,\n",
              "         -2.72614621e-02, -2.61482801e-02,  1.26426052e-02,\n",
              "          1.17545780e-02,  8.15664753e-02,  7.47606903e-02,\n",
              "          3.21675874e-02,  2.24569812e-02, -3.90860513e-02,\n",
              "          6.35994375e-02, -2.24998072e-02,  8.22072942e-03,\n",
              "          2.55981255e-02, -2.87283156e-02, -3.69775062e-03,\n",
              "          8.03368688e-02, -3.12980847e-03, -1.14155553e-01,\n",
              "         -6.79618388e-05, -8.48676413e-02, -4.16608192e-02,\n",
              "         -7.77504966e-03,  1.49233162e-01,  1.51611269e-02,\n",
              "          2.87881796e-03, -3.20171155e-02,  1.74184125e-02,\n",
              "          5.50488308e-02, -3.36850844e-02,  6.70984909e-02,\n",
              "         -1.26028150e-01,  5.97128225e-03,  2.48598540e-03,\n",
              "         -3.90500054e-02,  6.34969771e-02,  9.07340124e-02,\n",
              "          2.12549083e-02,  1.99421886e-02, -3.20497453e-02,\n",
              "          1.04074061e-01, -6.75337985e-02,  3.61093180e-03,\n",
              "         -4.65961136e-02,  1.21825375e-01,  4.69704308e-02,\n",
              "          1.20611088e-02, -1.01968898e-02,  9.11733042e-03,\n",
              "          6.86389878e-02, -6.01598946e-03,  3.21785198e-03,\n",
              "         -5.85339330e-02,  1.81519389e-02,  3.57794724e-02,\n",
              "         -1.05647899e-01, -5.42342057e-03,  2.77254526e-02]]),\n",
              " 'documents': ['There is no spoon.', 'I know kung fu.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents', 'embeddings'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "morpheus_collection = client.create_collection(\n",
        "     name=\"morpheus\", metadata={\"hnsw:space\": \"cosine\"}\n",
        ")"
      ],
      "metadata": {
        "id": "PaLScNa-nZ_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morpheus_collection.add(\n",
        "    documents=[\n",
        "        \"This is your last chance. After this, there is no turning back.\",\n",
        "        \"You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.\",\n",
        "        \"You take the red pill, you stay in Wonderland, and I show you how deep the rabbit hole goes.\",\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\", \"quote3\"],\n",
        ")"
      ],
      "metadata": {
        "id": "AHGPNVWBncBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morpheus_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfBAHxhgneLT",
        "outputId": "3fcf83b0-bf8e-4bd4-8787-1d99388fbe25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['This is your last chance. After this, there is no turning back.',\n",
              "  'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.',\n",
              "  'You take the red pill, you stay in Wonderland, and I show you how deep the rabbit hole goes.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying by a set of query_texts\n",
        "results = morpheus_collection.query(\n",
        "    query_texts=[\"Take the red pill\"],\n",
        "    n_results=2,\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqf054E7nf6j",
        "outputId": "a85d5bb5-2258-4598-d387-a30a089064a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['quote3', 'quote2']], 'embeddings': None, 'documents': [['You take the red pill, you stay in Wonderland, and I show you how deep the rabbit hole goes.', 'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None, None]], 'distances': [[0.4833802580833435, 0.523399829864502]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the raw documents\n",
        "trinity_collection.add(\n",
        "    documents=[\n",
        "        \"Dodge this.\",\n",
        "        \"I think they're trying to tell us something.\",\n",
        "        \"Neo, no one has ever done this before.\",\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\", \"quote3\"],\n",
        ")"
      ],
      "metadata": {
        "id": "0-VwGBFZniWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = trinity_collection.get(ids=[\"quote2\", \"quote3\"])\n",
        "\n",
        "print(items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdMz0VGVnkpT",
        "outputId": "22a9946e-3753-4850-ec31-7349edf5ebb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': ['quote2', 'quote3'], 'embeddings': None, 'documents': [\"I think they're trying to tell us something.\", 'Neo, no one has ever done this before.'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [None, None]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the collection by text and choose which data is returned\n",
        "results = morpheus_collection.query(\n",
        "    query_texts=[\"take the red pill\"],\n",
        "    n_results=1,\n",
        "    include=[\"embeddings\", \"distances\"]\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnB0W6rInn2L",
        "outputId": "90e5736d-6277-487f-a057-1dd9253bc0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['quote3']], 'embeddings': [array([[ 6.12788051e-02, -2.98455637e-02, -1.90498065e-02,\n",
            "         5.54056689e-02, -7.39526376e-03,  4.34898846e-02,\n",
            "         1.22926414e-01,  1.97325833e-02,  5.92359267e-02,\n",
            "        -5.11117578e-02, -9.32596251e-02,  3.73888649e-02,\n",
            "        -3.44367623e-02,  2.96901911e-02,  8.96170177e-03,\n",
            "        -8.79780110e-03,  4.69029732e-02, -1.29458467e-02,\n",
            "        -6.32883236e-02,  7.15122838e-03,  4.88326512e-03,\n",
            "         3.83658893e-02,  5.51178083e-02,  5.23131639e-02,\n",
            "        -9.75997671e-02, -2.97604296e-02, -2.98656104e-03,\n",
            "        -1.70954689e-02, -1.61748484e-01, -1.31750181e-02,\n",
            "         6.69235960e-02,  2.20748540e-02,  2.14834567e-02,\n",
            "        -2.67290417e-02,  2.12764218e-02,  6.96146190e-02,\n",
            "         1.16724530e-02, -1.91992391e-02,  6.75865486e-02,\n",
            "         4.26341631e-02, -2.53720768e-02, -4.45584990e-02,\n",
            "         1.78892035e-02,  8.54158700e-02,  4.13706042e-02,\n",
            "         1.25522064e-02, -4.74720225e-02,  6.62021562e-02,\n",
            "         6.79530874e-02, -3.02774329e-02, -4.72253449e-02,\n",
            "         1.99937988e-02, -3.82457189e-02,  5.65455332e-02,\n",
            "        -6.47886768e-02,  8.43382999e-02, -1.43867573e-02,\n",
            "        -3.17160599e-02, -1.86195713e-03,  2.77398024e-02,\n",
            "        -5.11714257e-02, -1.50036870e-03,  1.67416148e-02,\n",
            "         7.06712008e-02, -7.64283910e-02,  5.70729412e-02,\n",
            "        -1.48289632e-02,  2.18991786e-02,  9.48137417e-03,\n",
            "         1.22245125e-01, -2.22922955e-02, -1.56783666e-02,\n",
            "        -4.25365306e-02, -4.30342406e-02, -4.04861458e-02,\n",
            "        -4.83581983e-02,  3.41597223e-03, -4.63564917e-02,\n",
            "        -8.65491666e-03, -6.52046595e-03,  2.97123771e-02,\n",
            "         3.34578641e-02,  6.75687343e-02,  4.68487069e-02,\n",
            "        -2.04289109e-02,  2.76770140e-03,  5.67281209e-02,\n",
            "        -4.33382019e-02, -9.75506566e-03, -2.98385527e-02,\n",
            "        -2.70346943e-02, -5.85107431e-02, -2.73601636e-02,\n",
            "         9.44759026e-02, -3.94958258e-02, -1.24920920e-01,\n",
            "        -4.45044152e-02,  9.90825705e-03, -5.57038486e-02,\n",
            "         9.74255875e-02,  1.96387507e-02, -5.78473620e-02,\n",
            "         2.36342978e-02, -1.98371690e-02,  8.84900019e-02,\n",
            "        -5.73106967e-02, -3.43649909e-02,  2.01693047e-02,\n",
            "         8.30343291e-02, -3.29250880e-02,  6.61548004e-02,\n",
            "        -5.41716442e-02,  5.94151430e-02,  1.45776626e-02,\n",
            "         4.98831011e-02, -2.63347272e-02,  7.95857012e-02,\n",
            "        -1.52764292e-02, -6.10731095e-02,  7.84735009e-02,\n",
            "         4.69369292e-02,  2.66294344e-03, -5.32603264e-02,\n",
            "         4.58554141e-02, -4.49738204e-02, -3.03524975e-02,\n",
            "         9.61624901e-04, -4.15332864e-33, -7.60313049e-02,\n",
            "        -3.45514007e-02,  6.05579801e-02,  1.59900084e-01,\n",
            "         3.41693386e-02,  6.78148344e-02, -8.84805769e-02,\n",
            "        -1.27597861e-02,  5.20603545e-03,  7.82054365e-02,\n",
            "        -2.86978837e-02,  1.05211732e-03, -9.56031531e-02,\n",
            "         4.83657010e-02, -1.53786549e-02,  6.76800683e-02,\n",
            "        -2.59167943e-02,  6.54156953e-02,  3.66009809e-02,\n",
            "         3.83297205e-02, -9.29340497e-02,  1.45711070e-02,\n",
            "        -2.05741841e-02, -3.59884696e-03, -1.26177100e-02,\n",
            "         2.73837335e-02, -1.10692903e-02,  2.85082124e-03,\n",
            "        -1.77550348e-04,  2.35579479e-02,  5.74867688e-02,\n",
            "         5.88781536e-02,  1.68998111e-02,  4.94073145e-04,\n",
            "        -8.30916911e-02, -1.01220785e-02, -5.47486618e-02,\n",
            "        -1.39049469e-02,  3.71385626e-02,  5.38524576e-02,\n",
            "        -7.12075233e-02, -1.59670711e-02, -3.40099186e-02,\n",
            "         1.17917277e-01,  1.74661409e-02, -3.42282131e-02,\n",
            "         1.07280249e-02,  5.27982675e-02, -2.50531323e-02,\n",
            "         8.58259872e-02, -4.18069735e-02,  3.87632810e-02,\n",
            "         5.51380105e-02,  2.98005193e-02, -3.70905288e-02,\n",
            "        -4.49586101e-03, -8.88104215e-02,  6.82187453e-02,\n",
            "         6.39099181e-02, -7.68027094e-04,  3.17389369e-02,\n",
            "         1.28361713e-02, -3.29535306e-02, -1.14459703e-02,\n",
            "        -3.14689660e-03,  3.89331952e-02, -2.23192871e-02,\n",
            "        -4.68117371e-02, -2.97918878e-02,  8.06982815e-02,\n",
            "         1.32421590e-03,  5.74452616e-03,  2.09172145e-02,\n",
            "        -3.90430652e-02, -1.12053112e-03, -5.40853031e-02,\n",
            "        -4.07057293e-02, -2.59911120e-02,  3.68360579e-02,\n",
            "        -8.93692002e-02,  4.55704108e-02, -3.70337665e-02,\n",
            "        -3.63411419e-02,  1.48067307e-02,  2.65040640e-02,\n",
            "        -1.00299353e-02,  9.57551003e-02,  2.43298803e-03,\n",
            "         4.23727706e-02, -5.51673658e-02, -2.38751490e-02,\n",
            "        -3.83914411e-02,  3.74657176e-02, -6.11066185e-02,\n",
            "         2.96136513e-02,  4.10736608e-33, -2.08840240e-02,\n",
            "        -5.36225960e-02,  1.03553254e-02,  3.35066766e-02,\n",
            "         4.99531217e-02, -5.30303158e-02, -1.88388377e-02,\n",
            "        -1.64430887e-02,  1.57984383e-02,  9.54845101e-02,\n",
            "         1.26488805e-02, -4.06926079e-03,  9.84922703e-03,\n",
            "         3.87630202e-02,  2.50498913e-02, -3.39823514e-02,\n",
            "         6.85000271e-02, -7.10901618e-02, -3.68584171e-02,\n",
            "         1.40335821e-02, -8.15946460e-02, -2.43696272e-02,\n",
            "        -8.88102278e-02,  1.73620246e-02, -9.42691579e-04,\n",
            "         1.96062308e-02,  1.16894633e-01, -3.16957906e-02,\n",
            "         3.86614874e-02, -8.81026387e-02, -3.86363380e-02,\n",
            "         5.02911676e-03, -1.20225385e-01, -7.01212436e-02,\n",
            "        -2.51704864e-02,  6.13569049e-03, -1.30902249e-02,\n",
            "        -4.79765721e-02, -1.00534685e-01, -9.60037410e-02,\n",
            "        -5.72415851e-02, -4.55055721e-02, -1.02588460e-01,\n",
            "        -1.66492872e-02,  3.71521804e-03,  1.83759835e-02,\n",
            "         2.38661915e-02,  9.89738256e-02, -5.84532320e-03,\n",
            "         8.08705986e-02, -6.04915731e-02, -1.10081755e-01,\n",
            "         4.01172824e-02,  2.08174139e-02, -2.01767664e-02,\n",
            "        -3.25763994e-03, -3.79397422e-02, -1.79647710e-02,\n",
            "         1.49267782e-02, -2.37414446e-02, -6.49741292e-02,\n",
            "         8.16822890e-03, -2.59934962e-02,  6.72160834e-02,\n",
            "         2.21069269e-02, -6.01123385e-02, -6.56899065e-02,\n",
            "         7.67451897e-02,  1.55558465e-02,  3.29183713e-02,\n",
            "         1.28929084e-02,  4.09362502e-02,  3.22316736e-02,\n",
            "        -2.90727522e-02,  8.19006294e-04, -1.34149380e-02,\n",
            "         2.69498564e-02, -7.98776001e-02, -6.61133751e-02,\n",
            "        -6.24969602e-02,  4.22972776e-02, -1.24163464e-01,\n",
            "         1.03190534e-01,  3.71810608e-02,  1.29424306e-02,\n",
            "        -8.13530106e-03,  3.73143377e-03, -8.46158154e-03,\n",
            "        -9.65834409e-02,  5.17770760e-02,  7.06365928e-02,\n",
            "        -2.58642826e-02, -5.81083596e-02,  6.92165410e-03,\n",
            "         5.61544523e-02, -2.44252707e-08, -9.27068832e-05,\n",
            "         1.39576010e-02,  2.24900641e-03, -8.48095790e-02,\n",
            "         8.93922821e-02, -9.19094961e-03,  1.02316979e-02,\n",
            "         3.47167514e-02,  6.62977516e-04,  5.80884293e-02,\n",
            "         2.46488344e-04,  6.93628192e-02,  6.86786845e-02,\n",
            "        -3.00862938e-02, -7.30748754e-03,  1.44579262e-01,\n",
            "        -2.39702757e-03, -6.51167035e-02, -2.94090267e-02,\n",
            "         6.01550415e-02, -2.38572452e-02,  3.69396918e-02,\n",
            "         4.92690355e-02,  5.21013290e-02, -1.01270303e-02,\n",
            "         3.75591069e-02,  1.93966590e-02, -3.18022049e-03,\n",
            "        -1.01537053e-02, -2.85340976e-02,  3.95384878e-02,\n",
            "         3.20585780e-02, -4.55858558e-02,  8.66943374e-02,\n",
            "        -2.15340834e-02, -7.79222175e-02, -2.20003966e-02,\n",
            "         9.32801068e-02,  1.10798702e-02, -3.78331095e-02,\n",
            "        -8.97460207e-02, -3.53135765e-02,  1.17662713e-01,\n",
            "         2.13550199e-02, -7.87480846e-02, -2.78058425e-02,\n",
            "         1.33047504e-02, -1.40922191e-02, -1.16275689e-02,\n",
            "        -1.94495413e-02, -2.26681456e-02,  4.58761342e-02,\n",
            "         4.48645726e-02,  5.98610602e-02,  4.16573212e-02,\n",
            "        -2.25423127e-02, -2.50699377e-04,  3.30955312e-02,\n",
            "        -6.72219172e-02,  5.54449111e-02, -6.15285262e-02,\n",
            "        -7.73361744e-03,  3.24770510e-02, -1.28064960e-01]])], 'documents': None, 'uris': None, 'included': ['embeddings', 'distances'], 'data': None, 'metadatas': None, 'distances': [[0.4833802580833435]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the collection\n",
        "matrix_collection = client.create_collection(name=\"matrix\")"
      ],
      "metadata": {
        "id": "I0hCDefLnvAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the raw documents\n",
        "matrix_collection.add(\n",
        "    documents=[\n",
        "        \"The Matrix is everywhere, it is all around us.\",\n",
        "        \"Unfortunately, no one can be told what the Matrix is\",\n",
        "        \"You can see it when you look out your window or when you turn on your television.\",\n",
        "        \"You are a plague, Mr. Anderson. You and your kind are a cancer of this planet.\",\n",
        "        \"You hear that Mr. Anderson?... That is the sound of inevitability...\",\n",
        "    ],\n",
        "    metadatas=[\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\", \"quote3\", \"quote4\", \"quote5\"],\n",
        ")"
      ],
      "metadata": {
        "id": "fepG_wXMnw4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying with where filters\n",
        "results = matrix_collection.query(\n",
        "    query_texts=[\"What is the Matrix?\"],\n",
        "    where={\"speaker\": \"Sanjeet Kumar\"},\n",
        "    n_results=2,\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uZmBTLJny2s",
        "outputId": "81b9e2d2-6908-41f2-87bb-3cbbdb527d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [[]], 'embeddings': None, 'documents': [[]], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[]], 'distances': [[]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update items in the collection\n",
        "matrix_collection.update(\n",
        "    ids=[\"quote2\"],\n",
        "    metadatas=[{\"category\": \"quote\", \"speaker\": \"Morpheus\"}],\n",
        "    documents=[\"The Matrix is a system, Neo. That system is our enemy.\"],\n",
        ")"
      ],
      "metadata": {
        "id": "0xv7tJecn1Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = matrix_collection.get(ids=[\"quote2\"])\n",
        "\n",
        "print(items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSG5KTAn3yb",
        "outputId": "7278abaa-dab5-493f-8944-df1289a3dc52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': ['quote2'], 'embeddings': None, 'documents': ['The Matrix is a system, Neo. That system is our enemy.'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'category': 'quote', 'speaker': 'Morpheus'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVQmX43Xn5zL",
        "outputId": "95578ee7-b897-412c-cc2f-627fce082808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3', 'quote4', 'quote5'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is everywhere, it is all around us.',\n",
              "  'The Matrix is a system, Neo. That system is our enemy.',\n",
              "  'You can see it when you look out your window or when you turn on your television.',\n",
              "  'You are a plague, Mr. Anderson. You and your kind are a cancer of this planet.',\n",
              "  'You hear that Mr. Anderson?... That is the sound of inevitability...'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert operation\n",
        "matrix_collection.upsert(\n",
        "    ids=[\"quote2\", \"quote4\"],\n",
        "    metadatas=[\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "    ],\n",
        "    documents=[\n",
        "        \"You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.\",\n",
        "        \"I'm going to enjoy watching you die, Mr. Anderson.\",\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "4vzTfx2Hn8Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lx5WqkMn96r",
        "outputId": "6528bf57-a669-483a-f54b-524c065f9f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3', 'quote4', 'quote5'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is everywhere, it is all around us.',\n",
              "  'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.',\n",
              "  'You can see it when you look out your window or when you turn on your television.',\n",
              "  \"I'm going to enjoy watching you die, Mr. Anderson.\",\n",
              "  'You hear that Mr. Anderson?... That is the sound of inevitability...'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Agent Smith'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert operation\n",
        "matrix_collection.upsert(\n",
        "    ids=[\"quote10\"],\n",
        "    metadatas=[\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "    ],\n",
        "    documents=[\n",
        "        \"Everything is a matrix\",\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "XU4cLZ3QoAXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ8VEzbroCVT",
        "outputId": "8dee984f-c73a-4058-cf3b-c8d82dc409a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3', 'quote4', 'quote5', 'quote10'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is everywhere, it is all around us.',\n",
              "  'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.',\n",
              "  'You can see it when you look out your window or when you turn on your television.',\n",
              "  \"I'm going to enjoy watching you die, Mr. Anderson.\",\n",
              "  'You hear that Mr. Anderson?... That is the sound of inevitability...',\n",
              "  'Everything is a matrix'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trinity_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXI8n44YgkFM",
        "outputId": "f86f80af-051b-4908-a43e-b2f3a8cc6712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['Dodge this.',\n",
              "  \"I think they're trying to tell us something.\",\n",
              "  'Neo, no one has ever done this before.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trinity_collection.delete(ids=[\"quote3\"])"
      ],
      "metadata": {
        "id": "TuXRBGbVoEID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trinity_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J5j-oTeoGPj",
        "outputId": "6d6c602b-ca94-4612-acf5-033923e33cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['Dodge this.', \"I think they're trying to tell us something.\"],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the raw documents\n",
        "matrix_collection.add(\n",
        "    documents=[\n",
        "        \"The Matrix is everywhere, it is all around us.\",\n",
        "        \"You can see it when you look out your window or when you turn on your television.\",\n",
        "        \"You can feel it when you go to work, when you go to church, when you pay your taxes.\",\n",
        "        \"It seems that you've been living two lives.\",\n",
        "        \"I believe that, as a species, human beings define their reality through misery and suffering\",\n",
        "        \"Human beings are a disease, a cancer of this planet.\",\n",
        "    ],\n",
        "    metadatas=[\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Morpheus\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "        {\"category\": \"quote\", \"speaker\": \"Agent Smith\"},\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\", \"quote3\", \"quote4\", \"quote5\", \"quote6\"],\n",
        ")"
      ],
      "metadata": {
        "id": "9IouqbL9oJeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD70wIwvoLdz",
        "outputId": "c0a18a94-bf5b-47e8-9463-73f87e38e82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1',\n",
              "  'quote2',\n",
              "  'quote3',\n",
              "  'quote4',\n",
              "  'quote5',\n",
              "  'quote10',\n",
              "  'quote6'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is everywhere, it is all around us.',\n",
              "  'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.',\n",
              "  'You can see it when you look out your window or when you turn on your television.',\n",
              "  \"I'm going to enjoy watching you die, Mr. Anderson.\",\n",
              "  'You hear that Mr. Anderson?... That is the sound of inevitability...',\n",
              "  'Everything is a matrix',\n",
              "  'Human beings are a disease, a cancer of this planet.'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Agent Smith'},\n",
              "  {'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'speaker': 'Agent Smith', 'category': 'quote'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting items that match the where filter\n",
        "matrix_collection.delete(where={\"speaker\": \"Agent Smith\"})"
      ],
      "metadata": {
        "id": "Fg4Ly1reoNYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_count = matrix_collection.count()\n",
        "print(f\"Count of items in collection: {item_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Y8P64moPYc",
        "outputId": "692ae6cf-117c-4991-8748-93bb3d6dd274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of items in collection: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH4rahlCoRWD",
        "outputId": "655a8e75-4034-43dc-8e76-46d7ee5b752f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3', 'quote10'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is everywhere, it is all around us.',\n",
              "  'You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe.',\n",
              "  'You can see it when you look out your window or when you turn on your television.',\n",
              "  'Everything is a matrix'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [{'speaker': 'Morpheus', 'category': 'quote'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'},\n",
              "  {'category': 'quote', 'speaker': 'Morpheus'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb.utils import embedding_functions"
      ],
      "metadata": {
        "id": "DCLj5weYoUU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTvTgtilnqzC",
        "outputId": "4f7648c2-8c48-4c89-b558-a688fe14a2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.38)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.4)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.11.10)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langsmith) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZXKaxkUcnqPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "AZURE_OPENAI_KEY = userdata.get('AZURE_OPENAI_KEY')\n",
        "DEPLOYMENT_NAME = userdata.get('DEPLOYMENT_NAME')\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"azure-llamaindex-monitoring\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LangSmith_KEY')"
      ],
      "metadata": {
        "id": "VsTP5OHwotaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azure_openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_base=AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=AZURE_OPENAI_KEY,\n",
        "    api_type=\"azure\",\n",
        "    api_version=\"2023-05-15\",\n",
        "    model_name=\"text-embedding-3-small\",\n",
        "    deployment_id=\"text-embedding-3-small\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "nUn829nLoni7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the collection with the OpenAI embedding function\n",
        "matrix_collection1 = client.create_collection(\n",
        "    name=\"matrix1\",\n",
        "    embedding_function=azure_openai_ef,\n",
        ")"
      ],
      "metadata": {
        "id": "u4rqOg7epAfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the raw documents\n",
        "matrix_collection1.add(\n",
        "    documents=[\n",
        "        \"The Matrix is all around us.\",\n",
        "        \"What you know you can't explain, but you feel it\",\n",
        "        \"There is a difference between knowing the path and walking the path\",\n",
        "    ],\n",
        "    ids=[\"quote1\", \"quote2\", \"quote3\"],\n",
        ")"
      ],
      "metadata": {
        "id": "oUnXJXNtpGw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix_collection1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtJF9WogpIvb",
        "outputId": "857ee191-8973-4d11-d759-940c89d9034f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection(name=matrix1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection1.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DuNZIoQpKeb",
        "outputId": "6f96a37a-b8e1-4e68-e601-66fce4fb779c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['The Matrix is all around us.',\n",
              "  \"What you know you can't explain, but you feel it\",\n",
              "  'There is a difference between knowing the path and walking the path'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_collection1.peek()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19V-XiMBob7k",
        "outputId": "8008b04b-27d8-43e5-d5b7-1c3a398f35c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['quote1', 'quote2', 'quote3'],\n",
              " 'embeddings': array([[-0.0281448 ,  0.07828282, -0.06761283, ..., -0.00488247,\n",
              "         -0.02072753, -0.0040829 ],\n",
              "        [-0.01762121,  0.0103139 , -0.04998776, ..., -0.00487263,\n",
              "          0.00250494, -0.01048383],\n",
              "        [ 0.0042798 , -0.00240698,  0.00753062, ...,  0.0017909 ,\n",
              "         -0.03565412,  0.01825963]]),\n",
              " 'documents': ['The Matrix is all around us.',\n",
              "  \"What you know you can't explain, but you feel it\",\n",
              "  'There is a difference between knowing the path and walking the path'],\n",
              " 'uris': None,\n",
              " 'included': ['metadatas', 'documents', 'embeddings'],\n",
              " 'data': None,\n",
              " 'metadatas': [None, None, None]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying by a set of query_texts\n",
        "results = matrix_collection1.query(query_texts=[\"What is the Matrix?\"], n_results=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv_mMbuppNfT",
        "outputId": "3278a466-2c14-4d1e-8db4-4bb749d27669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['quote1', 'quote2']], 'embeddings': None, 'documents': [['The Matrix is all around us.', \"What you know you can't explain, but you feel it\"]], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None, None]], 'distances': [[0.6623820066452026, 1.538782000541687]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install chromadb langchain_classic langchain_openai tiktoken langchain_community langsmith"
      ],
      "metadata": {
        "id": "cvPnHJydpXU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e0448e-ab5c-4913-ce24-02d408ba9dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.1/467.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.1 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_classic.prompts import PromptTemplate\n",
        "from langchain_classic.chains import LLMChain\n",
        "\n",
        "# Example prompt\n",
        "prompt = PromptTemplate.from_template(\"Translate this to French: {text}\")\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=DEPLOYMENT_NAME,\n",
        "    api_version=\"2024-05-01-preview\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    openai_api_version=\"2023-05-15\",\n",
        "    openai_api_key=AZURE_OPENAI_KEY,\n",
        ")\n",
        "\n",
        "# Create chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run chain (automatically logged to LangSmith)\n",
        "response = chain.invoke(\"Hello, how are you?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S4V1KwCi35g",
        "outputId": "e3f17f6c-baa1-461c-ae4c-e6ed607377ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-359484768.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use `RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Bonjour, comment ça va ?'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_classic.document_loaders import TextLoader\n",
        "from langchain_classic.document_loaders import DirectoryLoader\n",
        "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "#from langchain_classic.llms import OpenAI\n",
        "#from langchain_classic.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_classic.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "J85qBce0ph8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"articles\", exist_ok=True)\n",
        "print(\"New 'articles' folder created.\")\n",
        "\n",
        "articles = {\n",
        "    \"ai.txt\": \"\"\"Artificial Intelligence (AI) focuses on creating systems that can perform tasks that normally require human intelligence.\n",
        "It includes perception, reasoning, learning, problem-solving, and interaction with the environment.\n",
        "Modern AI drives innovations in healthcare, robotics, and language understanding.\"\"\",\n",
        "\n",
        "    \"machine_learning.txt\": \"\"\"Machine Learning (ML) enables computers to learn from data rather than relying on explicit programming.\n",
        "It powers systems like recommendation engines, predictive analytics, and fraud detection.\n",
        "Key techniques include supervised learning, unsupervised learning, and reinforcement learning.\"\"\",\n",
        "\n",
        "    \"deep_learning.txt\": \"\"\"Deep Learning is a subset of ML that relies on neural networks with multiple layers.\n",
        "It excels in handling unstructured data such as images, videos, and audio.\n",
        "Deep learning models like CNNs and Transformers have revolutionized speech and vision applications.\"\"\",\n",
        "\n",
        "    \"natural_language_processing.txt\": \"\"\"Natural Language Processing (NLP) is the technology that helps computers understand, interpret, and generate human language.\n",
        "It powers chatbots, translation systems, and sentiment analysis tools.\n",
        "Transformer-based architectures like BERT, GPT, and T5 dominate modern NLP.\"\"\",\n",
        "\n",
        "    \"computer_vision.txt\": \"\"\"Computer Vision enables AI systems to interpret and understand visual information from the real world.\n",
        "It is applied in object detection, facial recognition, autonomous vehicles, and medical imaging.\n",
        "Techniques rely heavily on convolutional neural networks (CNNs) and visual transformers.\"\"\",\n",
        "\n",
        "    \"reinforcement_learning.txt\": \"\"\"Reinforcement Learning (RL) teaches an agent to make decisions by rewarding desirable actions.\n",
        "It’s used in robotics, gaming, and optimization systems.\n",
        "Notable methods include Q-learning, Policy Gradient, and Deep Q-Networks (DQN).\"\"\",\n",
        "\n",
        "    \"ethical_ai.txt\": \"\"\"Ethical AI ensures that artificial intelligence is developed responsibly, transparently, and fairly.\n",
        "Concerns include algorithmic bias, data privacy, accountability, and human oversight.\n",
        "Organizations are adopting governance frameworks for trustworthy AI deployment.\"\"\",\n",
        "\n",
        "    \"generative_ai_rag.txt\": \"\"\"Generative AI with Retrieval-Augmented Generation (RAG) combines generation and retrieval to create more factual and context-aware responses.\n",
        "It enhances chatbot reliability by pulling knowledge from external databases or documents before generating answers.\n",
        "This hybrid method reduces hallucinations in large language models.\"\"\"\n",
        "}\n",
        "\n",
        "\n",
        "for filename, content in articles.items():\n",
        "    with open(os.path.join(\"articles\", filename), \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(\"8 AI-related article text files created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-LnVHJ1mnOx",
        "outputId": "d1004157-8169-47d3-ab2a-8ed46eaf7370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New 'articles' folder created.\n",
            "8 AI-related article text files created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"./articles/\", glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "-ZlVJ-vAqntS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKk2AX1jrCFD",
        "outputId": "01f00bdb-a1f0-4298-e425-010bbd094295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'articles/ethical_ai.txt'}, page_content='Ethical AI ensures that artificial intelligence is developed responsibly, transparently, and fairly.\\nConcerns include algorithmic bias, data privacy, accountability, and human oversight.\\nOrganizations are adopting governance frameworks for trustworthy AI deployment.'),\n",
              " Document(metadata={'source': 'articles/natural_language_processing.txt'}, page_content='Natural Language Processing (NLP) is the technology that helps computers understand, interpret, and generate human language.\\nIt powers chatbots, translation systems, and sentiment analysis tools.\\nTransformer-based architectures like BERT, GPT, and T5 dominate modern NLP.'),\n",
              " Document(metadata={'source': 'articles/ai.txt'}, page_content='Artificial Intelligence (AI) focuses on creating systems that can perform tasks that normally require human intelligence.\\nIt includes perception, reasoning, learning, problem-solving, and interaction with the environment.\\nModern AI drives innovations in healthcare, robotics, and language understanding.'),\n",
              " Document(metadata={'source': 'articles/deep_learning.txt'}, page_content='Deep Learning is a subset of ML that relies on neural networks with multiple layers.\\nIt excels in handling unstructured data such as images, videos, and audio.\\nDeep learning models like CNNs and Transformers have revolutionized speech and vision applications.'),\n",
              " Document(metadata={'source': 'articles/machine_learning.txt'}, page_content='Machine Learning (ML) enables computers to learn from data rather than relying on explicit programming.\\nIt powers systems like recommendation engines, predictive analytics, and fraud detection.\\nKey techniques include supervised learning, unsupervised learning, and reinforcement learning.'),\n",
              " Document(metadata={'source': 'articles/computer_vision.txt'}, page_content='Computer Vision enables AI systems to interpret and understand visual information from the real world.\\nIt is applied in object detection, facial recognition, autonomous vehicles, and medical imaging.\\nTechniques rely heavily on convolutional neural networks (CNNs) and visual transformers.'),\n",
              " Document(metadata={'source': 'articles/generative_ai_rag.txt'}, page_content='Generative AI with Retrieval-Augmented Generation (RAG) combines generation and retrieval to create more factual and context-aware responses.\\nIt enhances chatbot reliability by pulling knowledge from external databases or documents before generating answers.\\nThis hybrid method reduces hallucinations in large language models.'),\n",
              " Document(metadata={'source': 'articles/reinforcement_learning.txt'}, page_content='Reinforcement Learning (RL) teaches an agent to make decisions by rewarding desirable actions.\\nIt’s used in robotics, gaming, and optimization systems.\\nNotable methods include Q-learning, Policy Gradient, and Deep Q-Networks (DQN).')]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "TnPVEi_KrE6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6sHyWZfrIGD",
        "outputId": "284bd34b-7508-47fd-ba67-4a41cdb8b28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'articles/ethical_ai.txt'}, page_content='Ethical AI ensures that artificial intelligence is developed responsibly, transparently, and fairly.\\nConcerns include algorithmic bias, data privacy, accountability, and human oversight.\\nOrganizations are adopting governance frameworks for trustworthy AI deployment.'),\n",
              " Document(metadata={'source': 'articles/natural_language_processing.txt'}, page_content='Natural Language Processing (NLP) is the technology that helps computers understand, interpret, and generate human language.\\nIt powers chatbots, translation systems, and sentiment analysis tools.\\nTransformer-based architectures like BERT, GPT, and T5 dominate modern NLP.'),\n",
              " Document(metadata={'source': 'articles/ai.txt'}, page_content='Artificial Intelligence (AI) focuses on creating systems that can perform tasks that normally require human intelligence.\\nIt includes perception, reasoning, learning, problem-solving, and interaction with the environment.\\nModern AI drives innovations in healthcare, robotics, and language understanding.'),\n",
              " Document(metadata={'source': 'articles/deep_learning.txt'}, page_content='Deep Learning is a subset of ML that relies on neural networks with multiple layers.\\nIt excels in handling unstructured data such as images, videos, and audio.\\nDeep learning models like CNNs and Transformers have revolutionized speech and vision applications.'),\n",
              " Document(metadata={'source': 'articles/machine_learning.txt'}, page_content='Machine Learning (ML) enables computers to learn from data rather than relying on explicit programming.\\nIt powers systems like recommendation engines, predictive analytics, and fraud detection.\\nKey techniques include supervised learning, unsupervised learning, and reinforcement learning.'),\n",
              " Document(metadata={'source': 'articles/computer_vision.txt'}, page_content='Computer Vision enables AI systems to interpret and understand visual information from the real world.\\nIt is applied in object detection, facial recognition, autonomous vehicles, and medical imaging.\\nTechniques rely heavily on convolutional neural networks (CNNs) and visual transformers.'),\n",
              " Document(metadata={'source': 'articles/generative_ai_rag.txt'}, page_content='Generative AI with Retrieval-Augmented Generation (RAG) combines generation and retrieval to create more factual and context-aware responses.\\nIt enhances chatbot reliability by pulling knowledge from external databases or documents before generating answers.\\nThis hybrid method reduces hallucinations in large language models.'),\n",
              " Document(metadata={'source': 'articles/reinforcement_learning.txt'}, page_content='Reinforcement Learning (RL) teaches an agent to make decisions by rewarding desirable actions.\\nIt’s used in robotics, gaming, and optimization systems.\\nNotable methods include Q-learning, Policy Gradient, and Deep Q-Networks (DQN).')]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6fvyJ6HrJ0L",
        "outputId": "c4b4ddfb-d805-48e9-b7b0-4d696b113535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"db\""
      ],
      "metadata": {
        "id": "F7tl7KwhrKtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# Define Azure OpenAI Embedding model\n",
        "embedding = AzureOpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",            # model name\n",
        "    azure_deployment=\"text-embedding-3-small\",         # your deployment name in Azure\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    openai_api_version=\"2023-05-15\",\n",
        "    openai_api_key=AZURE_OPENAI_KEY,\n",
        "\n",
        "   )\n",
        "\n",
        "# Create Chroma Vector DB from documents\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n"
      ],
      "metadata": {
        "id": "DcJtE4BJrN8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# persist the db to the disk\n",
        "vectordb.persist()\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "t23NewUXsC-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d9545d-7f85-46ef-b269-b75bcda02567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-318903705.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function = embedding\n",
        ")"
      ],
      "metadata": {
        "id": "Hfy6QRMGsHUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7e47ad-67ed-4d38-c0e9-6b2bc56215f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2964001279.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
            "  vectordb = Chroma(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "HDfQcKuysI9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "MmbRO3CdsNMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dfWF2W4TsPI7",
        "outputId": "c3fafc6a-766b-4d00-bcb3-40cd6ad89789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'similarity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_kwargs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOuk0-ZhsQ_y",
        "outputId": "54ef067d-fa6e-42d0-ed3c-d0d764800835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'k': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "578_we0kkQJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is ML?\"\n",
        "llm_response = qa_chain(query)\n",
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHH5BHvakX6O",
        "outputId": "056f8393-efa3-4426-927f-82936e402dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4266354630.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
            "  llm_response = qa_chain(query)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is ML?',\n",
              " 'result': 'ML, or Machine Learning, is a field of computer science that enables computers to learn from data rather than relying on explicit programming. Instead of being manually programmed for specific tasks, ML systems use data to identify patterns, make predictions, and improve their performance over time. It powers applications such as recommendation engines, predictive analytics, and fraud detection. Key techniques in ML include supervised learning, unsupervised learning, and reinforcement learning.',\n",
              " 'source_documents': [Document(metadata={'source': 'articles/machine_learning.txt'}, page_content='Machine Learning (ML) enables computers to learn from data rather than relying on explicit programming.\\nIt powers systems like recommendation engines, predictive analytics, and fraud detection.\\nKey techniques include supervised learning, unsupervised learning, and reinforcement learning.'),\n",
              "  Document(metadata={'source': 'articles/deep_learning.txt'}, page_content='Deep Learning is a subset of ML that relies on neural networks with multiple layers.\\nIt excels in handling unstructured data such as images, videos, and audio.\\nDeep learning models like CNNs and Transformers have revolutionized speech and vision applications.'),\n",
              "  Document(metadata={'source': 'articles/reinforcement_learning.txt'}, page_content='Reinforcement Learning (RL) teaches an agent to make decisions by rewarding desirable actions.\\nIt’s used in robotics, gaming, and optimization systems.\\nNotable methods include Q-learning, Policy Gradient, and Deep Q-Networks (DQN).'),\n",
              "  Document(metadata={'source': 'articles/natural_language_processing.txt'}, page_content='Natural Language Processing (NLP) is the technology that helps computers understand, interpret, and generate human language.\\nIt powers chatbots, translation systems, and sentiment analysis tools.\\nTransformer-based architectures like BERT, GPT, and T5 dominate modern NLP.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response[\"result\"])\n",
        "  print('\\n\\nSources:')\n",
        "  for source in llm_response[\"source_documents\"]:\n",
        "    print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "1QAMf_EOk7nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the news about Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2pEiFcxk__F",
        "outputId": "aa1bdf1a-3df4-4a56-f138-3666de79d270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/natural_language_processing.txt\n",
            "articles/generative_ai_rag.txt\n",
            "articles/computer_vision.txt\n",
            "articles/ethical_ai.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Generative AI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cgp2ubGlBye",
        "outputId": "43c7d201-dcb2-479d-bac0-89099ae221c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI refers to artificial intelligence models designed to create new content such as text, images, audio, or video. These models are trained on vast amounts of data and use patterns within that data to generate outputs that mimic human-like creativity. Popular examples include GPT (Generative Pre-trained Transformer) for text generation and tools like DALL·E for image creation.\n",
            "\n",
            "Generative AI is frequently combined with Retrieval-Augmented Generation (RAG) to improve the accuracy and reliability of responses. RAG leverages external databases or documents during the generation process, ensuring that the output is more factual and context-aware. This hybrid approach helps reduce hallucinations, which are instances where AI produces incorrect or nonsensical information.\n",
            "\n",
            "Generative AI is used across various domains, including content creation, education, healthcare, and entertainment. It showcases the potential of AI to not only understand but also produce creative and meaningful outputs.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/generative_ai_rag.txt\n",
            "articles/ai.txt\n",
            "articles/ethical_ai.txt\n",
            "articles/natural_language_processing.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\""
      ],
      "metadata": {
        "id": "VlCGJV6flGO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Generative AI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOVChiZdlv7T",
        "outputId": "c80a9b8d-aff2-4cbb-953e-6a2e97800920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI refers to a category of artificial intelligence focused on creating new content, such as text, images, audio, or videos, based on input data it has been trained on. It uses models like GPT (Generative Pre-trained Transformer) to predict and generate outputs that resemble human-created content. Generative AI can write essays, compose music, create artwork, and even simulate conversations.\n",
            "\n",
            "A more advanced form of Generative AI is Retrieval-Augmented Generation (RAG), which combines generation with retrieval capabilities. RAG pulls knowledge from external databases or documents during the generation process, resulting in responses that are more factual and context-aware, while reducing errors or hallucinations commonly seen in purely generative systems.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/generative_ai_rag.txt\n",
            "articles/ai.txt\n",
            "articles/ethical_ai.txt\n",
            "articles/natural_language_processing.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O8-py8NenMD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}