{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_KEY = os.getenv(\"api_key\")\n",
    "AZURE_DEPLOYMENT_NAME = os.getenv(\"model-name\")\n",
    "API_VERSION = os.getenv(\"api-version\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"azure_endpoint\")\n",
    "\n",
    "\n",
    "\n",
    "# Create Azure Model Client\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    deployment_name=AZURE_DEPLOYMENT_NAME ,  # Your deployment name\n",
    "    model =AZURE_DEPLOYMENT_NAME \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "def weather_check_tool(city: str) -> str:\n",
    "    weather_data = {\n",
    "        \"Dubai\": \"Sunny, 35°C\",\n",
    "        \"New York\": \"Cloudy, 22°C\",\n",
    "        \"London\": \"Rainy, 18°C\",\n",
    "        \"Tokyo\": \"Clear, 26°C\"\n",
    "    }\n",
    "    return weather_data.get(city, \"Weather data not available.\")\n",
    "\n",
    "def currency_exchange_tool(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    exchange_rates = {\n",
    "        (\"USD\", \"EUR\"): 0.92,\n",
    "        (\"EUR\", \"USD\"): 1.08,\n",
    "        (\"USD\", \"AED\"): 3.67,\n",
    "        (\"AED\", \"USD\"): 0.27\n",
    "    }\n",
    "    rate = exchange_rates.get((from_currency, to_currency), None)\n",
    "    if rate:\n",
    "        converted_amount = amount * rate\n",
    "        return f\"{amount} {from_currency} is equal to {converted_amount:.2f} {to_currency}.\"\n",
    "    return \"Exchange rate not available.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "planning_agent = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks. It should break down tasks and delegate them to the appropriate agents.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        WeatherAgent: Checks weather conditions\n",
    "        CurrencyAgent: Handles currency conversion\n",
    "    \n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "    \n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "    \n",
    "    After all tasks are complete, summarize the findings and end with \"TERMINATE\".\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "weather_agent = AssistantAgent(\n",
    "    \"WeatherAgent\",\n",
    "    description=\"An agent that provides current weather conditions for a given city.\",\n",
    "    tools=[weather_check_tool],\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a weather-checking agent.\n",
    "    Your only tool is weather_check_tool - use it to fetch weather data for a city.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "currency_agent = AssistantAgent(\n",
    "    \"CurrencyAgent\",\n",
    "    description=\"An agent that performs currency exchange calculations.\",\n",
    "    model_client=model_client,\n",
    "    tools=[currency_exchange_tool],\n",
    "    system_message=\"\"\"\n",
    "    You are a currency exchange agent.\n",
    "    Your job is to convert a given amount from one currency to another using the available exchange rates.\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention all termination conditions\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=25)\n",
    "termination = text_mention_termination | max_messages_termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the team\n",
    "\n",
    "team = SelectorGroupChat(\n",
    "    [planning_agent, weather_agent, currency_agent],\n",
    "    model_client=model_client,\n",
    "    termination_condition=termination,\n",
    "    allow_repeated_speaker=True,  # Allow an agent to speak multiple turns in a row.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the task\u001b[39;00m\n\u001b[32m      2\u001b[39m task = \u001b[33m\"\u001b[39m\u001b[33mWhat is the current weather in Dubai, and how much is 100 USD in AED?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Console(team.run_stream(task=task))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:499\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token)\u001b[39m\n\u001b[32m    493\u001b[39m     shutdown_task = asyncio.create_task(stop_runtime())\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    496\u001b[39m     \u001b[38;5;66;03m# Run the team by sending the start message to the group chat manager.\u001b[39;00m\n\u001b[32m    497\u001b[39m     \u001b[38;5;66;03m# The group chat manager will start the group chat by relaying the message to the participants\u001b[39;00m\n\u001b[32m    498\u001b[39m     \u001b[38;5;66;03m# and the group chat manager.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._runtime.send_message(\n\u001b[32m    500\u001b[39m         GroupChatStart(messages=messages),\n\u001b[32m    501\u001b[39m         recipient=AgentId(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mself\u001b[39m._group_chat_manager_topic_type, key=\u001b[38;5;28mself\u001b[39m._team_id),\n\u001b[32m    502\u001b[39m         cancellation_token=cancellation_token,\n\u001b[32m    503\u001b[39m     )\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Collect the output messages in order.\u001b[39;00m\n\u001b[32m    505\u001b[39m     output_messages: List[BaseAgentEvent | BaseChatMessage] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py:383\u001b[39m, in \u001b[36mSingleThreadedAgentRuntime.send_message\u001b[39m\u001b[34m(self, message, recipient, sender, cancellation_token, message_id)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._message_queue.put(\n\u001b[32m    370\u001b[39m     SendMessageEnvelope(\n\u001b[32m    371\u001b[39m         message=message,\n\u001b[32m   (...)\u001b[39m\u001b[32m    378\u001b[39m     )\n\u001b[32m    379\u001b[39m )\n\u001b[32m    381\u001b[39m cancellation_token.link_future(future)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py:506\u001b[39m, in \u001b[36mSingleThreadedAgentRuntime._process_send\u001b[39m\u001b[34m(self, message_envelope)\u001b[39m\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tracer_helper.trace_block(\n\u001b[32m    495\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprocess\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    496\u001b[39m         recipient_agent.id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    503\u001b[39m         ),\n\u001b[32m    504\u001b[39m     ):\n\u001b[32m    505\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m MessageHandlerContext.populate_context(recipient_agent.id):\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m             response = \u001b[38;5;28;01mawait\u001b[39;00m recipient_agent.on_message(\n\u001b[32m    507\u001b[39m                 message_envelope.message,\n\u001b[32m    508\u001b[39m                 ctx=message_context,\n\u001b[32m    509\u001b[39m             )\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message_envelope.future.cancelled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_core\\_base_agent.py:119\u001b[39m, in \u001b[36mBaseAgent.on_message\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Any, ctx: MessageContext) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_message_impl(message, ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py:67\u001b[39m, in \u001b[36mSequentialRoutedAgent.on_message_impl\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fifo_lock.acquire()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().on_message_impl(message, ctx)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Release the FIFO lock to allow the next message to be processed.\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m._fifo_lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_core\\_routed_agent.py:485\u001b[39m, in \u001b[36mRoutedAgent.on_message_impl\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    484\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m h.router(message, ctx):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m h(\u001b[38;5;28mself\u001b[39m, message, ctx)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.on_unhandled_message(message, ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_core\\_routed_agent.py:389\u001b[39m, in \u001b[36mrpc.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in target types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m return_value = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, message, ctx)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m AnyType \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m return_types \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(return_value) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m return_types:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat_manager.py:129\u001b[39m, in \u001b[36mBaseGroupChatManager.handle_start\u001b[39m\u001b[34m(self, message, ctx)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Link the select speaker future to the cancellation token.\u001b[39;00m\n\u001b[32m    128\u001b[39m ctx.cancellation_token.link_future(speaker_name_future)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m speaker_name = \u001b[38;5;28;01mawait\u001b[39;00m speaker_name_future\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m speaker_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._participant_name_to_topic_type:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpeaker \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspeaker_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in participant names.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_selector_group_chat.py:209\u001b[39m, in \u001b[36mSelectorGroupChatManager.select_speaker\u001b[39m\u001b[34m(self, thread)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Select the next speaker.\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(participants) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     agent_name = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._select_speaker(roles, participants, \u001b[38;5;28mself\u001b[39m._max_selector_attempts)\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    211\u001b[39m     agent_name = participants[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_selector_group_chat.py:266\u001b[39m, in \u001b[36mSelectorGroupChatManager._select_speaker\u001b[39m\u001b[34m(self, roles, participants, max_attempts)\u001b[39m\n\u001b[32m    264\u001b[39m     response = chunk\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_client.create(messages=select_speaker_messages)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.content, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    268\u001b[39m select_speaker_messages.append(AssistantMessage(content=response.content, source=\u001b[33m\"\u001b[39m\u001b[33mselector\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:624\u001b[39m, in \u001b[36mBaseOpenAIChatCompletionClient.create\u001b[39m\u001b[34m(self, messages, tools, json_output, extra_create_args, cancellation_token)\u001b[39m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    623\u001b[39m     cancellation_token.link_future(future)\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m create_params.response_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    626\u001b[39m     result = cast(ParsedChatCompletion[Any], result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2585\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2539\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   2540\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   2541\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2582\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2583\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m   2584\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2587\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2588\u001b[39m             {\n\u001b[32m   2589\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2590\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2591\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2592\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2593\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2594\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2595\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2596\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2597\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2598\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2599\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2600\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2601\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2602\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2603\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2604\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2605\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2606\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2607\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2608\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2609\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2610\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2611\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2612\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2613\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2614\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2615\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2616\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2617\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2618\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2619\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2620\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2621\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2622\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2623\u001b[39m             },\n\u001b[32m   2624\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2625\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2626\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2627\u001b[39m         ),\n\u001b[32m   2628\u001b[39m         options=make_request_options(\n\u001b[32m   2629\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2630\u001b[39m         ),\n\u001b[32m   2631\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   2632\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2633\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2634\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1782\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1790\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1791\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SanjeetKumar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1594\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1591\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1593\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1594\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "# Run the task\n",
    "task = \"What is the current weather in Dubai, and how much is 100 USD in AED?\"\n",
    "await Console(team.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom selector function\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "def selector_func(messages: Sequence[AgentEvent | ChatMessage]) -> str | None:\n",
    "    if messages[-1].source != planning_agent.name:\n",
    "        return planning_agent.name\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset()\n",
    "team = SelectorGroupChat(\n",
    "    [planning_agent, weather_agent, currency_agent],\n",
    "    model_client=model_client,\n",
    "    termination_condition=termination,\n",
    "    allow_repeated_speaker=True,\n",
    "    selector_func=selector_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the current weather in Dubai, and how much is 100 USD in AED?\n",
      "---------- TextMessage (PlanningAgent) ----------\n",
      "1. WeatherAgent: Check the current weather in Dubai.  \n",
      "2. CurrencyAgent: Convert 100 USD to AED.  \n",
      "---------- ToolCallRequestEvent (WeatherAgent) ----------\n",
      "[FunctionCall(id='call_bOQUUIBjZB0LmQ65TdJoXu1m', arguments='{\"city\":\"Dubai\"}', name='weather_check_tool')]\n",
      "---------- ToolCallExecutionEvent (WeatherAgent) ----------\n",
      "[FunctionExecutionResult(content='Sunny, 35°C', name='weather_check_tool', call_id='call_bOQUUIBjZB0LmQ65TdJoXu1m', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (WeatherAgent) ----------\n",
      "Sunny, 35°C\n",
      "---------- TextMessage (PlanningAgent) ----------\n",
      "1. CurrencyAgent: Convert 100 USD to AED.  \n",
      "---------- ToolCallRequestEvent (CurrencyAgent) ----------\n",
      "[FunctionCall(id='call_VeAASMMAaFy0Vpk8WDeTzg87', arguments='{\"amount\":100,\"from_currency\":\"USD\",\"to_currency\":\"AED\"}', name='currency_exchange_tool')]\n",
      "---------- ToolCallExecutionEvent (CurrencyAgent) ----------\n",
      "[FunctionExecutionResult(content='100.0 USD is equal to 367.00 AED.', name='currency_exchange_tool', call_id='call_VeAASMMAaFy0Vpk8WDeTzg87', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (CurrencyAgent) ----------\n",
      "100.0 USD is equal to 367.00 AED.\n",
      "---------- TextMessage (PlanningAgent) ----------\n",
      "Summary:  \n",
      "- The current weather in Dubai is sunny with a temperature of 35°C.  \n",
      "- 100 USD equals 367.00 AED.  \n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What is the current weather in Dubai, and how much is 100 USD in AED?', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=130, completion_tokens=27), metadata={}, content='1. WeatherAgent: Check the current weather in Dubai.  \\n2. CurrencyAgent: Convert 100 USD to AED.  ', type='TextMessage'), ToolCallRequestEvent(source='WeatherAgent', models_usage=RequestUsage(prompt_tokens=126, completion_tokens=16), metadata={}, content=[FunctionCall(id='call_bOQUUIBjZB0LmQ65TdJoXu1m', arguments='{\"city\":\"Dubai\"}', name='weather_check_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='WeatherAgent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='Sunny, 35°C', name='weather_check_tool', call_id='call_bOQUUIBjZB0LmQ65TdJoXu1m', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='WeatherAgent', models_usage=None, metadata={}, content='Sunny, 35°C', type='ToolCallSummaryMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=172, completion_tokens=14), metadata={}, content='1. CurrencyAgent: Convert 100 USD to AED.  ', type='TextMessage'), ToolCallRequestEvent(source='CurrencyAgent', models_usage=RequestUsage(prompt_tokens=182, completion_tokens=26), metadata={}, content=[FunctionCall(id='call_VeAASMMAaFy0Vpk8WDeTzg87', arguments='{\"amount\":100,\"from_currency\":\"USD\",\"to_currency\":\"AED\"}', name='currency_exchange_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='CurrencyAgent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='100.0 USD is equal to 367.00 AED.', name='currency_exchange_tool', call_id='call_VeAASMMAaFy0Vpk8WDeTzg87', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='CurrencyAgent', models_usage=None, metadata={}, content='100.0 USD is equal to 367.00 AED.', type='ToolCallSummaryMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=209, completion_tokens=36), metadata={}, content='Summary:  \\n- The current weather in Dubai is sunny with a temperature of 35°C.  \\n- 100 USD equals 367.00 AED.  \\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"What is the current weather in Dubai, and how much is 100 USD in AED?\"\n",
    "await Console(team.run_stream(task=task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
