{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_KEY = os.getenv(\"api_key\")\n",
    "AZURE_DEPLOYMENT_NAME = os.getenv(\"model-name\")\n",
    "API_VERSION = os.getenv(\"api-version\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"azure_endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "# Create Azure Model Client\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    deployment_name=AZURE_DEPLOYMENT_NAME ,  # Your deployment name\n",
    "    model =AZURE_DEPLOYMENT_NAME \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core.models import UserMessage\n",
    "\n",
    "result = await model_client.create([UserMessage(content=\"Tell me a joke.\", source=\"user\")])\n",
    "print(\"OpenAI Response:\", result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_message = TextMessage(content=\"What is the current date and time?\", source=\"user\")\n",
    "\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "\n",
    "response = await assistant.on_messages([text_message], cancellation_token=CancellationToken())\n",
    "print(response.chat_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to get the current date and time\n",
    "async def get_current_datetime() -> str:\n",
    "    \"\"\"Gets the current date and time.\"\"\"\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_current_datetime],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"What is the current date and time?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(\"Response:\", response)\n",
    "print(\"Final Response:\", response.chat_message)\n",
    "print(\"Inner Messages:\", response.inner_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using run()\n",
    "task_result = await agent.run(\n",
    "    task=[TextMessage(content=\"What is the current date and time?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(\"Task Result:\", task_result)\n",
    "print(\"Final Response:\", task_result.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which will be used as a tool\n",
    "async def get_current_datetime() -> str:\n",
    "    \"\"\"Gets the current date and time.\"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_core.tools import FunctionTool\n",
    "import datetime\n",
    "\n",
    "# Function can be used as tool like below by directly specifying the function name\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_current_datetime],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")\n",
    "\n",
    "# Or function can be used with tool with the help of FunctionTool\n",
    "# This step happens automatically inside the AssistantAgent if the tool is a Python function.\n",
    "get_datetime_tool = FunctionTool(get_current_datetime, description=\"Gets the current date and time\")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_datetime_tool],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_datetime_tool],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    "    reflect_on_tool_use=True\n",
    ")\n",
    "response = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"What is the current date and time?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(\"Final Response:\", response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_datetime_tool],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    "    reflect_on_tool_use=True\n",
    ")\n",
    "response = await agent.on_messages(\n",
    "    messages=[TextMessage(content=\"What is the current date and time?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(\"Final Response:\", response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.agents import UserProxyAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "\n",
    "async def simple_user_agent():\n",
    "    agent = UserProxyAgent(\"user_proxy\")\n",
    "    response = await asyncio.create_task(\n",
    "        agent.on_messages(\n",
    "            [TextMessage(content=\"What is your name? \", source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "    )\n",
    "    print(f\"Your name is {response.chat_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_user_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burj_khalifa_height(prompt: str) -> str:\n",
    "        return \"The height of the Burj Khalifa is 100 ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = UserProxyAgent(name=\"test_user\", input_func=burj_khalifa_height)\n",
    "messages = [TextMessage(content=\"What is the height of Burj Khalifa?\", source=\"assistant\")]\n",
    "\n",
    "response = await agent.on_messages(messages, CancellationToken())\n",
    "\n",
    "print(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import PIL\n",
    "from autogen_agentchat.messages import MultiModalMessage\n",
    "from autogen_core import Image\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"images/forest.png\"  \n",
    "pil_image = PIL.Image.open(image_path)\n",
    "img = Image(pil_image)\n",
    "\n",
    "multi_modal_message = MultiModalMessage(\n",
    "    content=[\n",
    "        \"Please describe the general content of this image, focusing on the forest environment. Also, try to locate and describe the cat within the image.\",\n",
    "        img\n",
    "    ],\n",
    "    source=\"user\"\n",
    ")\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.on_messages([multi_modal_message], CancellationToken())\n",
    "print(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=model_client,\n",
    "    model_client_stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assistant_run_stream() -> None:\n",
    "    # Option 1: read each message from the stream (as shown in the previous example).\n",
    "    # async for message in agent.on_messages_stream(\n",
    "    #     [TextMessage(content=\"Share information about azure ai search.\", source=\"user\")],\n",
    "    #     cancellation_token=CancellationToken(),\n",
    "    # ):\n",
    "    #     print(message)\n",
    "\n",
    "    # Option 2: use Console to print all messages as they appear.\n",
    "    await Console(\n",
    "        agent.on_messages_stream(\n",
    "            [TextMessage(content=\"Share information about azure ai search.\", source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        ),\n",
    "        output_stats=True,  # Enable stats printing.\n",
    "    )\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run_stream()) when running in a script.\n",
    "await assistant_run_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "# Create the BlogPostDraftAgent\n",
    "blog_post_draft_agent = AssistantAgent(\n",
    "    \"BlogPostDraftAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a blog post drafting agent. Your task is to generate an outline or initial draft of a blog post or article based on the topic provided. Make sure to include clear sections, headings, and a logical flow.\"\n",
    ")\n",
    "\n",
    "# Create the BlogPostEnhancementAgent\n",
    "blog_post_enhancement_agent = AssistantAgent(\n",
    "    \"BlogPostEnhancementAgent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a blog post enhancement agent. Your task is to improve the draft provided by the drafting agent. Focus on improving readability, adding relevant examples, and optimizing for SEO. If you are satisfied with the final draft, respond with 'FINAL'.\"\n",
    ")\n",
    "\n",
    "# Define the termination condition that stops the task when 'FINAL' is mentioned\n",
    "text_termination = TextMentionTermination(\"FINAL\")\n",
    "\n",
    "# Create a team where the BlogPostDraftAgent and BlogPostEnhancementAgent interact.\n",
    "team = RoundRobinGroupChat(\n",
    "    [blog_post_draft_agent, blog_post_enhancement_agent],\n",
    "    termination_condition=text_termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run a team using team.run() or team.run_stream()\n",
    "async for message in team.run_stream(task=\"Create a short blog post about the benefits of using AI in e-commerce.\"): \n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset()  # Reset the team for the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await Console(team.run_stream(task=\"Create a short blog post about the benefits of using AI in e-commerce.\"))  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the agents.\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)  # Use input() to get user input from console.\n",
    "\n",
    "# Create the termination condition which will end the conversation when the user says \"APPROVE\".\n",
    "termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create the team.\n",
    "team = RoundRobinGroupChat([assistant, user_proxy], termination_condition=termination)\n",
    "\n",
    "# Run the conversation and stream to the console.\n",
    "stream = team.run_stream(task=\"Suggest three creative ideas for a new mobile app.\")\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the agents.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "\n",
    "# Create the team setting a maximum number of turns to 1.\n",
    "team = RoundRobinGroupChat([assistant], max_turns=1)\n",
    "\n",
    "task = \"Suggest three creative ideas for a new mobile app.\"\n",
    "while True:\n",
    "    # Run the conversation and stream to the console.\n",
    "    stream = team.run_stream(task=task)\n",
    "    # Use asyncio.run(...) when running in a script.\n",
    "    await Console(stream)\n",
    "    # Get the user response.\n",
    "    task = input(\"Enter your feedback (type 'exit' to leave): \")\n",
    "    if task.lower().strip() == \"exit\":\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback for every message. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_msg_termination = MaxMessageTermination(max_messages=3)\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=max_msg_termination)\n",
    "\n",
    "await Console(round_robin_team.run_stream(task=\"Describe a futuristic city in 50 words\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define termination conditions\n",
    "max_msg_termination = MaxMessageTermination(max_messages=10)\n",
    "critic_approval_termination = TextMentionTermination(text=\"APPROVE\")\n",
    "\n",
    "# Combine conditions using OR (|)\n",
    "combined_termination = max_msg_termination | critic_approval_termination\n",
    "\n",
    "# Create a round-robin team with the combined termination condition\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=combined_termination)\n",
    "\n",
    "# Execute the conversation task\n",
    "await Console(round_robin_team.run_stream(task=\"Provide a summary of the latest advancements in AI.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
