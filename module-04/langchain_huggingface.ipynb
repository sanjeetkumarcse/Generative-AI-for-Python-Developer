{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "Yu-MtshyQDQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "gFfq1OWYQKbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec1vqlAqMaK6"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "print(hf_token)"
      ],
      "metadata": {
        "id": "96dpyv9SQXXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN = hf_token"
      ],
      "metadata": {
        "id": "gfxIncIyRUW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm = HuggingFaceEndpoint(repo_id= repo_id, temperature=0.7 )"
      ],
      "metadata": {
        "id": "tk2iNMN_Q9uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is Machine Learninig\")"
      ],
      "metadata": {
        "id": "1Oyku-EQRd7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient"
      ],
      "metadata": {
        "id": "mRqsSdrqVmDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = InferenceClient(model= repo_id , token= HUGGINGFACEHUB_API_TOKEN)"
      ],
      "metadata": {
        "id": "CdUVyKh0V8fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat_completion(\n",
        "    messages = [\n",
        "        {\"role\" : \"system\" , \"content\" : \"You are a helpful assistant\"},\n",
        "        {\"role\" : \"user\" , \"content\" : \"What is Machine Learning\"}\n",
        "    ]\n",
        "\n",
        ")\n",
        "print(response.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "id": "rA1JiJdqWWEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKk9qErrXj-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}