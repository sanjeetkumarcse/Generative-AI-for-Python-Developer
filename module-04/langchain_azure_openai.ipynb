{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAAdwPoJXpMS",
        "outputId": "14f51e84-7e23-40af-cb22-588047c6b880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.78)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR6Q9WdbYDHS"
      },
      "outputs": [],
      "source": [
        "# Azure OpenAI\n",
        "AZURE_OPENAI_ENDPOINT = \"\"\n",
        "AZURE_OPENAI_KEY = \"\"\n",
        "DEPLOYMENT_NAME = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9PybBzaYhMp",
        "outputId": "c2dbaa7e-77db-4450-88e0-3dbe48ea456c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.33)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.31 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5c41256d2f7243e6b445197a2cf03ee4",
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGEMpFrJYKzs"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njocqqt2YeH9",
        "outputId": "ead93e97-d31c-494d-f8c2-39af96487583"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1008584197.py:1: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
            "  llm = AzureChatOpenAI(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    openai_api_base=AZURE_OPENAI_ENDPOINT,\n",
        "    openai_api_key=AZURE_OPENAI_KEY,\n",
        "    openai_api_version=\"2023-03-15-preview\",\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    openai_api_type=\"azure\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9WQGcgvZc56",
        "outputId": "02a5297c-c5c1-4c27-a79b-49f463908bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=[' user_input'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[' user_input'], input_types={}, partial_variables={}, template=' You are a helpful assitant. \\n User: { user_input}\\n Assistant:'), additional_kwargs={})]\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(\" You are a helpful assitant. \\n User: { user_input}\\n Assistant:\")\n",
        "print(prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0QSCmwAahlC",
        "outputId": "f65de739-5a0b-4023-f3e4-a73d5689462c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-960525285.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8jAWaFaz_q",
        "outputId": "68f59638-5fc6-44b2-c2a8-3ac6cf68747c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Tell me about delhi\n",
            "Assistant:  Certainly! Delhi, officially known as the National Capital Territory of Delhi (NCT), is one of the most vibrant and historically rich cities in India. It serves as the political, cultural, and administrative hub of the country. Here are some key aspects of Delhi:\n",
            "\n",
            "---\n",
            "\n",
            "### **Geography and Location**\n",
            "- **Location:** Delhi is located in northern India and sits on the banks of the Yamuna River. It shares its borders with Haryana and Uttar Pradesh.\n",
            "- **Area:** The NCT covers an area of approximately 1,484 square kilometers.\n",
            "- **Climate:** Delhi has an extreme climate with hot summers, cold winters, and a monsoon season. Summers can reach temperatures above 40°C (104°F), while winters can dip below 5°C (41°F).\n",
            "\n",
            "---\n",
            "\n",
            "### **History**\n",
            "Delhi has a rich history that spans thousands of years. It has been the center of several powerful empires and has seen the rise and fall of many dynasties:\n",
            "- **Ancient Delhi:** Delhi is believed to be the site of Indraprastha, the legendary capital of the Pandavas in the Mahabharata.\n",
            "- **Medieval Era:** The city was ruled by various dynasties, including the Delhi Sultanate and the Mughals, who left behind iconic structures like the Qutub Minar, Red Fort, and Humayun's Tomb.\n",
            "- **British Rule:** Delhi became an important city under British colonial rule. In 1911, the British shifted the capital from Calcutta (Kolkata) to Delhi.\n",
            "- **Modern Delhi:** After India's independence in 1947, Delhi became the capital of the country.\n",
            "\n",
            "---\n",
            "\n",
            "### **Culture**\n",
            "Delhi is a melting pot of cultures and traditions:\n",
            "- **Languages:** Hindi and English are widely spoken, along with Punjabi, Urdu, and other regional languages.\n",
            "- **Festivals:** The city celebrates major Indian festivals like Diwali, Holi, Eid, Christmas, and Navratri with great enthusiasm.\n",
            "- **Cuisine:** Delhi is famous for its diverse food scene, including street food like chaat, golgappa, kebabs, butter chicken, and parathas from Paranthe Wali Gali in Chandni Chowk.\n",
            "\n",
            "---\n",
            "\n",
            "### **Landmarks and Attractions**\n",
            "Delhi is home to numerous historical and modern attractions:\n",
            "1. **Historical Sites:**\n",
            "   - Red Fort: A UNESCO World Heritage Site and a symbol of India's independence.\n",
            "   - Qutub Minar: An iconic minaret built during the Delhi Sultanate era.\n",
            "   - India Gate: A war memorial honoring Indian soldiers.\n",
            "   - Humayun's Tomb: A precursor to the Taj Mahal's architectural style.\n",
            "   - Lotus Temple: A stunning Baháʼí House of Worship.\n",
            "\n",
            "2. **Modern Attractions:**\n",
            "   - Akshardham Temple: A magnificent Hindu temple showcasing Indian culture and spirituality.\n",
            "   - Connaught Place: A bustling commercial hub.\n",
            "   - Dilli Haat: A vibrant marketplace for handicrafts and traditional cuisine.\n",
            "\n",
            "---\n",
            "\n",
            "### **Government and Politics**\n",
            "- Delhi is a union territory with a special status. It has its own legislative assembly and functions under the central government of India.\n",
            "- The city is the seat of the Indian government, housing the Rashtrapati Bhavan (President's residence), Parliament House, and various ministries.\n",
            "\n",
            "---\n",
            "\n",
            "### **Transportation**\n",
            "- **Metro:** The Delhi Metro is a world-class rapid transit system that connects various parts of the city.\n",
            "- **Airports:** Indira Gandhi International Airport serves as a major aviation hub.\n",
            "- **Roadways:** Delhi has an extensive network of roads and highways, with auto-rickshaws, buses, and taxis being common modes of transport.\n",
            "\n",
            "---\n",
            "\n",
            "### **Challenges**\n",
            "Like many major cities, Delhi faces challenges such as:\n",
            "- **Pollution:** Air quality in Delhi can be poor, especially during winter months due to smog.\n",
            "- **Traffic Congestion:** The city experiences heavy traffic due to a growing population and vehicle usage.\n",
            "- **Urbanization:** Rapid urbanization has led to infrastructure strain.\n",
            "\n",
            "---\n",
            "\n",
            "### **Interesting Facts**\n",
            "- Delhi has been destroyed and rebuilt multiple times throughout history.\n",
            "- The Delhi Metro is one of the cleanest and most efficient metro systems in the world.\n",
            "- The city is often referred to as \"Dilwalon Ki Dilli,\" meaning \"Delhi belongs to the kind-hearted.\"\n",
            "\n",
            "---\n",
            "\n",
            "If you’d like to know more about any specific aspect of Delhi, feel free to ask! 😊\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input == \"exit\":\n",
        "    break\n",
        "  response = chain.run(user_input)\n",
        "  print(\"Assistant: \", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aX8K3hVb6XD",
        "outputId": "f625fe97-469e-4521-e0b5-dd2cf26d8019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n",
            "content='The capital of France is **Paris**.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'finish_reason': 'stop', 'logprobs': None} id='run--cb8d949c-9746-4520-a846-d7bd247793f4-0'\n",
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"What is the capital of France?\")\n",
        "]\n",
        "\n",
        "print(messages)\n",
        "Output = llm.invoke(messages)\n",
        "print(Output)\n",
        "print(Output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xT_lHrpjgB1",
        "outputId": "854239aa-ae1e-450e-ce39-2171ea3da47d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Sure! Here's one for you:\\n\\nWhy don’t skeletons fight each other?\\n\\nBecause they don’t have the guts!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--1efb12fc-9f04-4eec-bf05-c1b610ca41f1-0'\n",
            "CPU times: user 5.07 ms, sys: 0 ns, total: 5.07 ms\n",
            "Wall time: 409 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = \"Tell me a joke\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYic17EfkQYW"
      },
      "outputs": [],
      "source": [
        "from langchain.globals import set_llm_cache\n",
        "from langchain.cache import InMemoryCache\n",
        "set_llm_cache(InMemoryCache())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y121S_WklaK",
        "outputId": "d60f7f73-c7e1-4ce5-84bb-232d2a898249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Sure! Here's one:\\n\\nWhy don't skeletons fight each other?\\n\\nBecause they don't have the guts!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--a67ec375-ff38-4511-977d-b3dee8d148ce-0'\n",
            "CPU times: user 5.3 ms, sys: 38 µs, total: 5.34 ms\n",
            "Wall time: 430 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = \"Tell me a joke\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuCAjSjHkrbS",
        "outputId": "0096e1e5-aefa-4434-c2c5-55406f51e242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Sure! Here's one:\\n\\nWhy don't skeletons fight each other?\\n\\nBecause they don't have the guts!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'finish_reason': 'stop', 'logprobs': None} id='run--a67ec375-ff38-4511-977d-b3dee8d148ce-0' usage_metadata={'total_cost': 0}\n",
            "CPU times: user 755 µs, sys: 0 ns, total: 755 µs\n",
            "Wall time: 747 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = \"Tell me a joke\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psm5ck6ik12o"
      },
      "outputs": [],
      "source": [
        "from langchain.cache import SQLiteCache\n",
        "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtkVCIIZlHr-",
        "outputId": "784dfec1-4523-46b5-b324-1e951aaa9afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Sure! Here's a light-hearted joke for you:\\n\\nWhy don’t skeletons fight each other?  \\nBecause they don’t have the guts!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 11, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'finish_reason': 'stop', 'logprobs': None} id='run--91d04b8d-1a30-4e8a-8926-3dcae025780f-0'\n",
            "CPU times: user 22.4 ms, sys: 1.16 ms, total: 23.5 ms\n",
            "Wall time: 591 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = \"Tell me a joke\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBpkQLKDlLxH",
        "outputId": "b3226787-48fa-40ac-fce2-30e61d8b2a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content=\"Sure! Here's a light-hearted joke for you:\\n\\nWhy don’t skeletons fight each other?  \\nBecause they don’t have the guts!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 11, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'finish_reason': 'stop', 'logprobs': None} id='run--91d04b8d-1a30-4e8a-8926-3dcae025780f-0' usage_metadata={'total_cost': 0}\n",
            "CPU times: user 2.97 ms, sys: 0 ns, total: 2.97 ms\n",
            "Wall time: 2.74 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = \"Tell me a joke\"\n",
        "response = llm.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cDbCtNJlO0H",
        "outputId": "41e25dac-815f-43ec-b4ae-c766d819f99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Title: \"Howlin' at the Moon\"**\n",
            "\n",
            "*(Verse 1)*  \n",
            "Underneath the silver glow, it pulls me in, I lose control  \n",
            "The night’s alive, the world stands still, chasing shadows over hills  \n",
            "Up above, that mystic sphere, whispering secrets in my ear  \n",
            "A cosmic dance, a timeless tune, my heart is howlin' at the moon  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, it's calling, calling my name  \n",
            "A wild desire I can't contain  \n",
            "Through the darkness, I rise, I swoon  \n",
            "Forever bound to the light of the moon  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Verse 2)*  \n",
            "Crater scars, its ancient face, a witness to this human race  \n",
            "A tidal pull, a lover’s ache, it stirs the fire, it makes me quake  \n",
            "In its glow, I find my truth, the kind of freedom I can’t lose  \n",
            "A lonely wolf, a midnight croon, I'm alive beneath the moon  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, it's burning, burning my soul  \n",
            "A restless spirit out of control  \n",
            "Through the shadows, the stars in bloom  \n",
            "Forever chasing the glow of the moon  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Bridge)*  \n",
            "It’s the keeper of dreams, the watcher of skies  \n",
            "A beacon of hope when the sun says goodbye  \n",
            "Through the chaos and storms, it shines ever bright  \n",
            "A force of nature, my muse in the night  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Outro)*  \n",
            "So here I stand, beneath its glow  \n",
            "A wanderer’s anthem, a tale to show  \n",
            "No turning back, I’m forever in tune  \n",
            "With the magic of howlin' at the moon  \n",
            "CPU times: user 8.91 ms, sys: 885 µs, total: 9.79 ms\n",
            "Wall time: 3.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = 'write a rock song about moon.'\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z69iB2I-nLcH",
        "outputId": "bf86650c-dfa4-447b-dffa-31572427ced2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Title: \"Howlin' at the Moon\"**\n",
            "\n",
            "*(Verse 1)*  \n",
            "Underneath the silver glow, it pulls me in, I lose control  \n",
            "The night’s alive, the world stands still, chasing shadows over hills  \n",
            "Up above, that mystic sphere, whispering secrets in my ear  \n",
            "A cosmic dance, a timeless tune, my heart is howlin' at the moon  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, it's calling, calling my name  \n",
            "A wild desire I can't contain  \n",
            "Through the darkness, I rise, I swoon  \n",
            "Forever bound to the light of the moon  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Verse 2)*  \n",
            "Crater scars, its ancient face, a witness to this human race  \n",
            "A tidal pull, a lover’s ache, it stirs the fire, it makes me quake  \n",
            "In its glow, I find my truth, the kind of freedom I can’t lose  \n",
            "A lonely wolf, a midnight croon, I'm alive beneath the moon  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, it's burning, burning my soul  \n",
            "A restless spirit out of control  \n",
            "Through the shadows, the stars in bloom  \n",
            "Forever chasing the glow of the moon  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Bridge)*  \n",
            "It’s the keeper of dreams, the watcher of skies  \n",
            "A beacon of hope when the sun says goodbye  \n",
            "Through the chaos and storms, it shines ever bright  \n",
            "A force of nature, my muse in the night  \n",
            "\n",
            "*(Chorus)*  \n",
            "Howlin' at the moon tonight  \n",
            "Let it take me, let it guide my fight  \n",
            "A rebel’s heart in the lunar light  \n",
            "Howlin' at the moon, feels so right  \n",
            "\n",
            "*(Outro)*  \n",
            "So here I stand, beneath its glow  \n",
            "A wanderer’s anthem, a tale to show  \n",
            "No turning back, I’m forever in tune  \n",
            "With the magic of howlin' at the moon  \n",
            "CPU times: user 2.74 ms, sys: 25 µs, total: 2.77 ms\n",
            "Wall time: 2.56 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = 'write a rock song about moon.'\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-4KKuywnTiW",
        "outputId": "755d2603-da2f-479e-9229-db807522125e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**\"Eclipse of Fire\"**  \n",
            "*(A Rock Anthem about the Moon and Sun)*  \n",
            "\n",
            "---\n",
            "\n",
            "**[Verse 1]**  \n",
            "The moon whispers secrets in the dead of night,  \n",
            "Silver shadows dance beneath its pale light.  \n",
            "It’s a quiet rebel, cold and untamed,  \n",
            "A lonely traveler with no one to blame.  \n",
            "\n",
            "The sun roars loud, a burning king of fire,  \n",
            "Rising high, it fuels the world's desire.  \n",
            "Golden rays cut through the darkest skies,  \n",
            "It’s the heart of life, where all hope lies.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Pre-Chorus]**  \n",
            "Two forces collide, pulling on my soul,  \n",
            "Caught in the gravity, losing control.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Chorus]**  \n",
            "Moon and sun, locked in a cosmic fight,  \n",
            "Day turns to darkness, and shadows ignite.  \n",
            "Eclipse of fire, a dance of despair,  \n",
            "We’re caught in the crossfire, gasping for air.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Verse 2]**  \n",
            "The moon’s a poet, spinning songs of the past,  \n",
            "Its light fades slowly, but its beauty lasts.  \n",
            "The sun’s a warrior, blazing trails up high,  \n",
            "It rules the heavens, never asking why.  \n",
            "\n",
            "They meet in silence, an eternal chase,  \n",
            "One hides the other in a fleeting embrace.  \n",
            "The skies tremble as the worlds collide,  \n",
            "A fleeting moment where they cannot hide.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Pre-Chorus]**  \n",
            "Two forces collide, pulling on my soul,  \n",
            "Caught in the gravity, losing control.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Chorus]**  \n",
            "Moon and sun, locked in a cosmic fight,  \n",
            "Day turns to darkness, and shadows ignite.  \n",
            "Eclipse of fire, a dance of despair,  \n",
            "We’re caught in the crossfire, gasping for air.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Bridge]**  \n",
            "Oh, the sun burns bright but it’ll never know,  \n",
            "The quiet moon holds secrets it can’t show.  \n",
            "Opposites drawn but they can’t be one,  \n",
            "The endless war of the moon and sun.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Chorus]**  \n",
            "Moon and sun, locked in a cosmic fight,  \n",
            "Day turns to darkness, and shadows ignite.  \n",
            "Eclipse of fire, a dance of despair,  \n",
            "We’re caught in the crossfire, gasping for air.  \n",
            "\n",
            "---\n",
            "\n",
            "**[Outro]**  \n",
            "The moon will rise, the sun will set,  \n",
            "They’ll chase each other ‘til the end, I bet.  \n",
            "Eternal rivals under heaven's dome,  \n",
            "Two restless spirits that’ll never find home.  \n",
            "CPU times: user 16.6 ms, sys: 1.02 ms, total: 17.6 ms\n",
            "Wall time: 4.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = 'write a rock song about moon and sun.'\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqwNWl6And_8",
        "outputId": "a605f281-2caa-4844-c139-64d2ef78bc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Title: \"Chasing the Moon, Dancing with the Sun\"**\n",
            "\n",
            "*(Verse 1)*  \n",
            "I’ve been running through the shadows, trying to find my light,  \n",
            "Caught between the darkness and the fire burning bright.  \n",
            "The moon whispers secrets in the stillness of the night,  \n",
            "The sun pulls me closer, sets my soul alight.  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, they’re pulling me apart, but I can’t turn away,  \n",
            "Chasing the moon, while the sun begs me to stay.  \n",
            "\n",
            "*(Chorus)*  \n",
            "Moon and sun, they collide in my mind,  \n",
            "One’s a quiet dream, the other’s wild and untamed.  \n",
            "I’m chasing the moon, dancing with the sun,  \n",
            "Caught in their orbit, I’ll never outrun.  \n",
            "\n",
            "*(Verse 2)*  \n",
            "Silver shadows guide me where the moonlight breaks,  \n",
            "But the golden rays of morning leave me wide awake.  \n",
            "They’re opposites, they’re rivals, yet they share the same sky,  \n",
            "And I’m stuck somewhere in the middle, asking myself why.  \n",
            "\n",
            "*(Pre-Chorus)*  \n",
            "Oh, they tear me in two, but I’ll never let go,  \n",
            "Chasing the moon, as the sun steals the show.  \n",
            "\n",
            "*(Chorus)*  \n",
            "Moon and sun, they collide in my mind,  \n",
            "One’s a quiet dream, the other’s wild and untamed.  \n",
            "I’m chasing the moon, dancing with the sun,  \n",
            "Caught in their orbit, I’ll never outrun.  \n",
            "\n",
            "*(Bridge)*  \n",
            "The moon says, “Follow me, I’ll show you the stars,”  \n",
            "The sun says, “Stay with me, I’ll heal your scars.”  \n",
            "I’m torn between the night and the burning day,  \n",
            "But maybe I need both to find my way.  \n",
            "\n",
            "*(Solo)*  \n",
            "(Guitar wails like the clash of light and dark, building tension and release.)  \n",
            "\n",
            "*(Final Chorus)*  \n",
            "Moon and sun, they collide in my soul,  \n",
            "Tugging at my heart, making me whole.  \n",
            "I’m chasing the moon, dancing with the sun,  \n",
            "Living in their rhythm, until my time is done.  \n",
            "\n",
            "*(Outro)*  \n",
            "So I’ll chase the moon, and I’ll dance with the sun,  \n",
            "Caught in their battle, but I know I’ve won.  CPU times: user 631 ms, sys: 70.2 ms, total: 701 ms\n",
            "Wall time: 3.98 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt = 'write a rock new song about moon and sun.'\n",
        "for chunk in llm.stream(prompt):\n",
        "  print(chunk.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQlG-dMoGqo8",
        "outputId": "cbff6244-4f47-4f17-fb69-9ea8b36d532a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human:  You are a experienced machine learinig engineer.\n",
            "choose which type of problem is this you have to predict how much icecrea will sale in this festival sale is based on data and desire result in hindi.\n"
          ]
        }
      ],
      "source": [
        "template = ''' You are a experienced machine learinig engineer.\n",
        "choose which type of problem is this {problem} is based on data and desire result in {language}.'''\n",
        "\n",
        "prompt_template = prompt_template.from_template(template)\n",
        "\n",
        "prompt = prompt_template.format(problem=\"you have to predict how much icecrea will sale in this festival sale\", language=\"hindi\")\n",
        "print(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nycp6bUAHebL",
        "outputId": "3f140736-cb35-4edf-f887-705b24fb4746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This type of problem falls under **Regression** in machine learning. Regression problems are used when the goal is to predict a continuous numerical value, such as sales, prices, or temperatures, based on input data.\n",
            "\n",
            "Here’s how it applies to your situation:\n",
            "\n",
            "- **Problem Type:** Predicting how much ice cream will sell during a festival.\n",
            "- **Input Data:** Historical data, such as weather conditions, previous festival sales, date, time, location, etc.\n",
            "- **Output:** A continuous numerical value (amount of ice cream sales).\n",
            "- **Desired Result in Hindi:** अनुमान लगाना कि इस त्यौहार में कितनी आइसक्रीम बिकेगी।\n",
            "\n",
            "### Suitable Algorithms:\n",
            "You can use regression algorithms like:\n",
            "- Linear Regression\n",
            "- Decision Tree Regression\n",
            "- Random Forest Regression\n",
            "- Gradient Boosting (e.g., XGBoost, LightGBM)\n",
            "- Neural Networks (if the data is complex)\n",
            "\n",
            "Let me know if you need guidance on implementing this! 😊\n"
          ]
        }
      ],
      "source": [
        "output = llm.invoke(prompt)\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WvlD6JtJxwr",
        "outputId": "7d997705-f9d2-4f53-99bc-eb78ac93093e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SystemMessage(content='You responsed only in JSON Format.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Top 5 countries in world by population.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import HumanMessagePromptTemplate , ChatMessagePromptTemplate\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "   [\n",
        "       SystemMessage(content=\"You responsed only in JSON Format.\"),\n",
        "       HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
        "   ]\n",
        ")\n",
        "\n",
        "chat_prompt = chat_template.format_prompt(user_input=\"Top 5 countries in world by population.\").to_messages()\n",
        "print(chat_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7r7VR1XLcae",
        "outputId": "b96c4abe-d1b5-45e8-a114-972091dbb8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"top_5_countries_by_population\": [\n",
            "    {\n",
            "      \"rank\": 1,\n",
            "      \"country\": \"China\",\n",
            "      \"population\": \"1,425,000,000\"\n",
            "    },\n",
            "    {\n",
            "      \"rank\": 2,\n",
            "      \"country\": \"India\",\n",
            "      \"population\": \"1,421,000,000\"\n",
            "    },\n",
            "    {\n",
            "      \"rank\": 3,\n",
            "      \"country\": \"United States\",\n",
            "      \"population\": \"336,000,000\"\n",
            "    },\n",
            "    {\n",
            "      \"rank\": 4,\n",
            "      \"country\": \"Indonesia\",\n",
            "      \"population\": \"277,000,000\"\n",
            "    },\n",
            "    {\n",
            "      \"rank\": 5,\n",
            "      \"country\": \"Pakistan\",\n",
            "      \"population\": \"240,000,000\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "output = llm.invoke(chat_prompt)\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0iQ4v8MM852",
        "outputId": "a12290af-1da5-483a-e3e2-cfc43459683e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman:  You are a experienced machine learinig engineer.\n",
            "choose which type of problem is this you have to predict how much icecrea will sale in this festival sale is based on data and desire result in hindi.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'problem': 'you have to predict how much icecrea will sale in this festival sale', 'language': 'hindi', 'text': 'यह समस्या एक **Regression Problem** है। \\n\\nक्योंकि यहाँ आपको ice cream की बिक्री (sale) की मात्रा को एक संख्या या मूल्य के रूप में भविष्यवाणी करनी है। Regression का उपयोग तब किया जाता है जब हमें किसी continuous value (जैसे बिक्री की मात्रा, तापमान, कीमत आदि) का अनुमान लगाना हो। \\n\\nडेटा और त्योहारी बिक्री के पैटर्न के आधार पर आप इस समस्या को हल करने के लिए regression models जैसे Linear Regression, Decision Trees, Random Forest, या Gradient Boosting Algorithms (जैसे XGBoost, LightGBM) का उपयोग कर सकते हैं। \\n\\nअगर डेटा में समय के साथ बिक्री का पैटर्न हो तो आप Time Series Analysis भी कर सकते हैं।'}\n"
          ]
        }
      ],
      "source": [
        "from re import VERBOSE\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "template = ''' You are a experienced machine learinig engineer.\n",
        "choose which type of problem is this {problem} is based on data and desire result in {language}.'''\n",
        "\n",
        "prompt_template = prompt_template.from_template(template)\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template, verbose=True)\n",
        "\n",
        "output = chain.invoke({\"problem\":\"you have to predict how much icecrea will sale in this festival sale\", \"language\":\"hindi\"})\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePgqxpy7NbUl",
        "outputId": "f0354cea-9863-455f-ed05-ac39701fa79c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "यह समस्या एक **Regression Problem** है। \n",
            "\n",
            "क्योंकि यहाँ आपको ice cream की बिक्री (sale) की मात्रा को एक संख्या या मूल्य के रूप में भविष्यवाणी करनी है। Regression का उपयोग तब किया जाता है जब हमें किसी continuous value (जैसे बिक्री की मात्रा, तापमान, कीमत आदि) का अनुमान लगाना हो। \n",
            "\n",
            "डेटा और त्योहारी बिक्री के पैटर्न के आधार पर आप इस समस्या को हल करने के लिए regression models जैसे Linear Regression, Decision Trees, Random Forest, या Gradient Boosting Algorithms (जैसे XGBoost, LightGBM) का उपयोग कर सकते हैं। \n",
            "\n",
            "अगर डेटा में समय के साथ बिक्री का पैटर्न हो तो आप Time Series Analysis भी कर सकते हैं।\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "output = chain.invoke({\"problem\":\"you have to predict how much icecrea will sale in this festival sale\", \"language\":\"hindi\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miA_1i7LPR-T",
        "outputId": "2de892e9-a5d0-4698-e621-a37133c47d83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mCertainly! Below is a Python implementation of a simple Linear Regression model using NumPy. We'll write a function that calculates the coefficients \\( m \\) (slope) and \\( b \\) (intercept) for fitting a straight line \\( y = mx + b \\) to a given dataset of \\( x \\) and \\( y \\).\n",
            "\n",
            "### Linear Regression Function\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def linear_regression(x, y):\n",
            "    \"\"\"\n",
            "    Perform Linear Regression to find the slope (m) and intercept (b) of the line y = mx + b.\n",
            "\n",
            "    Parameters:\n",
            "    x (array-like): Independent variable (input features).\n",
            "    y (array-like): Dependent variable (target values).\n",
            "\n",
            "    Returns:\n",
            "    tuple: (m, b) where m is the slope and b is the intercept.\n",
            "    \"\"\"\n",
            "    # Ensure x and y are numpy arrays\n",
            "    x = np.array(x)\n",
            "    y = np.array(y)\n",
            "\n",
            "    # Calculate the mean of x and y\n",
            "    x_mean = np.mean(x)\n",
            "    y_mean = np.mean(y)\n",
            "\n",
            "    # Calculate the slope (m)\n",
            "    numerator = np.sum((x - x_mean) * (y - y_mean))  # Covariance between x and y\n",
            "    denominator = np.sum((x - x_mean) ** 2)         # Variance of x\n",
            "    m = numerator / denominator\n",
            "\n",
            "    # Calculate the intercept (b)\n",
            "    b = y_mean - m * x_mean\n",
            "\n",
            "    return m, b\n",
            "\n",
            "# Example usage\n",
            "if __name__ == \"__main__\":\n",
            "    # Example data points\n",
            "    x = [1, 2, 3, 4, 5]\n",
            "    y = [2, 4, 5, 4, 5]\n",
            "\n",
            "    # Perform linear regression\n",
            "    slope, intercept = linear_regression(x, y)\n",
            "    print(f\"Slope (m): {slope}\")\n",
            "    print(f\"Intercept (b): {intercept}\")\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "1. **Inputs**:\n",
            "    - `x`: Independent variable (feature).\n",
            "    - `y`: Dependent variable (target).\n",
            "\n",
            "2. **Steps**:\n",
            "    - Compute the mean values of `x` and `y`.\n",
            "    - Calculate the slope \\( m \\) using the formula:\n",
            "      \\[\n",
            "      m = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum{(x_i - \\bar{x})^2}}\n",
            "      \\]\n",
            "    - Calculate the intercept \\( b \\) using the formula:\n",
            "      \\[\n",
            "      b = \\bar{y} - m \\cdot \\bar{x}\n",
            "      \\]\n",
            "\n",
            "3. **Outputs**:\n",
            "    - The slope (\\( m \\)) and intercept (\\( b \\)) of the best-fit line for the given data.\n",
            "\n",
            "You can use this function to fit a linear model to your data and make predictions for new values of \\( x \\) using \\( y = mx + b \\). Let me know if you need help extending this to handle more complex scenarios!\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mCertainly! Below is a Python implementation of a simple Linear Regression model using NumPy. This function takes in the independent variable \\( x \\) and dependent variable \\( y \\) as inputs, calculates their relationship using the line equation \\( y = mx + b \\), and returns the slope \\( m \\) and intercept \\( b \\).\n",
            "\n",
            "### Linear Regression Function\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def linear_regression(x, y):\n",
            "    \"\"\"\n",
            "    Perform Linear Regression to calculate the slope (m) and intercept (b) of the line y = mx + b.\n",
            "\n",
            "    Parameters:\n",
            "    x (array-like): Independent variable (input data).\n",
            "    y (array-like): Dependent variable (output data).\n",
            "\n",
            "    Returns:\n",
            "    tuple: Coefficients (m, b) where m is the slope and b is the intercept.\n",
            "    \"\"\"\n",
            "    # Convert inputs to numpy arrays for easier computation\n",
            "    x = np.array(x)\n",
            "    y = np.array(y)\n",
            "\n",
            "    # Calculate the mean of x and y\n",
            "    x_mean = np.mean(x)\n",
            "    y_mean = np.mean(y)\n",
            "\n",
            "    # Calculate the numerator and denominator for the slope (m)\n",
            "    numerator = np.sum((x - x_mean) * (y - y_mean))  # Covariance between x and y\n",
            "    denominator = np.sum((x - x_mean) ** 2)         # Variance of x\n",
            "    m = numerator / denominator  # Slope\n",
            "\n",
            "    # Calculate the intercept (b)\n",
            "    b = y_mean - (m * x_mean)\n",
            "\n",
            "    return m, b\n",
            "\n",
            "\n",
            "# Example usage\n",
            "if __name__ == \"__main__\":\n",
            "    # Sample dataset\n",
            "    x = [1, 2, 3, 4, 5]\n",
            "    y = [2, 4, 5, 4, 5]\n",
            "\n",
            "    # Perform linear regression\n",
            "    slope, intercept = linear_regression(x, y)\n",
            "    print(f\"Slope (m): {slope:.2f}\")\n",
            "    print(f\"Intercept (b): {intercept:.2f}\")\n",
            "```\n",
            "\n",
            "### Explanation of the Code:\n",
            "1. **Inputs**:\n",
            "   - `x`: A list or array of independent variable values.\n",
            "   - `y`: A list or array of dependent variable values.\n",
            "\n",
            "2. **Steps**:\n",
            "   - **Mean Calculation**: Compute the mean of \\( x \\) and \\( y \\), denoted as \\( \\bar{x} \\) and \\( \\bar{y} \\).\n",
            "   - **Slope Calculation**: The slope \\( m \\) is calculated using the formula:\n",
            "     \\[\n",
            "     m = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum{(x_i - \\bar{x})^2}}\n",
            "     \\]\n",
            "     This is essentially the covariance divided by the variance of \\( x \\).\n",
            "   - **Intercept Calculation**: The intercept \\( b \\) is calculated as:\n",
            "     \\[\n",
            "     b = \\bar{y} - m \\cdot \\bar{x}\n",
            "     \\]\n",
            "\n",
            "3. **Output**:\n",
            "   - Returns the slope \\( m \\) and intercept \\( b \\) of the linear model.\n",
            "\n",
            "### Example Output:\n",
            "For the given example input:\n",
            "```python\n",
            "x = [1, 2, 3, 4, 5]\n",
            "y = [2, 4, 5, 4, 5]\n",
            "```\n",
            "\n",
            "The function produces:\n",
            "```\n",
            "Slope (m): 0.60\n",
            "Intercept (b): 2.80\n",
            "```\n",
            "\n",
            "This means the best-fit line through the input data points is given by the equation:\n",
            "\\[\n",
            "y = 0.60x + 2.80\n",
            "\\]\n",
            "\n",
            "### How to Extend the Code:\n",
            "1. **Prediction**: Create another function that takes in a new \\( x \\) value and uses \\( m \\) and \\( b \\) to predict \\( y \\) using \\( y = mx + b \\).\n",
            "2. **Evaluation**:\n",
            "   - Compute evaluation metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE).\n",
            "3. **Multiple Linear Regression**: Extend the function to handle multiple independent variables by using matrix operations.\n",
            "\n",
            "Let me know if you would like to explore these extensions or automate tasks further!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'Linear Regression', 'output': 'Certainly! Below is a Python implementation of a simple Linear Regression model using NumPy. This function takes in the independent variable \\\\( x \\\\) and dependent variable \\\\( y \\\\) as inputs, calculates their relationship using the line equation \\\\( y = mx + b \\\\), and returns the slope \\\\( m \\\\) and intercept \\\\( b \\\\).\\n\\n### Linear Regression Function\\n```python\\nimport numpy as np\\n\\ndef linear_regression(x, y):\\n    \"\"\"\\n    Perform Linear Regression to calculate the slope (m) and intercept (b) of the line y = mx + b.\\n\\n    Parameters:\\n    x (array-like): Independent variable (input data).\\n    y (array-like): Dependent variable (output data).\\n\\n    Returns:\\n    tuple: Coefficients (m, b) where m is the slope and b is the intercept.\\n    \"\"\"\\n    # Convert inputs to numpy arrays for easier computation\\n    x = np.array(x)\\n    y = np.array(y)\\n\\n    # Calculate the mean of x and y\\n    x_mean = np.mean(x)\\n    y_mean = np.mean(y)\\n\\n    # Calculate the numerator and denominator for the slope (m)\\n    numerator = np.sum((x - x_mean) * (y - y_mean))  # Covariance between x and y\\n    denominator = np.sum((x - x_mean) ** 2)         # Variance of x\\n    m = numerator / denominator  # Slope\\n\\n    # Calculate the intercept (b)\\n    b = y_mean - (m * x_mean)\\n\\n    return m, b\\n\\n\\n# Example usage\\nif __name__ == \"__main__\":\\n    # Sample dataset\\n    x = [1, 2, 3, 4, 5]\\n    y = [2, 4, 5, 4, 5]\\n\\n    # Perform linear regression\\n    slope, intercept = linear_regression(x, y)\\n    print(f\"Slope (m): {slope:.2f}\")\\n    print(f\"Intercept (b): {intercept:.2f}\")\\n```\\n\\n### Explanation of the Code:\\n1. **Inputs**:\\n   - `x`: A list or array of independent variable values.\\n   - `y`: A list or array of dependent variable values.\\n\\n2. **Steps**:\\n   - **Mean Calculation**: Compute the mean of \\\\( x \\\\) and \\\\( y \\\\), denoted as \\\\( \\\\bar{x} \\\\) and \\\\( \\\\bar{y} \\\\).\\n   - **Slope Calculation**: The slope \\\\( m \\\\) is calculated using the formula:\\n     \\\\[\\n     m = \\\\frac{\\\\sum{(x_i - \\\\bar{x})(y_i - \\\\bar{y})}}{\\\\sum{(x_i - \\\\bar{x})^2}}\\n     \\\\]\\n     This is essentially the covariance divided by the variance of \\\\( x \\\\).\\n   - **Intercept Calculation**: The intercept \\\\( b \\\\) is calculated as:\\n     \\\\[\\n     b = \\\\bar{y} - m \\\\cdot \\\\bar{x}\\n     \\\\]\\n\\n3. **Output**:\\n   - Returns the slope \\\\( m \\\\) and intercept \\\\( b \\\\) of the linear model.\\n\\n### Example Output:\\nFor the given example input:\\n```python\\nx = [1, 2, 3, 4, 5]\\ny = [2, 4, 5, 4, 5]\\n```\\n\\nThe function produces:\\n```\\nSlope (m): 0.60\\nIntercept (b): 2.80\\n```\\n\\nThis means the best-fit line through the input data points is given by the equation:\\n\\\\[\\ny = 0.60x + 2.80\\n\\\\]\\n\\n### How to Extend the Code:\\n1. **Prediction**: Create another function that takes in a new \\\\( x \\\\) value and uses \\\\( m \\\\) and \\\\( b \\\\) to predict \\\\( y \\\\) using \\\\( y = mx + b \\\\).\\n2. **Evaluation**:\\n   - Compute evaluation metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE).\\n3. **Multiple Linear Regression**: Extend the function to handle multiple independent variables by using matrix operations.\\n\\nLet me know if you would like to explore these extensions or automate tasks further!'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain , SimpleSequentialChain\n",
        "\n",
        "prompt_template_1 = prompt_template.from_template(\n",
        "    template = 'You are an expereined data scientist and Python Programer. Write a function that implement the concpet of {concept}.'\n",
        "    )\n",
        "\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt_template_1)\n",
        "\n",
        "llm_2 = AzureChatOpenAI(\n",
        "    openai_api_base=AZURE_OPENAI_ENDPOINT,\n",
        "    openai_api_key=AZURE_OPENAI_KEY,\n",
        "    openai_api_version=\"2023-03-15-preview\",\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    openai_api_type=\"azure\",\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "prompt_template_2 = prompt_template.from_template(\n",
        "    template = 'Write a python function that implement the concpet of {concept}.'\n",
        "    )\n",
        "\n",
        "chain_2 = LLMChain(llm=llm_2, prompt=prompt_template_2)\n",
        "\n",
        "overall = SimpleSequentialChain(chains=[chain_1, chain_2], verbose=True)\n",
        "\n",
        "output = overall.invoke(\"Linear Regression\")\n",
        "print(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4czfWywSvuA",
        "outputId": "bc38838b-8b05-43d5-e377-8feb9facf4b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://ai-new-agent-resource.openai.azure.com/ to https://ai-new-agent-resource.openai.azure.com/openai.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: tell me about patna\n",
            "Assistant:  Patna is the capital city of Bihar, a state in eastern India, and is one of the oldest continuously inhabited cities in the world. It has a rich history, significant cultural heritage, and serves as a major educational, political, and economic center.\n",
            "\n",
            "### Historical Significance:\n",
            "- **Ancient Patliputra:** Patna was historically known as **Patliputra**, which was the capital of several powerful empires in ancient India, including the Maurya, Gupta, and Shunga dynasties. It played a crucial role in Indian history as a center of politics, administration, education, and culture.\n",
            "- **Buddhism and Jainism:** The region holds great importance in the history of Buddhism and Jainism, as both religions flourished in and around Patna. It is close to significant religious sites like Bodh Gaya, Rajgir, and Vaishali.\n",
            "- **Historical Events:** Greek historians like Megasthenes described the grandeur of ancient Patliputra during the Mauryan Empire.\n",
            "\n",
            "### Modern Patna:\n",
            "Patna today is a bustling city on the southern banks of the river Ganges. It is a hub for politics in Bihar, and over the years, it has become an important center for trade and industries.\n",
            "\n",
            "### Key Attractions:\n",
            "1. **Golghar:** A large granary built by the British to store grain in the 18th century.\n",
            "2. **Patna Sahib Gurudwara:** A revered Sikh shrine associated with Guru Gobind Singh, the 10th Sikh Guru.\n",
            "3. **Bihar Museum:** A modern museum showcasing the history and heritage of Bihar.\n",
            "4. **Agam Kuan:** An ancient well linked to Emperor Ashoka and believed to have historical significance.\n",
            "5. **Mahavir Mandir:** A popular Hindu temple dedicated to Lord Hanuman.\n",
            "\n",
            "### Culture and Food:\n",
            "- Patna is known for its unique blend of Bihari cuisine, which includes dishes like **litti chokha**, **sattu**, and sweet treats like **khaja** and **chana murki**.\n",
            "- The region celebrates festivals like **Chhath Puja**, which holds immense spiritual significance for Biharis.\n",
            "\n",
            "### Economy and Education:\n",
            "- Patna is a growing trade hub, and agriculture plays a significant role in its economy. The city has markets for grains, sugarcane, and other produce.\n",
            "- It is home to several prestigious educational institutions, such as **Patna University**, **National Institute of Technology (NIT) Patna**, and **AIIMS Patna**.\n",
            "\n",
            "### Connectivity:\n",
            "- Patna is well-connected by rail, road, and air to major Indian cities. The **Jay Prakash Narayan International Airport** serves the city.\n",
            "\n",
            "### Geography and Climate:\n",
            "- Located along the banks of the **Ganges River**, Patna's geography includes fertile plains.\n",
            "- It experiences a humid subtropical climate with hot summers, a monsoon season, and mild winters.\n",
            "\n",
            "Patna is a city where ancient traditions blend seamlessly with modern developments, making it an intriguing destination for history enthusiasts, cultural explorers, and professionals alike.\n",
            "__________________________________________________\n",
            "You: tell me history of the city\n",
            "Assistant:  Of course! Could you please specify which city you'd like to know the history of?\n",
            "__________________________________________________\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.prompts import ChatPromptTemplate , HumanMessagePromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    openai_api_base=AZURE_OPENAI_ENDPOINT,\n",
        "    openai_api_key=AZURE_OPENAI_KEY,\n",
        "    openai_api_version=\"2023-03-15-preview\",\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    openai_api_type=\"azure\",\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "   [\n",
        "       SystemMessage(content=\"You responsed only in English.\"),\n",
        "       HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
        "   ]\n",
        ")\n",
        "\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input == \"exit\":\n",
        "    break\n",
        "  output = chain.invoke({\"user_input\":user_input})\n",
        "  print(\"Assistant: \", output)\n",
        "  print(\"_\" * 50)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPNOWs-hUW-e"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLpKlhP3UpG-",
        "outputId": "5125afd4-575f-489c-b9b0-37893b29766a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1496473724.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRiunWpAU0u7"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF8MHB5nU-Ta",
        "outputId": "893c31ec-8678-45f6-f2de-e97ae869d9f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Hi\n",
            "Assistant:  {'user_input': 'Hi', 'chat_history': [HumanMessage(content='Tell me about sun', additional_kwargs={}, response_metadata={}), AIMessage(content='The Sun is the star at the center of our solar system. It\\'s a massive, nearly perfect sphere of hot plasma that generates energy through nuclear fusion. Its size, gravitational pull, and energy output make it the most influential celestial body in our solar system, shaping everything from the orbits of planets to Earth\\'s climate. Here\\'s a deeper look at the Sun:\\n\\n### **Basic Facts About the Sun**\\n1. **Type of Star**: The Sun is classified as a G-type main-sequence star (G2V), often referred to as a \"yellow dwarf.\" However, it actually emits white light that appears yellow from Earth due to atmospheric scattering.\\n2. **Diameter**: Approximately 1.39 million kilometers (about 864,000 miles), making it about 109 times wider than Earth.\\n3. **Mass**: Roughly 1.989 × 10^30 kilograms, which is about 333,000 times the mass of Earth. The Sun contains more than 99.8% of the total mass of the solar system.\\n4. **Surface Temperature**: Around 5,500 degrees Celsius (9,932 degrees Fahrenheit), while its core reaches temperatures of about 15 million degrees Celsius (27 million degrees Fahrenheit).\\n5. **Distance from Earth**: About 150 million kilometers (93 million miles), a distance known as an astronomical unit (AU).\\n\\n---\\n\\n### **Structure of the Sun**\\nThe Sun\\'s structure is divided into several layers, listed from the innermost to the outermost:\\n\\n1. **Core**: \\n   - The central region where nuclear fusion occurs, converting hydrogen into helium and releasing enormous amounts of energy.\\n   - The source of the Sun\\'s light and heat.\\n\\n2. **Radiative Zone**: \\n   - Energy produced in the core travels outward as electromagnetic radiation through this dense layer. \\n   - Energy takes thousands to millions of years to pass through this zone.\\n\\n3. **Convective Zone**: \\n   - Hot plasma rises and cooler plasma sinks in a process called convection, moving energy to the Sun\\'s surface.\\n\\n4. **Photosphere**: \\n   - The Sun\\'s visible surface, where sunlight is emitted. It’s also the layer where sunspots appear.\\n\\n5. **Chromosphere**: \\n   - A thin layer of hot gases just above the photosphere. It’s visible as a reddish glow during solar eclipses.\\n\\n6. **Corona**: \\n   - The Sun\\'s outer atmosphere, extending millions of kilometers into space. The corona is incredibly hot (millions of degrees Celsius), much hotter than the layers beneath it, and is a source of the solar wind.\\n\\n---\\n\\n### **Energy and Nuclear Fusion**\\nThe Sun generates energy through a process called nuclear fusion, where hydrogen nuclei combine to form helium. This process releases immense amounts of energy in the form of light and heat. The energy travels outward from the core and eventually reaches Earth, where it drives weather patterns, supports plant photosynthesis, and sustains life.\\n\\n---\\n\\n### **Importance of the Sun**\\n1. **Life on Earth**: The Sun\\'s energy is the primary driver of Earth\\'s climate and weather. Plants rely on sunlight for photosynthesis, which forms the base of most food chains.\\n2. **Gravitational Anchor**: The Sun\\'s massive gravitational pull keeps the planets, moons, and other objects in the solar system in stable orbits.\\n3. **Solar Influence**: Solar activity, such as sunspots, solar flares, and coronal mass ejections, can impact Earth\\'s magnetic field, power grids, and communication systems.\\n\\n---\\n\\n### **Solar Cycle**\\nThe Sun undergoes an 11-year solar cycle, during which its magnetic activity waxes and wanes. At solar maximum, there is high sunspot activity, while at solar minimum, there are fewer sunspots. This cycle influences space weather and can lead to phenomena like geomagnetic storms on Earth.\\n\\n---\\n\\n### **Fun Facts About the Sun**\\n1. The Sun is about halfway through its life (approximately 4.6 billion years old) and will continue to fuse hydrogen for another 5 billion years.\\n2. After exhausting its hydrogen fuel, the Sun will expand into a red giant, eventually shedding its outer layers and leaving behind a dense core called a white dwarf.\\n3. Light from the Sun takes about 8 minutes and 20 seconds to reach Earth.\\n\\nThe Sun is undoubtedly the most crucial celestial object for life on Earth, and despite being an ordinary star in cosmic terms, it holds extraordinary significance for our existence.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about delhi', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Delhi, officially known as the **National Capital Territory of Delhi (NCT)**, is the capital of **India** and one of its most vibrant and historically rich cities. It is located in the northern part of the country and serves as a prominent political, cultural, and economic hub.\\n\\n### 1. **Geography and Demographics**  \\nDelhi covers an area of approximately 1,484 square kilometers, and as of 2023, its population exceeds **32 million**, making it the second-most populous city in the world after Tokyo. The city is bordered by the state of **Haryana** on three sides and **Uttar Pradesh** to the east.\\n\\nDelhi is divided into two main parts:\\n- **Old Delhi**: This area represents the historic city, with narrow streets, bustling markets, and Mughal-era landmarks.\\n- **New Delhi**: The planned city designed during the British colonial period, serving as the official capital of India.\\n\\nIt is also home to the **Yamuna River**, a significant water body in India, although environmental concerns like pollution have long affected its health.\\n\\n---\\n\\n### 2. **History**\\nDelhi has an incredibly rich history that spans thousands of years. It is one of the oldest continuously inhabited cities in the world and has been the seat of power for several empires. It is often said to have been rebuilt **seven times** throughout its history.\\n\\nKey historical phases:  \\n- **Ancient Era**: The city is linked to **Indraprastha**, the legendary capital mentioned in the Indian epic Mahabharata.\\n- **Medieval Delhi**: From the 12th to the 19th century, Delhi was ruled by various dynasties, including the **Delhi Sultanate** and the **Mughal Empire**.\\n- **British Period**: In 1911, the British moved India’s capital from Kolkata to Delhi and developed **New Delhi** as the administrative center.\\n- **Post-Independence**: After India gained independence in 1947, Delhi became the capital of the newly formed Republic of India.\\n\\n---\\n\\n### 3. **Government and Administration**\\nAs the capital of India, Delhi is the center of the country's government and hosts major institutions:\\n- **Rashtrapati Bhavan (Presidential Residence)**\\n- **Parliament of India**\\n- **Supreme Court of India**\\n\\nDelhi has a unique governance structure. It is both a union territory and a city, with powers shared between the **Delhi Government** and the **Central Government**.\\n\\n---\\n\\n### 4. **Cultural and Historical Landmarks**\\nDelhi is a treasure trove of cultural and historical monuments. Some iconic landmarks include:\\n- **Red Fort**: A UNESCO World Heritage Site and a symbol of India's independence.\\n- **Qutub Minar**: The tallest brick minaret in the world and another UNESCO World Heritage Site.\\n- **India Gate**: A war memorial dedicated to Indian soldiers.\\n- **Jama Masjid**: One of the largest mosques in India, built by Mughal Emperor Shah Jahan.\\n- **Humayun's Tomb**: A precursor to the Taj Mahal and a UNESCO World Heritage Site.\\n- **Lotus Temple**: A Bahá'í House of Worship known for its stunning architecture.\\n- **Akshardham Temple**: A modern Hindu temple with intricate carvings and exhibits.\\n\\n---\\n\\n### 5. **Food and Cuisine**\\nDelhi is known as a food lover's paradise, offering a mix of traditional and modern culinary experiences. Some must-try dishes include:\\n- **Chole Bhature**: Spicy chickpeas served with deep-fried bread.\\n- **Paranthas**: Stuffed flatbread, especially famous in the lanes of Chandni Chowk.\\n- **Butter Chicken**: A creamy chicken curry that originated in Delhi.\\n- **Golgappa/Pani Puri**: A popular street food.\\n- **Kebabs and Biryani**: Influenced by Mughal cuisine.\\n\\nThe city boasts a variety of eateries, from street food vendors to high-end restaurants.\\n\\n---\\n\\n### 6. **Transportation**\\nDelhi has a well-developed transportation network, making it one of the most accessible cities in India.  \\n- **Delhi Metro**: A modern and efficient metro system connecting nearly every corner of the city, considered one of the best in the world.\\n- **Indira Gandhi International Airport**: A major hub for domestic and international flights.\\n- **Roads and Highways**: Delhi is well-connected to neighboring states via national highways.\\n- **Buses and Auto-Rickshaws**: Widely used for local transportation.\\n\\n---\\n\\n### 7. **Climate**\\nDelhi experiences an extreme climate:\\n- **Summers (April to June)**: Very hot, with temperatures often exceeding 45°C (113°F).\\n- **Monsoon (July to September)**: Moderate rainfall.\\n- **Winters (December to February)**: Cool to cold, with temperatures dipping as low as 2°C (36°F). Fog is common in winter.\\n\\n---\\n\\n### 8. **Modern Delhi**\\nDelhi is a blend of tradition and modernity. While Old Delhi preserves the essence of India's rich history with its ancient bazaars and monuments, New Delhi showcases modern infrastructure, luxury malls, and global corporations. The city's cosmopolitan vibe is reflected in its diverse population and dynamic lifestyle.\\n\\n---\\n\\n### 9. **Challenges**\\nLike any major metropolis, Delhi faces several challenges, including:\\n- **Pollution**: Air pollution is a severe concern, often making headlines for the city's hazardous Air Quality Index (AQI) levels.\\n- **Traffic Congestion**: As one of the largest cities in the world, traffic is a perennial issue.\\n- **Urbanization**: Rapid urban expansion has put a strain on resources, infrastructure, and housing.\\n\\n---\\n\\n### 10. **Key Events and Festivals**\\nDelhi is home to a variety of events, fairs, and festivals, such as:\\n- **Republic Day Parade (January 26)**: A grand celebration showcasing India's military and cultural heritage.\\n- **Diwali**: The festival of lights, celebrated with great enthusiasm.\\n- **Holi**: The festival of colors.\\n- **Delhi International Arts Festival**: Celebrating art, culture, and performances from around the world.\\n- **Dastkar Bazaar and Trade Fairs**: Promoting artisans and crafts.\\n\\n---\\n\\nDelhi is a city that offers something for everyone—be it history enthusiasts, food lovers, or modern urban explorers. Its rich heritage and dynamic growth make it a key symbol of India's past, present, and future.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about machine learining', additional_kwargs={}, response_metadata={}), AIMessage(content='Machine learning (ML) is a subset of artificial intelligence (AI) that involves enabling computers or systems to learn from data and make decisions or predictions without being explicitly programmed. Essentially, it allows machines to improve their performance on a specific task over time by analyzing patterns and learning from experience.\\n\\n### Key Concepts in Machine Learning:\\n\\n1. **Data**: Machine learning models require large amounts of data to identify patterns and improve their predictive ability. This data is typically divided into training, validation, and testing datasets.\\n\\n2. **Algorithms**: These are the mathematical methods or procedures used to train models. Common algorithms include:\\n   - Linear Regression\\n   - Decision Trees\\n   - Neural Networks\\n   - Support Vector Machines\\n   - k-Nearest Neighbors (KNN)\\n\\n3. **Training**: During training, the model learns to make predictions or decisions by analyzing patterns in the data. The goal is to minimize the error or loss function.\\n\\n4. **Types of Machine Learning**:\\n   - **Supervised Learning**: The model is trained on labeled data, i.e. data with input-output pairs. Examples include classification (e.g., identifying spam emails) and regression (e.g., predicting sales trends).\\n   - **Unsupervised Learning**: The model is trained on unlabeled data, letting it discover patterns or groupings. Examples include clustering (e.g., customer segmentation) and dimensionality reduction (e.g., Principal Component Analysis).\\n   - **Semi-supervised Learning**: Combines elements of supervised and unsupervised learning, using a small amount of labeled data with a larger unlabeled dataset.\\n   - **Reinforcement Learning**: A model learns by interacting with an environment and receiving feedback in the form of rewards or penalties (e.g., training AI agents for games).\\n\\n5. **Model Evaluation**: After training, the model’s performance is tested using metrics such as accuracy, precision, recall, F1-score, or mean squared error.\\n\\n### Applications of Machine Learning:\\nMachine learning is widely used across industries, including:\\n- **Healthcare**: Disease prediction, drug discovery, personalized medicine.\\n- **Finance**: Fraud detection, credit scoring, stock market prediction.\\n- **Marketing**: Customer segmentation, recommendation systems.\\n- **Transportation**: Autonomous vehicles, traffic predictions.\\n- **Natural Language Processing**: Chatbots, sentiment analysis, language translation.\\n\\n### Tools and Frameworks:\\nPopular tools for machine learning development include:\\n- Python libraries: TensorFlow, PyTorch, Scikit-learn, Keras\\n- R (a statistical programming language)\\n- Cloud platforms: AWS Machine Learning, Google AI Platform, Microsoft Azure AI\\n\\n### Challenges in Machine Learning:\\n- **Data quality**: Poor or biased data can lead to inaccurate models.\\n- **Overfitting**: When a model performs well on training data but poorly on unseen data.\\n- **Computational requirements**: Training complex models can require substantial computational resources.\\n- **Ethical considerations**: Bias in datasets can perpetuate discrimination; privacy concerns also arise from data usage.\\n\\nMachine learning is a powerful tool that continues to evolve with advancements in computing power, algorithms, and data availability. Its potential to transform industries and solve complex problems is immense.', additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about book', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Could you clarify what you're asking about? Would you like a recommendation for a book, a summary of a specific book, or general information about books? Let me know so I can assist you better!\", additional_kwargs={}, response_metadata={})], 'text': 'Hello! How can I assist you today? 😊'}\n",
            "__________________________________________________\n",
            "You: quit\n",
            "Goodbye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower() in [\"exit\" , \"quit\", \"bye\"] :\n",
        "    print(\"Goodbye\")\n",
        "    break\n",
        "  output = chain.invoke({\"user_input\":user_input})\n",
        "  print(\"Assistant: \", output)\n",
        "  print(\"_\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Cla51cZ8WlQa",
        "outputId": "5c9f7276-e3a4-4ae1-878c-5e857fc84fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: write about crona virus in paragraph\n",
            "Assistant:  The coronavirus, officially known as COVID-19, is a highly contagious viral infection that emerged in late 2019 in the city of Wuhan, China. Classified as a novel coronavirus, it quickly spread worldwide, leading to a global pandemic declared by the World Health Organization (WHO) in March 2020. The virus primarily spreads through respiratory droplets and close contact, with symptoms ranging from mild, such as fever, cough, and fatigue, to severe, including difficulty breathing and complications like pneumonia. Vulnerable populations, such as the elderly and those with underlying health conditions, faced increased risks of severe outcomes. The pandemic had profound impacts on global health systems, economies, and daily life, prompting widespread lockdowns, travel restrictions, and shifts to remote work and education. In response, scientists and pharmaceutical companies rapidly developed vaccines, which became a crucial tool in combating the virus and reducing its spread. Despite progress in managing the pandemic, the emergence of new variants posed ongoing challenges, underscoring the importance of public health measures, vaccination campaigns, and global cooperation to mitigate the virus's impacts.\n",
            "__________________________________________________\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1009029042.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"exit\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# how to print the content instant of json format\n",
        "\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower() in [\"exit\" , \"quit\", \"bye\"] :\n",
        "    print(\"Goodbye\")\n",
        "    break\n",
        "  output = chain.run({\"user_input\":user_input})\n",
        "  print(\"Assistant: \", output)\n",
        "  print(\"_\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHlemjxJWpSi",
        "outputId": "215796fc-e289-4304-c2e0-c6274c847ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Hi\n",
            "Assistant:  {'user_input': 'Hi', 'chat_history': [HumanMessage(content='Tell me about sun', additional_kwargs={}, response_metadata={}), AIMessage(content='The Sun is the star at the center of our solar system. It\\'s a massive, nearly perfect sphere of hot plasma that generates energy through nuclear fusion. Its size, gravitational pull, and energy output make it the most influential celestial body in our solar system, shaping everything from the orbits of planets to Earth\\'s climate. Here\\'s a deeper look at the Sun:\\n\\n### **Basic Facts About the Sun**\\n1. **Type of Star**: The Sun is classified as a G-type main-sequence star (G2V), often referred to as a \"yellow dwarf.\" However, it actually emits white light that appears yellow from Earth due to atmospheric scattering.\\n2. **Diameter**: Approximately 1.39 million kilometers (about 864,000 miles), making it about 109 times wider than Earth.\\n3. **Mass**: Roughly 1.989 × 10^30 kilograms, which is about 333,000 times the mass of Earth. The Sun contains more than 99.8% of the total mass of the solar system.\\n4. **Surface Temperature**: Around 5,500 degrees Celsius (9,932 degrees Fahrenheit), while its core reaches temperatures of about 15 million degrees Celsius (27 million degrees Fahrenheit).\\n5. **Distance from Earth**: About 150 million kilometers (93 million miles), a distance known as an astronomical unit (AU).\\n\\n---\\n\\n### **Structure of the Sun**\\nThe Sun\\'s structure is divided into several layers, listed from the innermost to the outermost:\\n\\n1. **Core**: \\n   - The central region where nuclear fusion occurs, converting hydrogen into helium and releasing enormous amounts of energy.\\n   - The source of the Sun\\'s light and heat.\\n\\n2. **Radiative Zone**: \\n   - Energy produced in the core travels outward as electromagnetic radiation through this dense layer. \\n   - Energy takes thousands to millions of years to pass through this zone.\\n\\n3. **Convective Zone**: \\n   - Hot plasma rises and cooler plasma sinks in a process called convection, moving energy to the Sun\\'s surface.\\n\\n4. **Photosphere**: \\n   - The Sun\\'s visible surface, where sunlight is emitted. It’s also the layer where sunspots appear.\\n\\n5. **Chromosphere**: \\n   - A thin layer of hot gases just above the photosphere. It’s visible as a reddish glow during solar eclipses.\\n\\n6. **Corona**: \\n   - The Sun\\'s outer atmosphere, extending millions of kilometers into space. The corona is incredibly hot (millions of degrees Celsius), much hotter than the layers beneath it, and is a source of the solar wind.\\n\\n---\\n\\n### **Energy and Nuclear Fusion**\\nThe Sun generates energy through a process called nuclear fusion, where hydrogen nuclei combine to form helium. This process releases immense amounts of energy in the form of light and heat. The energy travels outward from the core and eventually reaches Earth, where it drives weather patterns, supports plant photosynthesis, and sustains life.\\n\\n---\\n\\n### **Importance of the Sun**\\n1. **Life on Earth**: The Sun\\'s energy is the primary driver of Earth\\'s climate and weather. Plants rely on sunlight for photosynthesis, which forms the base of most food chains.\\n2. **Gravitational Anchor**: The Sun\\'s massive gravitational pull keeps the planets, moons, and other objects in the solar system in stable orbits.\\n3. **Solar Influence**: Solar activity, such as sunspots, solar flares, and coronal mass ejections, can impact Earth\\'s magnetic field, power grids, and communication systems.\\n\\n---\\n\\n### **Solar Cycle**\\nThe Sun undergoes an 11-year solar cycle, during which its magnetic activity waxes and wanes. At solar maximum, there is high sunspot activity, while at solar minimum, there are fewer sunspots. This cycle influences space weather and can lead to phenomena like geomagnetic storms on Earth.\\n\\n---\\n\\n### **Fun Facts About the Sun**\\n1. The Sun is about halfway through its life (approximately 4.6 billion years old) and will continue to fuse hydrogen for another 5 billion years.\\n2. After exhausting its hydrogen fuel, the Sun will expand into a red giant, eventually shedding its outer layers and leaving behind a dense core called a white dwarf.\\n3. Light from the Sun takes about 8 minutes and 20 seconds to reach Earth.\\n\\nThe Sun is undoubtedly the most crucial celestial object for life on Earth, and despite being an ordinary star in cosmic terms, it holds extraordinary significance for our existence.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about delhi', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Delhi, officially known as the **National Capital Territory of Delhi (NCT)**, is the capital of **India** and one of its most vibrant and historically rich cities. It is located in the northern part of the country and serves as a prominent political, cultural, and economic hub.\\n\\n### 1. **Geography and Demographics**  \\nDelhi covers an area of approximately 1,484 square kilometers, and as of 2023, its population exceeds **32 million**, making it the second-most populous city in the world after Tokyo. The city is bordered by the state of **Haryana** on three sides and **Uttar Pradesh** to the east.\\n\\nDelhi is divided into two main parts:\\n- **Old Delhi**: This area represents the historic city, with narrow streets, bustling markets, and Mughal-era landmarks.\\n- **New Delhi**: The planned city designed during the British colonial period, serving as the official capital of India.\\n\\nIt is also home to the **Yamuna River**, a significant water body in India, although environmental concerns like pollution have long affected its health.\\n\\n---\\n\\n### 2. **History**\\nDelhi has an incredibly rich history that spans thousands of years. It is one of the oldest continuously inhabited cities in the world and has been the seat of power for several empires. It is often said to have been rebuilt **seven times** throughout its history.\\n\\nKey historical phases:  \\n- **Ancient Era**: The city is linked to **Indraprastha**, the legendary capital mentioned in the Indian epic Mahabharata.\\n- **Medieval Delhi**: From the 12th to the 19th century, Delhi was ruled by various dynasties, including the **Delhi Sultanate** and the **Mughal Empire**.\\n- **British Period**: In 1911, the British moved India’s capital from Kolkata to Delhi and developed **New Delhi** as the administrative center.\\n- **Post-Independence**: After India gained independence in 1947, Delhi became the capital of the newly formed Republic of India.\\n\\n---\\n\\n### 3. **Government and Administration**\\nAs the capital of India, Delhi is the center of the country's government and hosts major institutions:\\n- **Rashtrapati Bhavan (Presidential Residence)**\\n- **Parliament of India**\\n- **Supreme Court of India**\\n\\nDelhi has a unique governance structure. It is both a union territory and a city, with powers shared between the **Delhi Government** and the **Central Government**.\\n\\n---\\n\\n### 4. **Cultural and Historical Landmarks**\\nDelhi is a treasure trove of cultural and historical monuments. Some iconic landmarks include:\\n- **Red Fort**: A UNESCO World Heritage Site and a symbol of India's independence.\\n- **Qutub Minar**: The tallest brick minaret in the world and another UNESCO World Heritage Site.\\n- **India Gate**: A war memorial dedicated to Indian soldiers.\\n- **Jama Masjid**: One of the largest mosques in India, built by Mughal Emperor Shah Jahan.\\n- **Humayun's Tomb**: A precursor to the Taj Mahal and a UNESCO World Heritage Site.\\n- **Lotus Temple**: A Bahá'í House of Worship known for its stunning architecture.\\n- **Akshardham Temple**: A modern Hindu temple with intricate carvings and exhibits.\\n\\n---\\n\\n### 5. **Food and Cuisine**\\nDelhi is known as a food lover's paradise, offering a mix of traditional and modern culinary experiences. Some must-try dishes include:\\n- **Chole Bhature**: Spicy chickpeas served with deep-fried bread.\\n- **Paranthas**: Stuffed flatbread, especially famous in the lanes of Chandni Chowk.\\n- **Butter Chicken**: A creamy chicken curry that originated in Delhi.\\n- **Golgappa/Pani Puri**: A popular street food.\\n- **Kebabs and Biryani**: Influenced by Mughal cuisine.\\n\\nThe city boasts a variety of eateries, from street food vendors to high-end restaurants.\\n\\n---\\n\\n### 6. **Transportation**\\nDelhi has a well-developed transportation network, making it one of the most accessible cities in India.  \\n- **Delhi Metro**: A modern and efficient metro system connecting nearly every corner of the city, considered one of the best in the world.\\n- **Indira Gandhi International Airport**: A major hub for domestic and international flights.\\n- **Roads and Highways**: Delhi is well-connected to neighboring states via national highways.\\n- **Buses and Auto-Rickshaws**: Widely used for local transportation.\\n\\n---\\n\\n### 7. **Climate**\\nDelhi experiences an extreme climate:\\n- **Summers (April to June)**: Very hot, with temperatures often exceeding 45°C (113°F).\\n- **Monsoon (July to September)**: Moderate rainfall.\\n- **Winters (December to February)**: Cool to cold, with temperatures dipping as low as 2°C (36°F). Fog is common in winter.\\n\\n---\\n\\n### 8. **Modern Delhi**\\nDelhi is a blend of tradition and modernity. While Old Delhi preserves the essence of India's rich history with its ancient bazaars and monuments, New Delhi showcases modern infrastructure, luxury malls, and global corporations. The city's cosmopolitan vibe is reflected in its diverse population and dynamic lifestyle.\\n\\n---\\n\\n### 9. **Challenges**\\nLike any major metropolis, Delhi faces several challenges, including:\\n- **Pollution**: Air pollution is a severe concern, often making headlines for the city's hazardous Air Quality Index (AQI) levels.\\n- **Traffic Congestion**: As one of the largest cities in the world, traffic is a perennial issue.\\n- **Urbanization**: Rapid urban expansion has put a strain on resources, infrastructure, and housing.\\n\\n---\\n\\n### 10. **Key Events and Festivals**\\nDelhi is home to a variety of events, fairs, and festivals, such as:\\n- **Republic Day Parade (January 26)**: A grand celebration showcasing India's military and cultural heritage.\\n- **Diwali**: The festival of lights, celebrated with great enthusiasm.\\n- **Holi**: The festival of colors.\\n- **Delhi International Arts Festival**: Celebrating art, culture, and performances from around the world.\\n- **Dastkar Bazaar and Trade Fairs**: Promoting artisans and crafts.\\n\\n---\\n\\nDelhi is a city that offers something for everyone—be it history enthusiasts, food lovers, or modern urban explorers. Its rich heritage and dynamic growth make it a key symbol of India's past, present, and future.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about machine learining', additional_kwargs={}, response_metadata={}), AIMessage(content='Machine learning (ML) is a subset of artificial intelligence (AI) that involves enabling computers or systems to learn from data and make decisions or predictions without being explicitly programmed. Essentially, it allows machines to improve their performance on a specific task over time by analyzing patterns and learning from experience.\\n\\n### Key Concepts in Machine Learning:\\n\\n1. **Data**: Machine learning models require large amounts of data to identify patterns and improve their predictive ability. This data is typically divided into training, validation, and testing datasets.\\n\\n2. **Algorithms**: These are the mathematical methods or procedures used to train models. Common algorithms include:\\n   - Linear Regression\\n   - Decision Trees\\n   - Neural Networks\\n   - Support Vector Machines\\n   - k-Nearest Neighbors (KNN)\\n\\n3. **Training**: During training, the model learns to make predictions or decisions by analyzing patterns in the data. The goal is to minimize the error or loss function.\\n\\n4. **Types of Machine Learning**:\\n   - **Supervised Learning**: The model is trained on labeled data, i.e. data with input-output pairs. Examples include classification (e.g., identifying spam emails) and regression (e.g., predicting sales trends).\\n   - **Unsupervised Learning**: The model is trained on unlabeled data, letting it discover patterns or groupings. Examples include clustering (e.g., customer segmentation) and dimensionality reduction (e.g., Principal Component Analysis).\\n   - **Semi-supervised Learning**: Combines elements of supervised and unsupervised learning, using a small amount of labeled data with a larger unlabeled dataset.\\n   - **Reinforcement Learning**: A model learns by interacting with an environment and receiving feedback in the form of rewards or penalties (e.g., training AI agents for games).\\n\\n5. **Model Evaluation**: After training, the model’s performance is tested using metrics such as accuracy, precision, recall, F1-score, or mean squared error.\\n\\n### Applications of Machine Learning:\\nMachine learning is widely used across industries, including:\\n- **Healthcare**: Disease prediction, drug discovery, personalized medicine.\\n- **Finance**: Fraud detection, credit scoring, stock market prediction.\\n- **Marketing**: Customer segmentation, recommendation systems.\\n- **Transportation**: Autonomous vehicles, traffic predictions.\\n- **Natural Language Processing**: Chatbots, sentiment analysis, language translation.\\n\\n### Tools and Frameworks:\\nPopular tools for machine learning development include:\\n- Python libraries: TensorFlow, PyTorch, Scikit-learn, Keras\\n- R (a statistical programming language)\\n- Cloud platforms: AWS Machine Learning, Google AI Platform, Microsoft Azure AI\\n\\n### Challenges in Machine Learning:\\n- **Data quality**: Poor or biased data can lead to inaccurate models.\\n- **Overfitting**: When a model performs well on training data but poorly on unseen data.\\n- **Computational requirements**: Training complex models can require substantial computational resources.\\n- **Ethical considerations**: Bias in datasets can perpetuate discrimination; privacy concerns also arise from data usage.\\n\\nMachine learning is a powerful tool that continues to evolve with advancements in computing power, algorithms, and data availability. Its potential to transform industries and solve complex problems is immense.', additional_kwargs={}, response_metadata={}), HumanMessage(content='tell me about book', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Could you clarify what you're asking about? Would you like a recommendation for a book, a summary of a specific book, or general information about books? Let me know so I can assist you better!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today? 😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='write about crona virus in paragraph', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The coronavirus, officially known as COVID-19, is a highly contagious viral infection that emerged in late 2019 in the city of Wuhan, China. Classified as a novel coronavirus, it quickly spread worldwide, leading to a global pandemic declared by the World Health Organization (WHO) in March 2020. The virus primarily spreads through respiratory droplets and close contact, with symptoms ranging from mild, such as fever, cough, and fatigue, to severe, including difficulty breathing and complications like pneumonia. Vulnerable populations, such as the elderly and those with underlying health conditions, faced increased risks of severe outcomes. The pandemic had profound impacts on global health systems, economies, and daily life, prompting widespread lockdowns, travel restrictions, and shifts to remote work and education. In response, scientists and pharmaceutical companies rapidly developed vaccines, which became a crucial tool in combating the virus and reducing its spread. Despite progress in managing the pandemic, the emergence of new variants posed ongoing challenges, underscoring the importance of public health measures, vaccination campaigns, and global cooperation to mitigate the virus's impacts.\", additional_kwargs={}, response_metadata={})], 'text': 'Hello! How can I assist you today? 😊'}\n",
            "__________________________________________________\n",
            "You: quit\n",
            "Goodbye\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import FileChatMessageHistory\n",
        "\n",
        "histroy = FileChatMessageHistory(\"chat_history.json\")\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True ,\n",
        "    chat_memory=histroy\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower() in [\"exit\" , \"quit\", \"bye\"] :\n",
        "    print(\"Goodbye\")\n",
        "    break\n",
        "  output = chain.invoke({\"user_input\":user_input})\n",
        "  print(\"Assistant: \", output)\n",
        "  print(\"_\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrCed43MYKzu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgEQ5pjaYpWh"
      },
      "source": [
        "** different for each LLM provider **\n",
        "\n",
        "*   library required\n",
        "*   secrets key\n",
        "*   configure LLM connection\n",
        "\n",
        "** common for all LLM **\n",
        "\n",
        "*   prompt template / schema / chatmesage\n",
        "*   chain ( verbose= True)\n",
        "*   call the chain or llm\n",
        "*   cache memoery\n",
        "*   streaming\n",
        "*   simplesequenticalchain\n",
        "*   stroputput\n",
        "*   memeory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTt7aZ6bvC54",
        "outputId": "f2b1eae2-8254-4a7e-b0e7-df0880f443fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COVID-19, a highly contagious novel coronavirus, emerged in Wuhan, China, in late 2019 and rapidly spread globally, leading the WHO to declare a pandemic in March 2020. Transmitted through respiratory droplets, the virus caused symptoms ranging from mild to severe, with vulnerable populations facing heightened risks. The pandemic disrupted health systems, economies, and daily life, prompting lockdowns, travel restrictions, and remote work. Vaccines were rapidly developed as a key tool to combat the virus, but new variants continued to challenge global efforts, highlighting the need for public health measures, vaccination, and cooperation.\n"
          ]
        }
      ],
      "source": [
        "text = '''\n",
        "The coronavirus, officially known as COVID-19, is a highly contagious viral infection that emerged in late 2019 in the city of Wuhan, China.\n",
        "Classified as a novel coronavirus, it quickly spread worldwide, leading to a global pandemic declared by the World Health Organization\n",
        "(WHO) in March 2020. The virus primarily spreads through respiratory droplets and close contact, with symptoms ranging from mild, such as\n",
        "fever, cough, and fatigue, to severe, including difficulty breathing and complications like pneumonia. Vulnerable populations, such as\n",
        "the elderly and those with underlying health conditions, faced increased risks of severe outcomes. The pandemic had profound impacts on\n",
        "global health systems, economies, and daily life, prompting widespread lockdowns, travel restrictions, and shifts to remote work and\n",
        "education. In response, scientists and pharmaceutical companies rapidly developed vaccines, which became a crucial tool in combating\n",
        "the virus and reducing its spread. Despite progress in managing the pandemic, the emergence of new variants posed ongoing challenges,\n",
        "underscoring the importance of public health measures, vaccination campaigns, and global cooperation to mitigate the virus's impacts.'''\n",
        "\n",
        "messages = [\n",
        "  SystemMessage(content=\"You are an expert copywriter the expertize in summarizing documents.\"),\n",
        "  HumanMessage(content=f' please provide a short and concise summary of the following text : \\n TEXT :  {text}')\n",
        "]\n",
        "\n",
        "output = llm.invoke(messages)\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX8vIGJfvc_I",
        "outputId": "471e19f2-80c2-40c7-d934-df2c4f81dea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.get_num_tokens(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH0hi5EkvxJX"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import load_summarize_chain\n",
        "from langchain.docstore import document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "ZWDTl5EEwF0n",
        "outputId": "aa6a7d4c-50bc-465c-c04d-b2faa14f71d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ada3b17f-5a58-4338-af31-d488199dcba2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ada3b17f-5a58-4338-af31-d488199dcba2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving sj.txt to sj.txt\n",
            "I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.\n",
            "\n",
            "The first story is about connecting the dots.\n",
            "\n",
            "I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "with open ('sj.txt', encoding = 'utf-8') as f:\n",
        "  text = f.read()\n",
        "\n",
        "docs = [document.Document(page_content=text)]\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ol-8GkwxLE",
        "outputId": "61d6a4f8-9d33-4eb3-8090-14ae4ae055a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steve Jobs delivered a commencement speech sharing three impactful stories from his life. He spoke about connecting the dots, detailing how dropping out of college allowed him to explore his interests, such as calligraphy, which later influenced the Macintosh computer's typography. He addressed love and loss, recounting his firing from Apple, which led him to start NeXT and Pixar, ultimately bringing innovation and personal growth. Lastly, he reflected on death, emphasizing the finite nature of life and the importance of living authentically and following one’s heart. He urged graduates to pursue what they love and concluded with the advice: \"Stay Hungry. Stay Foolish.\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ''' write a concise and short summary of the following text. \\n TEXT : {text} '''\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "output = chain.run(docs)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE0fB1Wa0EHD",
        "outputId": "c1382eae-3b37-4e1c-cf1d-0d0324886780"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 128K [ Input token and output token]\n",
        "#limit 10000\n",
        "\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\"],\n",
        "    chunk_size=10000,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "chunk = text_splitter.create_documents([text])\n",
        "\n",
        "\n",
        "len(chunk)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zttJ1hwn1Cd4",
        "outputId": "456ee626-f2de-4faf-ed7e-c99cfdbe281f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steve Jobs' commencement speech shared three life lessons: trust in life's journey, find opportunity in setbacks, and embrace life's impermanence. Dropping out of college led him to discover calligraphy, shaping Macintosh's design. His firing from Apple inspired new ventures with NeXT and Pixar, ultimately fueling his return and innovation at Apple. A cancer diagnosis reminded him to live intentionally and authentically, urging graduates to pursue their passions and embrace individuality. He concluded with the advice: \"Stay Hungry. Stay Foolish.\"\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "output = chain.run(chunk)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHH8goHv2ktP"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3KkP8Z2yBb",
        "outputId": "535525b6-4607-4edb-fea6-d14bab2a95f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pdf2image pdfminer pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "nzlqkggg27Nf",
        "outputId": "f7f805a4-d675-4f52-bf68-0f88ddc258d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1f15f6f-72bb-40e8-99a3-4cc420766b72\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1f15f6f-72bb-40e8-99a3-4cc420766b72\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving attention_is_all_you_need.pdf to attention_is_all_you_need.pdf\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "File path  is not a valid file or url",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-935733619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0maload\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mto\u001b[0m \u001b[0mretrieve\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         self.parser = PyPDFParser(\n\u001b[1;32m    283\u001b[0m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_pdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File path %s is not a valid file or url\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File path  is not a valid file or url"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "pdf = PyPDFLoader('attention_is_all_you_need.pdf')\n",
        "data = loader.load()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
